{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "seq2seq.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "HXZ2_xdsAQee",
        "BC5CbwHlAQef"
      ],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AslanDevbrat/Seq2Seq/blob/visual/seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n"
      ],
      "metadata": {
        "id": "XtD33RcAAQeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install wandb --upgrade\n",
        "!pip install tensorflow-addons"
      ],
      "metadata": {
        "id": "UBUz4pd87YeP",
        "execution": {
          "iopub.status.busy": "2022-06-19T11:46:04.715027Z",
          "iopub.execute_input": "2022-06-19T11:46:04.715895Z",
          "iopub.status.idle": "2022-06-19T11:46:36.340025Z",
          "shell.execute_reply.started": "2022-06-19T11:46:04.715742Z",
          "shell.execute_reply": "2022-06-19T11:46:36.338600Z"
        },
        "trusted": true
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNNCell, GRUCell, Dense, LSTMCell\n",
        "from tensorflow.keras import Input\n",
        "import pandas as pd\n",
        "from numpy import argmax\n",
        "from math import log\n",
        "import pprint\n",
        "import math\n",
        "import wandb\n",
        "import os\n",
        "import io\n",
        "from wandb.keras import WandbCallback\n",
        "import time\n",
        "import sys\n",
        "from IPython.display import HTML as html_print\n",
        "from IPython.display import display\n",
        "# from kaggle_secrets import UserSecretsClient\n",
        "# user_secrets = UserSecretsClient()\n",
        "# wandb_api = user_secrets.get_secret(\"wandb_api\")\n",
        "\n",
        "# #wandb.login(key=wandb_api)\n",
        "# ! wandb login $wandb_api\n",
        "\n",
        "# os.environ[\"WANDB_SILENT\"] = \"true\"\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "EnvOeSibAQeV",
        "outputId": "517ea20e-7c21-4670-889b-82aaae5f8217",
        "execution": {
          "iopub.status.busy": "2022-06-19T14:55:00.466081Z",
          "iopub.execute_input": "2022-06-19T14:55:00.466557Z",
          "iopub.status.idle": "2022-06-19T14:55:04.846701Z",
          "shell.execute_reply.started": "2022-06-19T14:55:00.466520Z",
          "shell.execute_reply": "2022-06-19T14:55:04.844596Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maslan\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 271
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the data\n"
      ],
      "metadata": {
        "id": "NbOpYTqYAQeX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration\n"
      ],
      "metadata": {
        "id": "1rKnaKIZAQeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
        "!tar -xf 'dakshina_dataset_v1.0.tar'\n",
        "train_file_path = \"/content/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\"\n",
        "val_file_path= \"/content/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv\"\n",
        "test_file_path  = \"/content/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv\""
      ],
      "metadata": {
        "id": "roFBlOuMAYkx",
        "execution": {
          "iopub.status.busy": "2022-06-19T11:47:33.470862Z",
          "iopub.execute_input": "2022-06-19T11:47:33.471940Z",
          "iopub.status.idle": "2022-06-19T11:47:49.677198Z",
          "shell.execute_reply.started": "2022-06-19T11:47:33.471901Z",
          "shell.execute_reply": "2022-06-19T11:47:49.676010Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aeceadf-5539-46bf-aa31-e6a33c35b5af"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-22 11:12:28--  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.197.128, 74.125.135.128, 74.125.142.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.197.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2008340480 (1.9G) [application/x-tar]\n",
            "Saving to: ‘dakshina_dataset_v1.0.tar’\n",
            "\n",
            "dakshina_dataset_v1 100%[===================>]   1.87G   158MB/s    in 12s     \n",
            "\n",
            "2022-06-22 11:12:40 (157 MB/s) - ‘dakshina_dataset_v1.0.tar’ saved [2008340480/2008340480]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64  # Batch size for training.\n",
        "epochs = 100  # Number of epochs to train for.\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
        "num_samples = 100000  # Number of samples to train on.\n",
        "# Path to the data txt file on disk.\n",
        "data_path = train_file_path\n"
      ],
      "metadata": {
        "id": "akMCxfVHAQeZ",
        "execution": {
          "iopub.status.busy": "2022-06-19T09:33:02.211259Z",
          "iopub.execute_input": "2022-06-19T09:33:02.211737Z",
          "iopub.status.idle": "2022-06-19T09:33:02.219013Z",
          "shell.execute_reply.started": "2022-06-19T09:33:02.211682Z",
          "shell.execute_reply": "2022-06-19T09:33:02.217846Z"
        },
        "trusted": true
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the data\n"
      ],
      "metadata": {
        "id": "U-3Djb36AQea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def processData(filename,input_chars=set(),target_chars=set()):\n",
        "  input=[]\n",
        "  target=[]\n",
        "  with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.read().split(\"\\n\")\n",
        "  for line in lines[:len(lines)-1]:\n",
        "      t_text,i_text, attestation = line.split(\"\\t\")\n",
        "       # We use \"\\t\" as the \"start sequence\" character and \"\\n\" as \"end sequence\" character for the target text.\n",
        "      input.append(\"\\t\"+i_text+\"\\n\")\n",
        "      target.append(\"\\t\"+t_text+\"\\n\")\n",
        "      for char in i_text:\n",
        "        if char not in input_chars:\n",
        "            input_chars.add(char)\n",
        "      for char in t_text:\n",
        "        if char not in target_chars:\n",
        "            target_chars.add(char)\n",
        "  target_chars.add(\"\\t\")\n",
        "  target_chars.add(\"\\n\")\n",
        "  input_chars.add(\"\\t\")\n",
        "  input_chars.add(\"\\n\")\n",
        "\n",
        "  input_chars = sorted(list(input_chars))\n",
        "  target_chars = sorted(list(target_chars))\n",
        "  num_encoder_tokens = len(input_chars)\n",
        "  num_decoder_tokens = len(target_chars)\n",
        "  max_encoder_seq_length = max([len(txt) for txt in input])\n",
        "  max_decoder_seq_length = max([len(txt) for txt in target])\n",
        "  return input,target,input_chars,target_chars,num_encoder_tokens,num_decoder_tokens, max_encoder_seq_length, max_decoder_seq_length     "
      ],
      "metadata": {
        "id": "5CZtxlJmaYmb",
        "execution": {
          "iopub.status.busy": "2022-06-19T15:21:54.385136Z",
          "iopub.execute_input": "2022-06-19T15:21:54.385606Z",
          "iopub.status.idle": "2022-06-19T15:21:54.397778Z",
          "shell.execute_reply.started": "2022-06-19T15:21:54.385570Z",
          "shell.execute_reply": "2022-06-19T15:21:54.396551Z"
        },
        "trusted": true
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize the data.\n",
        "input,target,input_chars,target_chars,num_encoder_tokens,num_decoder_tokens, max_encoder_seq_length, max_decoder_seq_length=processData(train_file_path)\n",
        "print(\"Number of samples:\", len(input))\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)"
      ],
      "metadata": {
        "id": "pg8AcuMoab8U",
        "outputId": "35f49c7e-2b48-4cef-ece8-a0cb1d14ed9d",
        "execution": {
          "iopub.status.busy": "2022-06-19T15:21:56.055100Z",
          "iopub.execute_input": "2022-06-19T15:21:56.055975Z",
          "iopub.status.idle": "2022-06-19T15:21:56.181503Z",
          "shell.execute_reply.started": "2022-06-19T15:21:56.055922Z",
          "shell.execute_reply": "2022-06-19T15:21:56.179927Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 44204\n",
            "Number of unique input tokens: 28\n",
            "Number of unique output tokens: 65\n",
            "Max sequence length for inputs: 22\n",
            "Max sequence length for outputs: 21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize the data.\n",
        "# Vectorize the data.\n",
        "validation_input,validation_target,input_chars,target_chars,num_encoder_tokens,num_decoder_tokens, validation_max_encoder_seq_length, validation_max_decoder_seq_length=processData(val_file_path,set(input_chars),set(target_chars))\n",
        "\n",
        "print(\"Number of validation samples:\", len(validation_input))\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "print(\"validation Max sequence length for inputs:\", validation_max_encoder_seq_length)\n",
        "print(\"validation Max sequence length for outputs:\", validation_max_decoder_seq_length)"
      ],
      "metadata": {
        "id": "lmCnQKWNbsuh",
        "outputId": "04d9e413-d654-4174-8ef5-dec9d6495f38",
        "execution": {
          "iopub.status.busy": "2022-06-19T15:32:00.457765Z",
          "iopub.execute_input": "2022-06-19T15:32:00.458307Z",
          "iopub.status.idle": "2022-06-19T15:32:00.484257Z",
          "shell.execute_reply.started": "2022-06-19T15:32:00.458272Z",
          "shell.execute_reply": "2022-06-19T15:32:00.482872Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of validation samples: 4502\n",
            "Number of unique input tokens: 28\n",
            "Number of unique output tokens: 65\n",
            "validation Max sequence length for inputs: 18\n",
            "validation Max sequence length for outputs: 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize the data.\n",
        "test_input,test_target,test_input_chars,test_target_chars,test_num_encoder_tokens,test_num_decoder_tokens, test_max_encoder_seq_length, test_max_decoder_seq_length=processData(test_file_path)\n",
        "print(\"Number of validation samples:\", len(test_input))\n",
        "print(\"Test Max sequence length for inputs:\", test_max_encoder_seq_length)\n",
        "print(\"Test Max sequence length for outputs:\", test_max_decoder_seq_length)"
      ],
      "metadata": {
        "id": "Q9tUFlovbz5i",
        "outputId": "48f151f2-7f34-4bda-e186-7fdcff42a906",
        "execution": {
          "iopub.status.busy": "2022-06-19T15:05:18.181757Z",
          "iopub.execute_input": "2022-06-19T15:05:18.182569Z",
          "iopub.status.idle": "2022-06-19T15:05:18.200082Z",
          "shell.execute_reply.started": "2022-06-19T15:05:18.182519Z",
          "shell.execute_reply": "2022-06-19T15:05:18.199204Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of validation samples: 4358\n",
            "Test Max sequence length for inputs: 20\n",
            "Test Max sequence length for outputs: 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input_token = dict([(char, i) for i, char in enumerate(input_chars)])\n",
        "# target_token = dict([(char, i) for i, char in enumerate(target_chars)])\n",
        "\n",
        "# reverse_input_token = dict((i, char) for char, i in input_token.items())\n",
        "# reverse_target_token = dict((i, char) for char, i in target_token.items())\n",
        "\n",
        "\n",
        "# encoder_input_data = np.zeros(\n",
        "#     (len(input), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
        "# )\n",
        "# validation_encoder_input_data=np.zeros(\n",
        "#     (len(validation_input), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
        "# )\n",
        "# test_encoder_input_data=np.zeros(\n",
        "#     (len(test_input), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
        "# )\n",
        "# decoder_input_data = np.zeros(\n",
        "#     (len(input), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        "# )\n",
        "# validation_decoder_input_data =np.zeros(\n",
        "#     (len(validation_input), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        "# )\n",
        "# decoder_target_data = np.zeros(\n",
        "#     (len(input), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        "# )\n",
        "# validation_decoder_target_data = np.zeros(\n",
        "#     (len(validation_input), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        "# )\n",
        "\n",
        "# for i, (input_text, target_text) in enumerate(zip(input, target)):\n",
        "#     for t, char in enumerate(input_text):\n",
        "#         encoder_input_data[i, t, input_token[char]] = 1.0\n",
        "#     for t, char in enumerate(target_text):\n",
        "#         # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "#         decoder_input_data[i, t, target_token[char]] = 1.0\n",
        "#         if t > 0:\n",
        "#             # decoder_target_data will be ahead by one timestep\n",
        "#             # and will not include the start character.\n",
        "#             decoder_target_data[i, t - 1, target_token[char]] = 1.0\n",
        "# # for validation data\n",
        "# for i, (validation_input_text, validation_target_text) in enumerate(zip(validation_input, validation_target)):\n",
        "#     for t, char in enumerate(validation_input_text):\n",
        "#         validation_encoder_input_data[i, t, input_token[char]] = 1.0\n",
        "#     for t, char in enumerate(validation_target_text):\n",
        "#         # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "#         validation_decoder_input_data[i, t, target_token[char]] = 1.0\n",
        "#         if t > 0:\n",
        "#             # decoder_target_data will be ahead by one timestep\n",
        "#             # and will not include the start character.\n",
        "#             validation_decoder_target_data[i, t - 1, target_token[char]] = 1.0\n",
        "\n",
        "# # for test data\n",
        "# for i, (test_input_text, test_target_text) in enumerate(zip(test_input, test_target)):\n",
        "#     for t, char in enumerate(test_input_text):\n",
        "#         test_encoder_input_data[i, t, input_token[char]] = 1.0"
      ],
      "metadata": {
        "id": "oBF7Cdqrb5Hc",
        "execution": {
          "iopub.status.busy": "2022-06-19T14:30:35.223556Z",
          "iopub.execute_input": "2022-06-19T14:30:35.224039Z",
          "iopub.status.idle": "2022-06-19T14:30:36.884489Z",
          "shell.execute_reply.started": "2022-06-19T14:30:35.224003Z",
          "shell.execute_reply": "2022-06-19T14:30:36.883493Z"
        },
        "trusted": true
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2q7AdDj4P_8p",
        "execution": {
          "iopub.status.busy": "2022-06-19T14:30:37.301677Z",
          "iopub.execute_input": "2022-06-19T14:30:37.302743Z",
          "iopub.status.idle": "2022-06-19T14:30:38.242257Z",
          "shell.execute_reply.started": "2022-06-19T14:30:37.302700Z",
          "shell.execute_reply": "2022-06-19T14:30:38.241015Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1108199-b1c5-4b88-d9f7-d488a3b89140"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\t': 0,\n",
              " '\\n': 1,\n",
              " 'a': 2,\n",
              " 'b': 3,\n",
              " 'c': 4,\n",
              " 'd': 5,\n",
              " 'e': 6,\n",
              " 'f': 7,\n",
              " 'g': 8,\n",
              " 'h': 9,\n",
              " 'i': 10,\n",
              " 'j': 11,\n",
              " 'k': 12,\n",
              " 'l': 13,\n",
              " 'm': 14,\n",
              " 'n': 15,\n",
              " 'o': 16,\n",
              " 'p': 17,\n",
              " 'q': 18,\n",
              " 'r': 19,\n",
              " 's': 20,\n",
              " 't': 21,\n",
              " 'u': 22,\n",
              " 'v': 23,\n",
              " 'w': 24,\n",
              " 'x': 25,\n",
              " 'y': 26,\n",
              " 'z': 27}"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_token = dict([(char, i) for i, char in enumerate(input_chars)])\n",
        "target_token = dict([(char, i) for i, char in enumerate(target_chars)])\n",
        "\n",
        "reverse_input_token = dict((i, char) for char, i in input_token.items())\n",
        "reverse_target_token = dict((i, char) for char, i in target_token.items())\n",
        "\n",
        "enc_input_data = np.ones(\n",
        "    (len(input), max_encoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "dec_input_data = np.ones(\n",
        "    (len(input), max_decoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "dec_target_data = np.ones(\n",
        "    (len(input), max_decoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "#Decoder Target Sequences are Padded to a maximum length of max_decoder SeqLen characters with a vocabulary of sizeofTeluguVocab different characters. \n",
        "for i, (input_text, target_text) in enumerate(zip(input, target)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        enc_input_data[i, t] = input_token[char]\n",
        "    #enc_input_data[i, t + 1 :] = input_token[\" \"]\n",
        "\n",
        "    for t, char in enumerate(target_text):\n",
        "        # dec_target_data is ahead of dec_input_data by one timestep\n",
        "        dec_input_data[i, t] = target_token[char]\n",
        "        if t > 0:\n",
        "            # dec_target_data will not include the start character.\n",
        "            dec_target_data[i, t - 1] = target_token[char]\n",
        "    #dec_input_data[i, t + 1: ] = target_token[\" \"]\n",
        "    #dec_target_data[i, t:, target_token[\" \"]] = 1.0\n",
        "    \n",
        "val_enc_input_data = np.ones(\n",
        "    (len(validation_input), validation_max_encoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "val_dec_input_data = np.ones(\n",
        "    (len(validation_input), validation_max_decoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "val_dec_target_data = np.ones(\n",
        "    (len(validation_input), validation_max_decoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(validation_input,validation_target)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        # Enumerate() method adds a counter to an iterable and returns it in a form of enumerating object. \n",
        "        # This enumerated object can then be used directly for loops or converted into a list of tuples using the list() method.\n",
        "        val_enc_input_data[i, t] = input_token[char]\n",
        "    #val_enc_input_data[i, t + 1 :] = input_token_index[\" \"]\n",
        "\n",
        "    for t, char in enumerate(target_text):\n",
        "        val_dec_input_data[i, t] = target_token[char]\n",
        "        if t > 0:\n",
        "            # dec_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            val_dec_target_data[i, t - 1] =  target_token[char]\n",
        "    #val_dec_input_data[i, t + 1: ] = target_token_index[\" \"]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-19T15:33:00.750838Z",
          "iopub.execute_input": "2022-06-19T15:33:00.751958Z",
          "iopub.status.idle": "2022-06-19T15:33:01.589162Z",
          "shell.execute_reply.started": "2022-06-19T15:33:00.751901Z",
          "shell.execute_reply": "2022-06-19T15:33:01.588102Z"
        },
        "trusted": true,
        "id": "6_L_o5BGrP3z"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xtmF5PX1Xo9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class NMTDataset:\n",
        "#     def __init__(self, problem_type='en-hi'):\n",
        "#         self.problem_type = 'en-'\n",
        "#         self.inp_lang_tokenizer = None\n",
        "#         self.targ_lang_tokenizer = None\n",
        "    \n",
        "\n",
        "#     def unicode_to_ascii(self, s):\n",
        "#         return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "#     ## Step 1 and Step 2 \n",
        "#     def preprocess_sentence(self, w):\n",
        "#         # w = self.unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "#         # # creating a space between a word and the punctuation following it\n",
        "#         # # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "#         # # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "#         # w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "#         # w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "#         # # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "#         # w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "#         # w = w.strip()\n",
        "\n",
        "#         # adding a start and an end token to the sentence\n",
        "#         # so that the model know when to start and stop predicting.\n",
        "#         #print(w)\n",
        "#         w = '\\t' + w + '\\n'\n",
        "        \n",
        "#         return w\n",
        "    \n",
        "#     def create_dataset(self, path, num_examples):\n",
        "#         # path : path to spa-eng.txt file\n",
        "#         # num_examples : Limit the total number of training example for faster training (set num_examples = len(lines) to use full data)\n",
        "#         #lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "#         #word_pairs = [[self.preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "#         data =  pd.read_csv(path,delimiter=\"\\t\", header= None, nrows = num_examples )\n",
        "#         data = data.dropna()\n",
        "#         print(data.info())\n",
        "#         return data[0].apply(self.preprocess_sentence).values.astype(str), data[1].apply(self.preprocess_sentence).values.astype(str)\n",
        "\n",
        "#     # Step 3 and Step 4\n",
        "#     def tokenize(self, lang):\n",
        "#         # lang = list of sentences in a language\n",
        "        \n",
        "#         # print(len(lang), \"example sentence: {}\".format(lang[0]))\n",
        "#         lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(char_level = True)\n",
        "#         lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "#         ## tf.keras.preprocessing.text.Tokenizer.texts_to_sequences converts string (w1, w2, w3, ......, wn) \n",
        "#         ## to a list of correspoding integer ids of words (id_w1, id_w2, id_w3, ...., id_wn)\n",
        "#         tensor = lang_tokenizer.texts_to_sequences(lang) \n",
        "\n",
        "#         ## tf.keras.preprocessing.sequence.pad_sequences takes argument a list of integer id sequences \n",
        "#         ## and pads the sequences to match the longest sequences in the given input\n",
        "#         tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
        "\n",
        "#         return tensor, lang_tokenizer\n",
        "\n",
        "#     def load_dataset(self, path, num_examples=None):\n",
        "#         # creating cleaned input, output pairs\n",
        "#         targ_lang, inp_lang = self.create_dataset(path, num_examples)\n",
        "\n",
        "#         input_tensor, inp_lang_tokenizer = self.tokenize(inp_lang)\n",
        "#         target_tensor, targ_lang_tokenizer = self.tokenize(targ_lang)\n",
        "\n",
        "#         return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer\n",
        "\n",
        "#     def call(self, num_examples, BUFFER_SIZE, BATCH_SIZE):\n",
        "#         #file_path = download_dakshina()\n",
        "#         input_tensor_train, target_tensor_train, self.inp_lang_tokenizer, self.targ_lang_tokenizer = self.load_dataset(train_file_path, num_examples)\n",
        "#         input_tensor_val, target_tensor_val, self.inp_lang_tokenizer, self.targ_lang_tokenizer = self.load_dataset(val_file_path, num_examples)\n",
        "#         input_tensor_test, target_tensor_test, self.inp_lang_tokenizer, self.targ_lang_tokenizer = self.load_dataset(test_file_path, num_examples)\n",
        "#         x = input_tensor_train\n",
        "#         y  =target_tensor_train\n",
        "#         #input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.4)\n",
        "\n",
        "#         train_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train,target_tensor_train))\n",
        "#         train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "#         val_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_val, target_tensor_val))\n",
        "#         val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "#         test_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_test, target_tensor_test))\n",
        "#         test_dataset = test_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "#         return train_dataset, val_dataset, test_dataset, self.inp_lang_tokenizer, self.targ_lang_tokenizer\n"
      ],
      "metadata": {
        "id": "EOIwk0-PrP3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BUFFER_SIZE = 32000\n",
        "# BATCH_SIZE = 64\n",
        "# # Let's limit the #training examples for faster training\n",
        "# num_examples = 300000\n",
        "\n",
        "# dataset_creator = NMTDataset('en-spa')\n",
        "# train_dataset, val_dataset,test_dataset, inp_lang, targ_lang = dataset_creator.call(num_examples, BUFFER_SIZE, BATCH_SIZE)"
      ],
      "metadata": {
        "id": "s3Wn4CM1zgLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_dataset))[1][0]"
      ],
      "metadata": {
        "id": "9Rox45Q1hWgm",
        "outputId": "05609fc2-54dc-4c20-e204-01bda96fe41e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(21,), dtype=int32, numpy=\n",
              "array([ 1,  7, 15, 28,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_input_batch, example_target_batch = next(iter(train_dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gaZrS4g1T5X",
        "outputId": "97ad97b4-743b-44fc-81d2-ccd5ff884d00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 22]), TensorShape([64, 21]))"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the model\n"
      ],
      "metadata": {
        "id": "eGM50wwWAQed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, num_of_layers, enc_unit_type, batch_sz, recurrent_dropout, dropout):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.enc_unit_type = enc_unit_type\n",
        "    self.num_of_layers = num_of_layers\n",
        "    self.recurrent_dropout = recurrent_dropout\n",
        "    self.dropout = dropout\n",
        "    self.embedding = Embedding( vocab_size, embedding_dim)\n",
        "\n",
        "    self.encoder_layer = self.get_encoder_layer(self.enc_units,\n",
        "                                                self.num_of_layers, self.enc_unit_type)\n",
        "    \n",
        "\n",
        "  def get_encoder_layer(self, enc_units, num_of_layers, enc_unit_type):\n",
        "    return tf.keras.layers.RNN(tf.keras.layers.StackedRNNCells( [self.get_cell(enc_unit_type, \n",
        "                                                                                 enc_units) for i in range(num_of_layers)],),\n",
        "                                  return_sequences=True, return_state=True, name = \"Encoder\")\n",
        "\n",
        "  def get_cell(self, cell_type = \"lstm\", num_of_cell = 1, name = None):\n",
        "      #print(cell_type)\n",
        "      if cell_type == \"lstm\":\n",
        "        return LSTMCell(num_of_cell, dropout = self.dropout, recurrent_dropout = self.recurrent_dropout, )\n",
        "      elif cell_type == \"rnn\":\n",
        "        return SimpleRNNCell(num_of_cell, dropout = self.dropout, recurrent_dropout = self.recurrent_dropout)\n",
        "      elif cell_type ==\"gru\":\n",
        "        return GRUCell(num_of_cell, dropout = self.dropout, recurrent_dropout = self.recurrent_dropout)\n",
        "      else:\n",
        "        print(f\"Invalid cell type: {cell_type}\")\n",
        "\n",
        "    \n",
        "  def call(self, x):\n",
        "      x = self.embedding(x)\n",
        "      output = self.encoder_layer(x,)\n",
        "\n",
        "      #print(output)\n",
        "      return output\n",
        "    \n",
        "  def initialize_hidden_state(self):\n",
        "      print(\"Called\")\n",
        "      return [tf.zeros((self.batch_sz, self.enc_units)), tf.zeros((self.batch_sz, self.enc_units))]"
      ],
      "metadata": {
        "id": "-_IMrNwXsYR4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_input_data[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iT2EuNf1TDo",
        "outputId": "7a08f4c6-f141-4984-9b5f-544a2c3aceec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20,)"
            ]
          },
          "metadata": {},
          "execution_count": 278
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#encoder = Encoder( num_encoder_tokens, 1024, 1024, 3, \"lstm\", batch_size, 0.0, 0.0).build(input_shape =(None,22))\n",
        "encoder = Encoder( num_encoder_tokens, 1, 16, 3, \"lstm\", 64, 0.0, 0.0)\n",
        "#sample_hidden = encoder.initialize_hidden_state()\n",
        "# encoder.build(input_shape =(None,26))\n",
        "# encoder.summary()\n",
        "sample_output = encoder(enc_input_data[:64])\n",
        "out , state = sample_output[0], sample_output[1:]"
      ],
      "metadata": {
        "id": "oG6E1qaLv92s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out, state"
      ],
      "metadata": {
        "id": "yHmvx-1zRHJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, num_of_layers, \n",
        "               dec_unit_type, batch_sz, recurrent_dropout, dropout, \n",
        "               attention_type = \"luong\"):\n",
        "    \n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.dec_unit_type = dec_unit_type\n",
        "    self.num_of_layers = num_of_layers\n",
        "    self.attention_type = attention_type\n",
        "    self.recurrent_dropout = recurrent_dropout\n",
        "    self.dropout = dropout\n",
        "    #print(\"decoder embedding dim\", embedding_dim)\n",
        "    self.embedding = Embedding( vocab_size, embedding_dim)\n",
        "\n",
        "    self.fc  = tf.keras.layers.Dense(vocab_size, activation = \"softmax\")\n",
        "\n",
        "    self.decoder_cells = self.get_stacked_rnn_cell()\n",
        "\n",
        "    self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
        "    self.attention_mechanism = self.build_attention_mechanism(self.dec_units, None\n",
        "                                                              , self.batch_sz*[max_encoder_seq_length], \n",
        "                                                              self.attention_type)\n",
        "\n",
        "    self.cell = self.build_cell()\n",
        "\n",
        "    #print(self.cell)\n",
        "\n",
        "    self.decoder = tfa.seq2seq.BasicDecoder(self.cell, sampler = self.sampler, output_layer = self.fc)\n",
        "\n",
        "\n",
        "\n",
        "  def build_cell(self):\n",
        "    cell = tfa.seq2seq.AttentionWrapper(self.decoder_cells, self.attention_mechanism,\n",
        "                                        attention_layer_size = self.dec_units)\n",
        "    return cell\n",
        "  \n",
        "  def build_attention_mechanism(self, dec_units, memory, memory_sequence_length, attention_type='luong'):\n",
        "    # ------------- #\n",
        "    # typ: Which sort of attention (Bahdanau, Luong)\n",
        "    # dec_units: final dimension of attention outputs \n",
        "    # memory: encoder hidden states of shape (batch_size, max_length_input, enc_units)\n",
        "    # memory_sequence_length: 1d array of shape (batch_size) with every element set to max_length_input (for masking purpose)\n",
        "\n",
        "    if(attention_type=='bahdanau'):\n",
        "      return tfa.seq2seq.BahdanauAttention(units=dec_units, memory=memory, memory_sequence_length=memory_sequence_length)\n",
        "    else:\n",
        "      return tfa.seq2seq.LuongAttention(units=dec_units, memory=memory, memory_sequence_length=memory_sequence_length)\n",
        "\n",
        "  def get_cell(self, cell_type = \"lstm\", num_of_cell = 1, name = None):\n",
        "      #print(cell_type)\n",
        "      if cell_type == \"lstm\":\n",
        "        return LSTMCell(num_of_cell, dropout = self.dropout, recurrent_dropout = self.recurrent_dropout, )\n",
        "      elif cell_type == \"rnn\":\n",
        "        return SimpleRNNCell(num_of_cell, dropout = self.dropout, recurrent_dropout = self.recurrent_dropout)\n",
        "      elif cell_type ==\"gru\":\n",
        "        return GRUCell(num_of_cell, dropout = self.dropout, recurrent_dropout = self.recurrent_dropout)\n",
        "      else:\n",
        "        print(f\"Invalid cell type: {cell_type}\")\n",
        "\n",
        "  def get_stacked_rnn_cell(self,):\n",
        "    return tf.keras.layers.StackedRNNCells( [self.get_cell(self.dec_unit_type, self.dec_units,) for i in range(self.num_of_layers)])\n",
        "\n",
        "  def build_initial_state(self, batch_sz, encoder_state, Dtype):\n",
        "    decoder_initial_state = self.cell.get_initial_state(batch_size=batch_sz, dtype=Dtype)\n",
        "    #print(batch_sz)\n",
        "    #print(len(encoder_state))\n",
        "    decoder_initial_state = decoder_initial_state.clone(cell_state=encoder_state)\n",
        "    return decoder_initial_state\n",
        "\n",
        "  def call(self, x, initial_state):\n",
        "    x = self.embedding(x)\n",
        "    #print(\"calles\")\n",
        "    output = self.decoder(x, initial_state=initial_state)\n",
        "    return output"
      ],
      "metadata": {
        "id": "vPiwKS7P7A3X"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#encoder = Encoder( num_encoder_tokens, 1024, 1024, 3, \"lstm\", batch_size, 0.0, 0.0).build(input_shape =(None,22))\n",
        "decoder = Decoder( num_decoder_tokens,  1, 16, 3, \"lstm\", 64, 0.0, 0.0)\n",
        "#sample_hidden = encoder.initialize_hidden_state()\n",
        "#decoder.build(input_shape =(None, ))\n",
        "# decoder.summary()\n",
        "#sample_x = tf.random.uniform((2  ,max_decoder_seq_length))\n",
        "decoder.attention_mechanism.setup_memory(out)\n",
        "initial_state = decoder.build_initial_state(64, tuple(state), tf.float32)\n",
        "# sample_output = decoder(dec_input_data[:8192], initial_state)\n",
        "# out1 , state1 = sample_output[0], sample_output[1:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fe8whQdYCdfZ",
        "outputId": "62bd1aa0-6726-41c8-a941-25bf2702c4fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decoder embedding dim 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out1"
      ],
      "metadata": {
        "id": "s1cQ1JBzWhth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = tf.data.Dataset.from_tensor_slices((enc_input_data, dec_input_data))\n",
        "target_data =  tf.data.Dataset.from_tensor_slices(dec_target_data)\n",
        "train_dataset  = tf.data.Dataset.zip((input_data, target_data)).batch(batch_size, drop_remainder=True)\n",
        "\n",
        "input_data = tf.data.Dataset.from_tensor_slices((val_enc_input_data, val_dec_input_data))\n",
        "target_data =  tf.data.Dataset.from_tensor_slices(val_dec_target_data)\n",
        "val_dataset  = tf.data.Dataset.zip((input_data, target_data)).batch(batch_size, drop_remainder=True)"
      ],
      "metadata": {
        "id": "Y-R5t0ex2M6v"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class seq2seq():\n",
        "  def __init__(self, num_encoder_tokens, num_decoder_token, encoder_embedding_dim, decoder_embedding_dim,num_of_unit, num_of_layers, unit_type, batch_size, recurrent_dropout, dropout):\n",
        "    super().__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.encoder = Encoder(  num_encoder_tokens, encoder_embedding_dim, num_of_unit, num_of_layers, unit_type, self.batch_size,  recurrent_dropout, dropout)\n",
        "    #self.encoder.summary()\n",
        "    self.dec = Decoder( num_decoder_tokens,  decoder_embedding_dim, num_of_unit, num_of_layers, unit_type, self.batch_size, recurrent_dropout, dropout)\n",
        "    #sample_x = tf.random.uniform((batch_size  ,max_decoder_seq_length))\n",
        "\n",
        "  def call(self, enc_inp, dec_inp):\n",
        "    #print(\"fsdfa\",dec_inp.shape)\n",
        "    x = self.encoder(enc_inp)\n",
        "    enc_out, enc_state = x[0], x[1:]\n",
        "    #print(enc_out.shape)\n",
        "    self.dec.attention_mechanism.setup_memory(enc_out)\n",
        "    dec_initial_state = self.dec.build_initial_state(self.batch_size, tuple(enc_state), tf.float32)\n",
        "    #print(\"fucck\")\n",
        "    x = self.dec(dec_inp,dec_initial_state)\n",
        "    return x\n",
        "\n",
        "  @tf.function\n",
        "  def validation_step(self, val_enc_input_data, val_dec_input_data, targ):\n",
        "    #dec_input_data = val_dec_input_data[ : , :-1 ]\n",
        "    out = self.call(val_enc_input_data, val_dec_input_data)\n",
        "    logits = out[0].rnn_output\n",
        "    #print(logits.item())\n",
        "    loss = 0\n",
        "    for (i, (ta, pre)) in enumerate(zip(tf.unstack(targ),tf.unstack(logits))):\n",
        "        stop = tf.where( ta == 1)[0][0]\n",
        "        stop+=1\n",
        "        self.metric.update_state(ta[:stop], pre[:stop])\n",
        "        loss += self.loss_function(ta[:stop], pre[:stop])\n",
        "    #loss += self.loss_function(real, logits)\n",
        "    #print(\"Validation Loss = \", loss.numpy())\n",
        "    #self.metric.update_state(real, logits)\n",
        "    return loss/i, self.metric.result()\n",
        "\n",
        "  @tf.function\n",
        "  def train_step(self, enc_input_data, dec_input_data, targ):\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      \n",
        "      out = self.call(enc_input_data, dec_input_data)\n",
        "      logits = out[0].rnn_output\n",
        "      loss = 0\n",
        "      for (i, (ta, pre)) in enumerate(zip(tf.unstack(targ),tf.unstack(logits))):\n",
        "        stop = tf.where( ta == 1)[0][0]\n",
        "        stop+=1\n",
        "        self.metric.update_state(ta[:stop], pre[:stop])\n",
        "        loss += self.loss_function(ta[:stop], pre[:stop])\n",
        " \n",
        "      \n",
        "    variables = self.encoder.variables + self.dec.variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return loss/i, self.metric.result()\n",
        "\n",
        "  def fit(self, train_dataset, val_dataset, epochs, loss, optimizer, checkpoint, metric):\n",
        "    self.metric = metric\n",
        "\n",
        "    \n",
        "    self.loss_function = loss\n",
        "    self.optimizer = optimizer\n",
        "    steps_per_epoch = len(input)//batch_size\n",
        "    step_per_val_epoch  = len(validation_input)//batch_size\n",
        "    print(steps_per_epoch)\n",
        "    for epoch in range(epochs):\n",
        "      start = time.time()\n",
        "\n",
        "      #enc_hidden = encoder.initialize_hidden_state()\n",
        "      total_loss = 0\n",
        "      total_acc = 0\n",
        "      # print(enc_hidden[0].shape, enc_hidden[1].shape)\n",
        "\n",
        "      self.metric.reset_states()\n",
        "      for (batch, (inp, targ)) in enumerate(train_dataset.take(steps_per_epoch)):\n",
        "        #print(\"targ\", targ)\n",
        "        batch_loss , acc = self.train_step(inp[0],inp[1] ,targ )\n",
        "        total_loss += batch_loss\n",
        "        total_acc += acc\n",
        "        if batch % 100 == 0:\n",
        "          #break\n",
        "          print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                      batch,\n",
        "                                                      batch_loss.numpy()))\n",
        "      # saving (checkpoint) the model every 2 epochs\n",
        "      #val_enc_inp, val_dec_inp , val_targ = val_dataset.take(-1)\n",
        "      #val_enc_inp, val_dec_inp = val_inp.take(-1)\n",
        "      total_val_loss = 0\n",
        "      total_val_acc = 0\n",
        "\n",
        "      self.metric.reset_states()\n",
        "      for (batch, (inp, targ)) in enumerate(val_dataset.take(steps_per_epoch)):\n",
        "        #print(batch)\n",
        "       \n",
        "        val_batch_loss, val_acc = self.validation_step(inp[0],inp[1] ,targ)\n",
        "        total_val_loss +=val_batch_loss\n",
        "        total_val_acc += val_acc\n",
        "\n",
        "      print(f\"Validatiion loss:  {total_val_loss.numpy()/  step_per_val_epoch}\")\n",
        "      print((f\"Validatiion Acc:  {(total_val_acc.numpy()/  step_per_val_epoch)*100}\"))\n",
        "      # print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "      #                                                 batch,\n",
        "      #                                                 val_batch_loss.numpy()))\n",
        "      if (epoch + 1) % 2 == 0:\n",
        "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "      print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                          total_loss / steps_per_epoch))\n",
        "      print(\"Accuracy \",(total_acc.numpy()/steps_per_epoch) *100)\n",
        "      print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
        "\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "cVoQMjKYYLX2"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "s2s = seq2seq(num_encoder_tokens, num_decoder_tokens,  encoder_embedding_dim =64,\n",
        "              decoder_embedding_dim= 1024,\n",
        "              num_of_unit =16,\n",
        "              num_of_layers = 1, \n",
        "              unit_type =\"lstm\",\n",
        "             batch_size = batch_size, \n",
        "              recurrent_dropout = 0.3,\n",
        "              dropout = 0 )\n",
        "\n",
        "sample_out = s2s.call(enc_input_data[:batch_size], dec_input_data[:batch_size])"
      ],
      "metadata": {
        "id": "BRKTJEGid7MN"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s2s.call(enc_input_data[:batch_size], dec_input_data[:batch_size])"
      ],
      "metadata": {
        "id": "f_J78RufnWC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.RMSprop()\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  # real shape = (BATCH_SIZE, max_length_output)\n",
        "  # pred shape = (BATCH_SIZE, max_length_output, tar_vocab_size )\n",
        "  #print(pred,\"fucck\", real)\n",
        "  cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "  loss = cross_entropy(y_true=real, y_pred=pred)\n",
        "  mask = tf.logical_not(tf.math.equal(real,0))   #output 0 for y=0 else output 1\n",
        "  mask = tf.cast(mask, dtype=loss.dtype)  \n",
        "  loss = mask* loss\n",
        "  loss = tf.reduce_mean(loss)\n",
        "  return loss  "
      ],
      "metadata": {
        "id": "CD30sG2dRTLD"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=s2s.encoder,\n",
        "                                 decoder=s2s.dec,\n",
        "                                 )"
      ],
      "metadata": {
        "id": "25sIIGGxRVC2"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.run_functions_eagerly(False)\n",
        "s2s.fit(train_dataset, val_dataset, 5, loss_function, optimizer, checkpoint , metric =  tf.keras.metrics.SparseCategoricalAccuracy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHckm-8X2qG2",
        "outputId": "b2da81d0-6d43-4d18-9e7c-24cf26a16873"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "690\n",
            "Epoch 1 Batch 0 Loss 4.2407\n",
            "Epoch 1 Batch 100 Loss 4.0987\n",
            "Epoch 1 Batch 200 Loss 4.0885\n",
            "Epoch 1 Batch 300 Loss 4.0521\n",
            "Epoch 1 Batch 400 Loss 4.0726\n",
            "Epoch 1 Batch 500 Loss 4.1171\n",
            "Epoch 1 Batch 600 Loss 4.0375\n",
            "Validatiion loss:  4.038237217494419\n",
            "Validatiion Acc:  22.221897670200892\n",
            "Epoch 1 Loss 4.0647\n",
            "Accuracy  19.391267195991848\n",
            "Time taken for 1 epoch 76.85993146896362 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 4.0749\n",
            "Epoch 2 Batch 100 Loss 4.0521\n",
            "Epoch 2 Batch 200 Loss 4.0362\n",
            "Epoch 2 Batch 300 Loss 3.9977\n",
            "Epoch 2 Batch 400 Loss 4.0515\n",
            "Epoch 2 Batch 500 Loss 3.9508\n",
            "Epoch 2 Batch 600 Loss 4.0062\n",
            "Validatiion loss:  4.057774135044643\n",
            "Validatiion Acc:  20.193119049072266\n",
            "Epoch 2 Loss 4.0047\n",
            "Accuracy  24.660416755123414\n",
            "Time taken for 1 epoch 54.55500078201294 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 4.0403\n",
            "Epoch 3 Batch 100 Loss 4.0517\n",
            "Epoch 3 Batch 200 Loss 4.0257\n",
            "Epoch 3 Batch 300 Loss 3.9742\n",
            "Epoch 3 Batch 400 Loss 4.0187\n",
            "Epoch 3 Batch 500 Loss 3.9442\n",
            "Epoch 3 Batch 600 Loss 4.0013\n",
            "Validatiion loss:  4.059542410714286\n",
            "Validatiion Acc:  20.128597531999862\n",
            "Epoch 3 Loss 3.9953\n",
            "Accuracy  25.70935235507246\n",
            "Time taken for 1 epoch 54.16705775260925 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 4.0219\n",
            "Epoch 4 Batch 100 Loss 4.0754\n",
            "Epoch 4 Batch 200 Loss 4.0314\n",
            "Epoch 4 Batch 300 Loss 3.9612\n",
            "Epoch 4 Batch 400 Loss 3.9992\n",
            "Epoch 4 Batch 500 Loss 3.9513\n",
            "Epoch 4 Batch 600 Loss 3.9982\n",
            "Validatiion loss:  4.038169206891741\n",
            "Validatiion Acc:  21.741794858660015\n",
            "Epoch 4 Loss 3.9893\n",
            "Accuracy  27.750427688377492\n",
            "Time taken for 1 epoch 54.09791803359985 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 4.0307\n",
            "Epoch 5 Batch 100 Loss 4.0725\n",
            "Epoch 5 Batch 200 Loss 4.0080\n",
            "Epoch 5 Batch 300 Loss 3.9255\n",
            "Epoch 5 Batch 400 Loss 3.9869\n",
            "Epoch 5 Batch 500 Loss 3.9496\n",
            "Epoch 5 Batch 600 Loss 3.9870\n",
            "Validatiion loss:  4.087664794921875\n",
            "Validatiion Acc:  17.89147240774972\n",
            "Epoch 5 Loss 3.9866\n",
            "Accuracy  27.887500265370246\n",
            "Time taken for 1 epoch 55.82119822502136 sec\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkBBZHwzemoX",
        "outputId": "9bb77756-462a-45e7-8e19-ba47fac83ecb"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dec_input_data[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOmh_uHyl2SD",
        "outputId": "ec2df7ca-505d-4ece-ac84-f79e825bc5ac"
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17,)"
            ]
          },
          "metadata": {},
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualising RNN connectivity"
      ],
      "metadata": {
        "id": "hzwTPQfSPI41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8J11Yg-NPISA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_batch(appende, batch_size = 64):\n",
        "  temp  = []\n",
        "  for i in range(batch_size):\n",
        "    temp.append(appende)\n",
        "  return np.array(temp)"
      ],
      "metadata": {
        "id": "nW7WaEkvt4Ry"
      },
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tx = 0"
      ],
      "metadata": {
        "id": "sx8_gvU2zGmn"
      },
      "execution_count": 301,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def idx_to_word(word):\n",
        "  return  \"\".join([reverse_target_token[char] for char in word])\n",
        "def word_to_index(word):\n",
        "  return  [reverse_input_token[char] for char in word]\n",
        "\n",
        "def translate(word):\n",
        "  word = \"\\t\"+word+\"\\n\"\n",
        "  char_to_idx = [input_token[x] for x in word]\n",
        "  temp = np.ones(46)\n",
        "  input_encoder = create_batch(char_to_idx)\n",
        "  input_decoder = create_batch(temp)\n",
        "  enc_out = s2s.call(input_encoder, input_decoder)\n",
        "  tx = enc_out\n",
        "  index = argmax(enc_out[0].rnn_output[0], axis = 1)\n",
        "  print(index)\n",
        "  stop = np.where(index == 1)[0][0]\n",
        "  index[:stop]\n",
        "  return idx_to_word(index[:stop])"
      ],
      "metadata": {
        "id": "jVkrJj9Sl6o1"
      },
      "execution_count": 389,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translate(\"fuutderagck\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "VZaVEoF6npUv",
        "outputId": "8df2aee1-c418-47f2-9a17-a6017dc535eb"
      },
      "execution_count": 387,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
            " 43 43 43 43 43 43  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'रररररररररररररररररररररररररररररर'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 387
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhKAYFnzzMuT",
        "outputId": "ee997beb-765e-4232-bd42-f5415a6cb546"
      },
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 304
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get html element\n",
        "def cstr(s, color='black'):\n",
        "\tif s == ' ':\n",
        "    \n",
        "\t\treturn \"<text style=color:#000;padding-left:10px;background-color:{}> </text>\".format(color, s)\n",
        "\telse:\n",
        "\n",
        "\t\treturn \"<text style=color:#000;background-color:{}>{} </text>\".format(color, s)\n",
        "\t\n",
        "# print html\n",
        "def print_color(t):\n",
        "\tdisplay(html_print(''.join([cstr(ti, color=ci) for ti,ci in t])))\n",
        "\n",
        "# get appropriate color for value\n",
        "def get_clr(value):\n",
        "\tcolors = ['#85c2e1', '#89c4e2', '#95cae5', '#99cce6', '#a1d0e8'\n",
        "\t\t'#b2d9ec', '#baddee', '#c2e1f0', '#eff7fb', '#f9e8e8',\n",
        "\t\t'#f9e8e8', '#f9d4d4', '#f9bdbd', '#f8a8a8', '#f68f8f',\n",
        "\t\t'#f47676', '#f45f5f', '#f34343', '#f33b3b', '#f42e2e']\n",
        "\tvalue = int((value * 100) / 5)\n",
        "\treturn colors[value]\n",
        "\n",
        "# sigmoid function\n",
        "def sigmoid(x):\n",
        "\tz = 1/(1 + np.exp(-x)) \n",
        "\treturn z\n",
        "def visualize(output_values, result_list, cell_no, predicted_char):\n",
        "    #print( result_list)\n",
        "    #print(\"\\nPredicted Char : \", predicted_char)\n",
        "    print(f\"Importance of {predicted_char}\")\n",
        "    text_colours = []\n",
        "    for i in range(len(output_values)):\n",
        "      text = (result_list[i], get_clr(output_values[i][cell_no]))\n",
        "      text_colours.append(text)\n",
        "    print_color(text_colours)"
      ],
      "metadata": {
        "id": "dwPTRBsNraL0"
      },
      "execution_count": 434,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_connectivity(word):\n",
        "  print(\"Input word : \", word)\n",
        "  index_list = [input_token[x] for x in word]\n",
        "  #print(index_list)\n",
        "  enc_inp = create_batch(index_list)\n",
        "  dec_input = create_batch(np.ones(len(enc_inp)))\n",
        "  output = s2s.call(enc_inp, dec_input)\n",
        "  temp_list = []\n",
        "  for i in range(len(index_list)):\n",
        "    input_char_list = list(word)\n",
        "    out_char_list = list(idx_to_word(argmax(output[0].rnn_output[0][:i+1], axis =1)))\n",
        "    #print(\"fuck \",char_list)\n",
        "    temp_list.append(idx_to_word(argmax(output[0].rnn_output[0][:len(index_list)], axis = 1)))\n",
        "    #print(temp_list)\n",
        "    visualize(list(output[0].rnn_output[0][:i+1]), input_char_list,i+1, out_char_list[-1])\n",
        "  pred_word = \"\".join(out_char_list)\n",
        "  print(f\"\\nTransliterate word of {word[:-1]} is {pred_word}\")\n",
        "get_connectivity(\"afafsrc\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "b3tfWKZaDA40",
        "outputId": "83f897d5-9826-48fd-f3a2-1c3d04db58fc"
      },
      "execution_count": 441,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input word :  afafsrc\n",
            "\n",
            "Importance of र\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importance of र\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>f </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importance of र\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>f </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importance of र\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>f </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>f </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importance of र\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>f </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>f </text><text style=color:#000;background-color:#85c2e1>s </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importance of र\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>f </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>f </text><text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>r </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importance of र\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>f </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>f </text><text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>c </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importance of र\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>f </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>f </text><text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>c </text><text style=color:#000;background-color:#85c2e1>\n",
              " </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Transliterate word of afafsrc is रररररररर\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "visualize([[0.3,0.53, 0.9]],['f'], 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "Y8vQnQlQllIu",
        "outputId": "c69b3330-55cf-423e-fe1d-702de616bd2a"
      },
      "execution_count": 383,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cell Number: 0 \n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#c2e1f0>f </text><br><text style=color:#000;background-color:#c2e1f0>f </text><br>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tx  = s2s.call(create_batch([0,12,3,12,1]),create_batch(np.ones(43)))\n",
        "tx[0].rnn_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4wKxNnvzj1z",
        "outputId": "dd084341-1018-48d6-ebab-178034b40ad7"
      },
      "execution_count": 325,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 43, 65])"
            ]
          },
          "metadata": {},
          "execution_count": 325
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tx[0].rnn_output[0][1] == tx[0].rnn_output[0][2] "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPDPJBfe-K-c",
        "outputId": "e0fb2ab4-208e-4f96-cee3-c38d35214da0"
      },
      "execution_count": 359,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(65,), dtype=bool, numpy=\n",
              "array([False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False])>"
            ]
          },
          "metadata": {},
          "execution_count": 359
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.run_functions_eagerly(True)\n",
        "visualize(list(tx[0].rnn_output[4][:43].numpy()), ['r','2','44','2','3','3','r','2','44','2','3','3','r','2','44','2','3','3','r','2','44','2','3','3','r','2','44','2','3','3','r','2','44','2','3','3','r','2','44','2','3','3','r','2',], 43)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SOwoVBYY9imG",
        "outputId": "a57767d2-ce12-4d89-c973-02cbfb2745bc"
      },
      "execution_count": 381,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cell Number: 43 \n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#f9d4d4>r </text><br><text style=color:#000;background-color:#f9d4d4>r </text><br><text style=color:#000;background-color:#f9bdbd>2 </text><br><text style=color:#000;background-color:#f9bdbd>2 </text><br><text style=color:#000;background-color:#baddee>44 </text><br><text style=color:#000;background-color:#baddee>44 </text><br><text style=color:#000;background-color:#a1d0e8#b2d9ec>2 </text><br><text style=color:#000;background-color:#a1d0e8#b2d9ec>2 </text><br><text style=color:#000;background-color:#89c4e2>3 </text><br><text style=color:#000;background-color:#89c4e2>3 </text><br><text style=color:#000;background-color:#85c2e1>3 </text><br><text style=color:#000;background-color:#85c2e1>3 </text><br><text style=color:#000;background-color:#85c2e1>r </text><br><text style=color:#000;background-color:#85c2e1>r </text><br><text style=color:#000;background-color:#85c2e1>2 </text><br><text style=color:#000;background-color:#85c2e1>2 </text><br><text style=color:#000;background-color:#85c2e1>44 </text><br><text style=color:#000;background-color:#85c2e1>44 </text><br><text style=color:#000;background-color:#85c2e1>2 </text><br><text style=color:#000;background-color:#85c2e1>2 </text><br><text style=color:#000;background-color:#85c2e1>3 </text><br><text style=color:#000;background-color:#85c2e1>3 </text><br><text style=color:#000;background-color:#85c2e1>3 </text><br><text style=color:#000;background-color:#85c2e1>3 </text><br><text style=color:#000;background-color:#85c2e1>r </text><br><text style=color:#000;background-color:#85c2e1>r </text><br><text style=color:#000;background-color:#85c2e1>2 </text><br><text style=color:#000;background-color:#85c2e1>2 </text><br><text style=color:#000;background-color:#85c2e1>44 </text><br><text style=color:#000;background-color:#85c2e1>44 </text><br><text style=color:#000;background-color:#85c2e1>2 </text><br><text style=color:#000;background-color:#85c2e1>2 </text><br><text style=color:#000;background-color:#85c2e1>3 </text><br><text style=color:#000;background-color:#85c2e1>3 </text><br><text style=color:#000;background-color:#85c2e1>3 </text><br><text style=color:#000;background-color:#85c2e1>3 </text><br><text style=color:#000;background-color:#85c2e1>r </text><br><text style=color:#000;background-color:#85c2e1>r </text><br><text style=color:#000;background-color:#85c2e1>2 </text><br><text style=color:#000;background-color:#85c2e1>2 </text><br><text style=color:#000;background-color:#85c2e1>44 </text><br><text style=color:#000;background-color:#85c2e1>44 </text><br><text style=color:#000;background-color:#85c2e1>2 </text><br><text style=color:#000;background-color:#85c2e1>2 </text><br><text style=color:#000;background-color:#85c2e1>3 </text><br><text style=color:#000;background-color:#85c2e1>3 </text><br><text style=color:#000;background-color:#85c2e1>3 </text><br><text style=color:#000;background-color:#85c2e1>3 </text><br><text style=color:#000;background-color:#85c2e1>r </text><br><text style=color:#000;background-color:#85c2e1>r </text><br><text style=color:#000;background-color:#85c2e1>2 </text><br><text style=color:#000;background-color:#85c2e1>2 </text><br><text style=color:#000;background-color:#85c2e1>44 </text><br><text style=color:#000;background-color:#85c2e1>44 </text><br><text style=color:#000;background-color:#85c2e1>2 </text><br><text style=color:#000;background-color:#85c2e1>2 </text><br><text style=color:#000;background-color:#85c2e1>3 </text><br><text style=color:#000;background-color:#85c2e1>3 </text><br><text style=color:#000;background-color:#85c2e1>3 </text><br><text style=color:#000;background-color:#85c2e1>3 </text><br><text style=color:#000;background-color:#85c2e1>r </text><br><text style=color:#000;background-color:#85c2e1>r </text><br><text style=color:#000;background-color:#85c2e1>2 </text><br><text style=color:#000;background-color:#85c2e1>2 </text><br><text style=color:#000;background-color:#85c2e1>44 </text><br><text style=color:#000;background-color:#85c2e1>44 </text><br><text style=color:#000;background-color:#85c2e1>2 </text><br><text style=color:#000;background-color:#85c2e1>2 </text><br><text style=color:#000;background-color:#85c2e1>3 </text><br><text style=color:#000;background-color:#85c2e1>3 </text><br><text style=color:#000;background-color:#85c2e1>3 </text><br><text style=color:#000;background-color:#85c2e1>3 </text><br><text style=color:#000;background-color:#85c2e1>r </text><br><text style=color:#000;background-color:#85c2e1>r </text><br><text style=color:#000;background-color:#85c2e1>2 </text><br><text style=color:#000;background-color:#85c2e1>2 </text><br><text style=color:#000;background-color:#85c2e1>44 </text><br><text style=color:#000;background-color:#85c2e1>44 </text><br><text style=color:#000;background-color:#85c2e1>2 </text><br><text style=color:#000;background-color:#85c2e1>2 </text><br><text style=color:#000;background-color:#85c2e1>3 </text><br><text style=color:#000;background-color:#85c2e1>3 </text><br><text style=color:#000;background-color:#85c2e1>3 </text><br><text style=color:#000;background-color:#85c2e1>3 </text><br><text style=color:#000;background-color:#85c2e1>r </text><br><text style=color:#000;background-color:#85c2e1>r </text><br>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tx[0].rnn_output[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6PIdRXS0NI7",
        "outputId": "2ec03365-202e-46b2-e231-4dd53944dca8"
      },
      "execution_count": 327,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(65,), dtype=float32, numpy=\n",
              "array([9.39975143e-05, 1.19094111e-04, 8.32622027e-06, 7.33076222e-03,\n",
              "       7.03148953e-06, 2.05596723e-02, 7.76925590e-05, 1.24401186e-05,\n",
              "       7.87261888e-06, 1.45139038e-05, 9.34945729e-06, 9.61322621e-06,\n",
              "       1.45605973e-05, 1.11680120e-05, 1.49269317e-05, 9.00633768e-06,\n",
              "       1.29177142e-05, 8.21553823e-03, 1.31760489e-05, 9.70954206e-05,\n",
              "       1.29535392e-05, 1.62258857e-05, 1.68107053e-05, 1.10783658e-05,\n",
              "       5.15205356e-05, 1.29093278e-05, 9.96780454e-06, 5.47792646e-04,\n",
              "       1.02913400e-05, 4.85462479e-05, 1.01602445e-05, 6.35375764e-05,\n",
              "       2.41774437e-03, 3.85047169e-05, 1.26933074e-03, 2.18282212e-02,\n",
              "       4.84381914e-02, 7.71376654e-05, 2.91850753e-02, 6.22322186e-05,\n",
              "       1.92820020e-02, 2.25520525e-02, 7.50554875e-02, 5.44308603e-01,\n",
              "       1.23257516e-04, 1.47117395e-02, 5.13632040e-05, 3.49489492e-05,\n",
              "       1.68809108e-03, 1.59105766e-05, 2.20268757e-05, 1.80076495e-01,\n",
              "       3.34512442e-05, 1.54750251e-05, 1.62275264e-05, 2.06923924e-05,\n",
              "       1.13326696e-05, 8.48267882e-06, 2.97092538e-05, 1.28925822e-05,\n",
              "       7.43998226e-06, 2.64499522e-05, 1.04117971e-05, 1.11005327e-03,\n",
              "       8.47604861e-06], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 327
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_out[0].rnn_output[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOp3_QFWpYHl",
        "outputId": "00cdad3a-f1a2-4974-e0a1-48427cd83eb5"
      },
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([65, 65])"
            ]
          },
          "metadata": {},
          "execution_count": 292
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx_to_word(argmax(sample_out[0].rnn_output[0], axis = -1), reverse_target_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "suHTwYQwppGz",
        "outputId": "9e2cf185-6eb4-43ff-fc54-698cde57fd02"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'रराा\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s2s.encoder.predict(val_enc_input_data[:1])\n",
        "\n",
        "\n",
        "def decode_sequence(inp_seq):\n",
        "  enc_out = s2s.encoder.predict(inp_seq)\n",
        "\n",
        "  target_seq = np.ones((1, num_decoder_tokens))\n",
        "\n",
        "  target_seq[0, 0 ] = target_token[\"\\t\"]\n",
        "  print(target_seq)\n",
        "  stop_condition = False\n",
        "  decoded_sentence = \"\"\n",
        "  while not stop_condition:\n",
        "    s2s.dec.attention_mechanism.setup_memory(enc_out[0])\n",
        "    #dec_initial_state = s2s.dec.build_initial_state(batch_size, tuple(enc_out[2:]), tf.float32)\n",
        "    x = s2s.dec(target_seq,enc_out[1:])\n",
        "    #output_token, h, c = s2s.dec.call(target_seq ,enc_out[1:])\n",
        "decode_sequence(val_enc_input_data[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "eqfEd2N3dzzY",
        "outputId": "dfe9b716-22fd-42b2-868d-d8aaaee29839"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-201-6b46865f3592>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms2s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menc_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#output_token, h, c = s2s.dec.call(target_seq ,enc_out[1:])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_enc_input_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-201-6b46865f3592>\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(inp_seq)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0ms2s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_mechanism\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#dec_initial_state = s2s.dec.build_initial_state(batch_size, tuple(enc_out[2:]), tf.float32)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms2s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menc_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;31m#output_token, h, c = s2s.dec.call(target_seq ,enc_out[1:])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_enc_input_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-f1d51797116e>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, initial_state)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m#print(\"calles\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_addons/seq2seq/decoder.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, initial_state, training, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mdecoder_init_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0mdecoder_init_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         )\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/typeguard/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0mmemo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_CallMemo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_localns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m         \u001b[0mcheck_argument_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m         \u001b[0mcheck_return_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_addons/seq2seq/decoder.py\u001b[0m in \u001b[0;36mdynamic_decode\u001b[0;34m(decoder, output_time_major, impute_finished, maximum_iterations, parallel_iterations, swap_memory, training, scope, enable_tflite_convertible, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m         )\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_addons/seq2seq/decoder.py\u001b[0m in \u001b[0;36mbody\u001b[0;34m(time, outputs_ta, state, inputs, finished, sequence_lengths)\u001b[0m\n\u001b[1;32m    429\u001b[0m             \"\"\"\n\u001b[1;32m    430\u001b[0m             (next_outputs, decoder_state, next_inputs, decoder_finished) = decoder.step(\n\u001b[0;32m--> 431\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m             )\n\u001b[1;32m    433\u001b[0m             \u001b[0mdecoder_state_sequence_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_addons/seq2seq/basic_decoder.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, time, inputs, state, training)\u001b[0m\n\u001b[1;32m    181\u001b[0m           \u001b[0;31m`\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinished\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \"\"\"\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mcell_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0mcell_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_addons/seq2seq/attention_wrapper.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, state, **kwargs)\u001b[0m\n\u001b[1;32m   1992\u001b[0m                     \u001b[0;34m\"Expected state to be instance of AttentionWrapperState or \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1993\u001b[0m                     \u001b[0;34m\"values that can construct AttentionWrapperState. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1994\u001b[0;31m                     \u001b[0;34m\"Received type %s instead.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1995\u001b[0m                 )\n\u001b[1;32m   1996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling layer \"attention_wrapper_4\" (type AttentionWrapper).\n\nExpected state to be instance of AttentionWrapperState or values that can construct AttentionWrapperState. Received type <class 'list'> instead.\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(1, 1024), dtype=float32)\n  • state=[['array([[ 0.889448  ,  0.9820368 , -0.9294946 ,  0.962945  , -0.9833836 ,\\n         0.9407073 , -0.62003136,  0.6466053 ,  0.0925342 , -0.83136547,\\n        -0.88713694, -0.8963272 ,  0.8827079 , -0.9673237 ,  0.53036314,\\n        -0.7544701 ]], dtype=float32)', 'array([[ 2.7038932 ,  9.136703  , -9.010024  ,  4.0533714 , -4.293053  ,\\n         8.52292   , -0.765205  ,  1.4761537 ,  0.12184431, -1.3651901 ,\\n        -8.127819  , -8.002233  ,  7.4236665 , -6.6726084 ,  1.7224821 ,\\n        -3.060453  ]], dtype=float32)']]\n  • kwargs={'training': 'False'}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualise connectivity"
      ],
      "metadata": {
        "id": "LVsewJyaIEFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.backend as K"
      ],
      "metadata": {
        "id": "048Of_YFJ3g7"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_out = s2s.call(val_enc_input_data[:1, val_dec_input_data[:64])"
      ],
      "metadata": {
        "id": "kGGbb4f2Wlq2"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "idx_to_word(val_dec_target_data[21], reverse_target_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "CpYf12svd3uj",
        "outputId": "7d5c1448-aeb7-46a0-c449-5daf7626c505"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'अंधापन\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "argmax(sample_out[0].rnn_output[0], axis = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mESyMaHw9F4X",
        "outputId": "835ad08e-23dd-47c9-922a-7f2a615ae31a"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([38, 43,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1])"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx_to_word(argmax(sample_out[0].rnn_output[21], axis = 1), reverse_target_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "4UgktvLgifMx",
        "outputId": "5e5f3c09-21bd-4340-d9a6-6df02610c5cc"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'भरराराा\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dec_target_data[0]\n",
        " "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlV9bsY5sKlf",
        "outputId": "3a5fee33-ae70-4f92-841e-444a9b74eed1"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 5.,  3., 17.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
              "        1.,  1.,  1.,  1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx_to_word(val_enc_input_data[0], reverse_input_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "82J9q355hrjs",
        "outputId": "4a8d2a02-9a9e-4b6b-c87a-d761cbdc88ad"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ankaaaaaaaaaaaaa'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_enc_input_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wU_SPa1qakeS",
        "outputId": "3b0f6b14-5192-493b-c4e9-0c1caa2fb6b2"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0., 13., 10.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "        0.,  0.,  0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s2s.encoder(val_enc_input_data[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hVQhIdJYEzM",
        "outputId": "2bde1fcf-0375-416d-b704-c23eecfd6651"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(1, 16, 16), dtype=float32, numpy=\n",
              " array([[[-0.27636853,  0.33281827, -0.03984123, -0.00467285,\n",
              "           0.18777025, -0.19771865, -0.3986882 , -0.7185621 ,\n",
              "           0.7134209 ,  0.10922858,  0.55633354,  0.08733544,\n",
              "          -0.4685068 , -0.02432256,  0.3997748 ,  0.07012274],\n",
              "         [-0.83587945,  0.73991835,  0.11614553,  0.73127866,\n",
              "           0.58252615, -0.5517096 , -0.35802874, -0.5785101 ,\n",
              "          -0.63424855,  0.8241316 , -0.4804708 ,  0.73157483,\n",
              "           0.2934353 , -0.6375461 ,  0.75951517,  0.7579167 ],\n",
              "         [ 0.29191756,  0.8620113 ,  0.6478494 ,  0.8562199 ,\n",
              "           0.6973058 ,  0.01579316, -0.60925883, -0.7312868 ,\n",
              "           0.7003064 ,  0.5895543 , -0.7643195 , -0.56934243,\n",
              "           0.72889125, -0.923089  , -0.34866062,  0.8789022 ],\n",
              "         [-0.1521406 ,  0.7893863 ,  0.38588107,  0.46594876,\n",
              "           0.61778194,  0.38039958, -0.57790834, -0.71610993,\n",
              "           0.7408081 ,  0.47149193,  0.5830301 ,  0.32981083,\n",
              "          -0.65062565, -0.9573035 ,  0.6717144 ,  0.5396252 ],\n",
              "         [-0.5465814 ,  0.86045104,  0.35793364,  0.73375994,\n",
              "           0.7454285 ,  0.52303994, -0.49433404, -0.85436904,\n",
              "           0.83125526,  0.02300029,  0.8689016 ,  0.3551489 ,\n",
              "          -0.33579335, -0.9554038 ,  0.5929108 ,  0.34621066],\n",
              "         [-0.55821747,  0.8580467 ,  0.32968166,  0.6833153 ,\n",
              "           0.7037918 ,  0.6345963 , -0.24890366, -0.8334821 ,\n",
              "           0.847001  , -0.12197903,  0.92374516,  0.5596041 ,\n",
              "          -0.07313406, -0.94634074,  0.6495899 ,  0.05702863],\n",
              "         [-0.48515457,  0.8351927 ,  0.26936182,  0.6096762 ,\n",
              "           0.6908983 ,  0.7180035 , -0.02717104, -0.8075319 ,\n",
              "           0.87261367, -0.17083706,  0.9432415 ,  0.62574667,\n",
              "          -0.07904097, -0.9248461 ,  0.69045234, -0.14940424],\n",
              "         [-0.4429919 ,  0.7937542 ,  0.21972938,  0.570455  ,\n",
              "           0.6987913 ,  0.7739649 ,  0.13823529, -0.80800486,\n",
              "           0.9032369 , -0.15585463,  0.9573021 ,  0.6149105 ,\n",
              "          -0.08813273, -0.8899851 ,  0.71616673, -0.28571245],\n",
              "         [-0.42166033,  0.7218892 ,  0.18332507,  0.5523657 ,\n",
              "           0.7116201 ,  0.8051315 ,  0.25159803, -0.8146123 ,\n",
              "           0.92833936, -0.1392601 ,  0.96839535,  0.58903974,\n",
              "          -0.07384375, -0.84710485,  0.73417395, -0.3713165 ],\n",
              "         [-0.40708393,  0.6172061 ,  0.15938579,  0.5359737 ,\n",
              "           0.7199484 ,  0.82242656,  0.33420292, -0.82048553,\n",
              "           0.9466509 , -0.12746331,  0.9762319 ,  0.56836927,\n",
              "          -0.04108934, -0.7974052 ,  0.74816453, -0.42472062],\n",
              "         [-0.3957811 ,  0.4849048 ,  0.14277548,  0.515264  ,\n",
              "           0.7218005 ,  0.8317298 ,  0.40053517, -0.82567644,\n",
              "           0.95983154, -0.11824133,  0.98156255,  0.55287087,\n",
              "           0.00804854, -0.7381564 ,  0.76068044, -0.45745236],\n",
              "         [-0.3865252 ,  0.33529735,  0.12978916,  0.48885423,\n",
              "           0.7173348 ,  0.8349986 ,  0.45790336, -0.83078575,\n",
              "           0.9693554 , -0.11037215,  0.98518157,  0.53921735,\n",
              "           0.07088815, -0.66672623,  0.7727083 , -0.47560692],\n",
              "         [-0.3786828 ,  0.1810395 ,  0.11849951,  0.45649856,\n",
              "           0.7070219 ,  0.8327776 ,  0.5087994 , -0.83613664,\n",
              "           0.976243  , -0.10344035,  0.98760873,  0.5243175 ,\n",
              "           0.14193048, -0.5835925 ,  0.7842113 , -0.48202354],\n",
              "         [-0.37228063,  0.03443789,  0.10820368,  0.41890028,\n",
              "           0.69163424,  0.8253118 ,  0.55265415, -0.84194803,\n",
              "           0.98119634, -0.09724947,  0.98915887,  0.50605565,\n",
              "           0.21431231, -0.49366933,  0.79455894, -0.4780067 ],\n",
              "         [-0.36774746, -0.0944861 ,  0.09895041,  0.37772965,\n",
              "           0.6725403 ,  0.81302863,  0.587441  , -0.8482818 ,\n",
              "           0.9847106 , -0.09170865,  0.99003905,  0.48399073,\n",
              "           0.28218102, -0.40511185,  0.80300486, -0.4648853 ],\n",
              "         [-0.36544824, -0.19906135,  0.09106166,  0.33533457,\n",
              "           0.6517816 ,  0.7966775 ,  0.61108136, -0.85491174,\n",
              "           0.98714733, -0.08681165,  0.99041134,  0.45947564,\n",
              "           0.34183112, -0.32578483,  0.80914384, -0.44517463]]],\n",
              "       dtype=float32)>, [<tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n",
              "  array([[-0.36544824, -0.19906135,  0.09106166,  0.33533457,  0.6517816 ,\n",
              "           0.7966775 ,  0.61108136, -0.85491174,  0.98714733, -0.08681165,\n",
              "           0.99041134,  0.45947564,  0.34183112, -0.32578483,  0.80914384,\n",
              "          -0.44517463]], dtype=float32)>,\n",
              "  <tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n",
              "  array([[-0.3865216 , -0.20516595,  1.0877342 ,  0.9449842 ,  1.2137372 ,\n",
              "           1.7455283 ,  0.75206435, -1.2842455 ,  2.5676017 , -1.550819  ,\n",
              "           2.9597306 ,  2.5009162 ,  0.4558264 , -0.82200843,  1.7090622 ,\n",
              "          -0.74601793]], dtype=float32)>]]"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def past_connection(model, word):\n",
        "  sample_out = s2s.call(val_enc_input_data[:64], val_dec_input_data[:64])\n",
        "  sample\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNNJizwwKjcV",
        "outputId": "9edaf795-7cc8-47cc-8f7b-3c4743c435ab"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.seq2seq at 0x7f36dabecc10>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_out[0]"
      ],
      "metadata": {
        "id": "hKdlHnyqe6K-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cells = s2s.output\n",
        "\n",
        "attn_func = K.function(inputs = [val_dec_input_data[:64], sample_out[0].rnn_output, K.learning_phase()],\n",
        "           outputs = [cells.output]\n",
        "          )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "MLfwVosWILPk",
        "outputId": "474e1866-25ae-4ec4-cc7a-e3047a95d784"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-cd16f568e985>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcells\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms2s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m attn_func = K.function(inputs = [val_dec_input_data[:64], sample_out[0].rnn_output, K.learning_phase()],\n\u001b[1;32m      4\u001b[0m            \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcells\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'seq2seq' object has no attribute 'output'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s2s."
      ],
      "metadata": {
        "id": "_bzS9tj9H33l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(seq):\n",
        "  sentence = [] \n",
        "  for x in seq:\n",
        "    char =reverse_input_token[x]\n",
        "    sentence.append(char)\n",
        "  return \"\".join(sentence)\n",
        "\n",
        "sample_out[0]\n",
        "#translate(argmax(sample_out[0].rnn_output[-1], axis =1))\n",
        "translate(val_enc_input_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xgrOWGiYBm5n",
        "outputId": "cea1fe40-203e-4f84-e042-ed86a0e0448e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ankaaaaaaaaaaaaa'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "argmax(sample_out[0].rnn_output[25], axis =1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKkMHEo2Im7X",
        "outputId": "cf2e7333-7ddd-4a50-d460-a13abadbc54c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17,)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_sentence(sentence):\n",
        "  #sentence = dataset_creator.preprocess_sentence(sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                          maxlen=max_length_input,\n",
        "                                                          padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "  inference_batch_size = inputs.shape[0]\n",
        "  result = ''\n",
        "\n",
        "  enc_start_state = [tf.zeros((inference_batch_size, units)), tf.zeros((inference_batch_size,units))]\n",
        "  enc_out, enc_h, enc_c = encoder(inputs, enc_start_state)\n",
        "\n",
        "  dec_h = enc_h\n",
        "  dec_c = enc_c\n",
        "\n",
        "  start_tokens = tf.fill([inference_batch_size], targ_lang.word_index['<start>'])\n",
        "  end_token = targ_lang.word_index['<end>']\n",
        "\n",
        "  greedy_sampler = tfa.seq2seq.GreedyEmbeddingSampler()\n",
        "\n",
        "  # Instantiate BasicDecoder object\n",
        "  decoder_instance = tfa.seq2seq.BasicDecoder(cell=decoder.rnn_cell, sampler=greedy_sampler, output_layer=decoder.fc)\n",
        "  # Setup Memory in decoder stack\n",
        "  decoder.attention_mechanism.setup_memory(enc_out)\n",
        "\n",
        "  # set decoder_initial_state\n",
        "  decoder_initial_state = decoder.build_initial_state(inference_batch_size, [enc_h, enc_c], tf.float32)\n",
        "\n",
        "\n",
        "  ### Since the BasicDecoder wraps around Decoder's rnn cell only, you have to ensure that the inputs to BasicDecoder \n",
        "  ### decoding step is output of embedding layer. tfa.seq2seq.GreedyEmbeddingSampler() takes care of this. \n",
        "  ### You only need to get the weights of embedding layer, which can be done by decoder.embedding.variables[0] and pass this callabble to BasicDecoder's call() function\n",
        "\n",
        "  decoder_embedding_matrix = decoder.embedding.variables[0]\n",
        "  \n",
        "  outputs, _, _ = decoder_instance(decoder_embedding_matrix, start_tokens = start_tokens, end_token= end_token, initial_state=decoder_initial_state)\n",
        "  return outputs.sample_id.numpy()\n",
        "\n",
        "def translate(sentence):\n",
        "  result = evaluate_sentence(sentence)\n",
        "  print(result)\n",
        "  result = targ_lang.sequences_to_texts(result)\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))"
      ],
      "metadata": {
        "id": "i9XBf8WUBNrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "status=checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "status??"
      ],
      "metadata": {
        "id": "DZogyF7dBR8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s2s.encoder.variables"
      ],
      "metadata": {
        "id": "3jFijxIbEdVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translate(u'hace mucho frio aqui.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "1hxPV2prBUxv",
        "outputId": "9eba2fba-46a7-46e6-93a6-fe953093a007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-a7e085e16f9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'hace mucho frio aqui.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-81-734761cec068>\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarg_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences_to_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-81-734761cec068>\u001b[0m in \u001b[0;36mevaluate_sentence\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;31m#sentence = dataset_creator.preprocess_sentence(sentence)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minp_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n\u001b[1;32m      6\u001b[0m                                                           \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-81-734761cec068>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;31m#sentence = dataset_creator.preprocess_sentence(sentence)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minp_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n\u001b[1;32m      6\u001b[0m                                                           \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'inp_lang' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def beam_evaluate_sentence(sentence, beam_width=3):\n",
        "  sentence = dataset_creator.preprocess_sentence(sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                          maxlen=max_length_input,\n",
        "                                                          padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "  inference_batch_size = inputs.shape[0]\n",
        "  result = ''\n",
        "\n",
        "  enc_start_state = [tf.zeros((inference_batch_size, units)), tf.zeros((inference_batch_size,units))]\n",
        "  enc_out, enc_h, enc_c = encoder(inputs, enc_start_state)\n",
        "\n",
        "  dec_h = enc_h\n",
        "  dec_c = enc_c\n",
        "\n",
        "  start_tokens = tf.fill([inference_batch_size], targ_lang.word_index['<start>'])\n",
        "  end_token = targ_lang.word_index['<end>']\n",
        "\n",
        "  # From official documentation\n",
        "  # NOTE If you are using the BeamSearchDecoder with a cell wrapped in AttentionWrapper, then you must ensure that:\n",
        "  # The encoder output has been tiled to beam_width via tfa.seq2seq.tile_batch (NOT tf.tile).\n",
        "  # The batch_size argument passed to the get_initial_state method of this wrapper is equal to true_batch_size * beam_width.\n",
        "  # The initial state created with get_initial_state above contains a cell_state value containing properly tiled final state from the encoder.\n",
        "\n",
        "  enc_out = tfa.seq2seq.tile_batch(enc_out, multiplier=beam_width)\n",
        "  decoder.attention_mechanism.setup_memory(enc_out)\n",
        "  print(\"beam_with * [batch_size, max_length_input, rnn_units] :  3 * [1, 16, 1024]] :\", enc_out.shape)\n",
        "\n",
        "  # set decoder_inital_state which is an AttentionWrapperState considering beam_width\n",
        "  hidden_state = tfa.seq2seq.tile_batch([enc_h, enc_c], multiplier=beam_width)\n",
        "  decoder_initial_state = decoder.rnn_cell.get_initial_state(batch_size=beam_width*inference_batch_size, dtype=tf.float32)\n",
        "  decoder_initial_state = decoder_initial_state.clone(cell_state=hidden_state)\n",
        "\n",
        "  # Instantiate BeamSearchDecoder\n",
        "  decoder_instance = tfa.seq2seq.BeamSearchDecoder(decoder.rnn_cell,beam_width=beam_width, output_layer=decoder.fc)\n",
        "  decoder_embedding_matrix = decoder.embedding.variables[0]\n",
        "\n",
        "  # The BeamSearchDecoder object's call() function takes care of everything.\n",
        "  outputs, final_state, sequence_lengths = decoder_instance(decoder_embedding_matrix, start_tokens=start_tokens, end_token=end_token, initial_state=decoder_initial_state)\n",
        "  # outputs is tfa.seq2seq.FinalBeamSearchDecoderOutput object. \n",
        "  # The final beam predictions are stored in outputs.predicted_id\n",
        "  # outputs.beam_search_decoder_output is a tfa.seq2seq.BeamSearchDecoderOutput object which keep tracks of beam_scores and parent_ids while performing a beam decoding step\n",
        "  # final_state = tfa.seq2seq.BeamSearchDecoderState object.\n",
        "  # Sequence Length = [inference_batch_size, beam_width] details the maximum length of the beams that are generated\n",
        "\n",
        "  \n",
        "  # outputs.predicted_id.shape = (inference_batch_size, time_step_outputs, beam_width)\n",
        "  # outputs.beam_search_decoder_output.scores.shape = (inference_batch_size, time_step_outputs, beam_width)\n",
        "  # Convert the shape of outputs and beam_scores to (inference_batch_size, beam_width, time_step_outputs)\n",
        "  final_outputs = tf.transpose(outputs.predicted_ids, perm=(0,2,1))\n",
        "  beam_scores = tf.transpose(outputs.beam_search_decoder_output.scores, perm=(0,2,1))\n",
        "  \n",
        "  return final_outputs.numpy(), beam_scores.numpy()"
      ],
      "metadata": {
        "id": "dismVFzoA2Pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def beam_translate(sentence):\n",
        "  result, beam_scores = beam_evaluate_sentence(sentence)\n",
        "  print(result.shape, beam_scores.shape)\n",
        "  for beam, score in zip(result, beam_scores):\n",
        "    print(beam.shape, score.shape)\n",
        "    output = targ_lang.sequences_to_texts(beam)\n",
        "    output = [a[:a.index('<end>')] for a in output]\n",
        "    beam_score = [a.sum() for a in score]\n",
        "    print('Input: %s' % (sentence))\n",
        "    for i in range(len(output)):\n",
        "      print('{} Predicted translation: {}  {}'.format(i+1, output[i], beam_score[i]))\n"
      ],
      "metadata": {
        "id": "YREHt6RDA6LA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beam_translate(u'hace mucho frio aqui.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "NMUInU7cA8Ms",
        "outputId": "afe75ade-7b9e-4411-fec2-e87123420d2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-4f791c530881>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbeam_translate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'hace mucho frio aqui.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-76-75238b01e5f9>\u001b[0m in \u001b[0;36mbeam_translate\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbeam_translate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeam_evaluate_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mbeam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-75-5584425e1250>\u001b[0m in \u001b[0;36mbeam_evaluate_sentence\u001b[0;34m(sentence, beam_width)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbeam_evaluate_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minp_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dataset_creator' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_enc_input_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-wA0D4dX2t4",
        "outputId": "722a2932-202c-4ab3-867e-66cf6832e304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0., 13., 10.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "        0.,  0.,  0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dec_input_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQOKJ5t2XxOr",
        "outputId": "f0ba6934-b2c2-4f0b-8f50-ebb4d17d46a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4502, 17)"
            ]
          },
          "metadata": {},
          "execution_count": 280
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dec_target_data[110]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HDvOkuGWkWB",
        "outputId": "dac5d6d6-afba-4c40-8124-560f0cfa7cdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 5., 36., 63., 42., 51., 42.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "        0.,  0.,  0.,  0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 268
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_out = s2s.call(val_enc_input_data[:64], val_dec_input_data[:64])"
      ],
      "metadata": {
        "id": "QImBhPbTV9OG"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.dot(1,np.equal(val_dec_target_data[0][:3], np.argmax(sample_out[0].rnn_output[0][:3], axis =1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-e_OlFyHbqkM",
        "outputId": "94c85d7b-d61f-4e8f-c4b4-c1629b404c59"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "argmax(sample_out[0].rnn_output[0], axis =1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VS5o8Whhmf6n",
        "outputId": "ddc4c6d9-432b-4ab7-ab21-0c786294545b"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([45,  3, 17, 51, 51, 51, 51, 51, 36, 51, 51, 51, 51, 51, 51, 51, 51])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dec_target_data[0][:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxvkjOlObMrK",
        "outputId": "b54a4b1c-cefc-4924-8082-30f5d7cecd75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4.,  2., 10.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_target[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "f8e2y3aAbo69",
        "outputId": "54e8f2b6-1444-41c6-82ba-4b8e08e97819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\tअंक\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_token"
      ],
      "metadata": {
        "id": "FgavI_web2HG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "m.update_state(val_dec_target_data[0], sample_out[0].rnn_output[0][:3])\n",
        "m.result().numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdmMny5tcgsk",
        "outputId": "13531154-fde4-463f-d351-779da7e42345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.14285715"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.where(val_dec_target_data[0] == 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlSvaPXRg6eq",
        "outputId": "71fe8e85-c003-4937-b33e-e8b302f81563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([3]),)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip(val_dec_target_data, sample_out[0].rnn_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4t5mn2ff9fn",
        "outputId": "7c43a97a-dbe0-48c2-bbd7-064332ff864a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<zip at 0x7f65f3eed8c0>"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function(val_dec_input_data[:64], sample_out[0].rnn_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNf_vGipbGDC",
        "outputId": "16d4ebbd-4c0c-4512-b94a-75d5ce403a9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=1.6536412>"
            ]
          },
          "metadata": {},
          "execution_count": 294
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "step_per_val_epoch  = len(validation_input)//batch_size\n",
        "m.update_state(val_dec_input_data[:64], sample_out[0].rnn_output)/step_per_val_epoch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnWZHZ3LcjuK",
        "outputId": "98642f71-b68d-4383-ead7-3ed727c7df59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=15.542857>"
            ]
          },
          "metadata": {},
          "execution_count": 313
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " dec_input_data[0]"
      ],
      "metadata": {
        "id": "whKn8yCHhJqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = list(val_dataset)[:2]\n",
        "x, y , z = t[0][0], t[0][1], t[1]"
      ],
      "metadata": {
        "id": "IjsQSX3ICgBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for val in t:\n",
        "  enc_inp\n",
        "  print(len(val[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mh3Use5VC0lz",
        "outputId": "a02d59e5-698d-49ca-f0d6-04ef44cd57fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "loss = cross_entropy(y_true=dec_target_data[:64], y_pred=sample_out[0].rnn_output)\n",
        "loss"
      ],
      "metadata": {
        "id": "Xd7eP7r0gNsA",
        "outputId": "bedc2e89-acdb-4272-8b64-67579ed11384",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64, 21), dtype=float32, numpy=\n",
              "array([[4.1747932, 4.1745915, 4.174487 , ..., 4.174175 , 4.174177 ,\n",
              "        4.17418  ],\n",
              "       [4.174734 , 4.174542 , 4.1742854, ..., 4.1741757, 4.174185 ,\n",
              "        4.1741924],\n",
              "       [4.174767 , 4.1745205, 4.1742883, ..., 4.174209 , 4.174211 ,\n",
              "        4.174213 ],\n",
              "       ...,\n",
              "       [4.1746445, 4.1743155, 4.174321 , ..., 4.1742435, 4.174258 ,\n",
              "        4.1742716],\n",
              "       [4.174657 , 4.174332 , 4.1743355, ..., 4.174272 , 4.174281 ,\n",
              "        4.1742883],\n",
              "       [4.174667 , 4.1743417, 4.174344 , ..., 4.1742654, 4.174274 ,\n",
              "        4.1742816]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in val_dataset:\n",
        "  print(x.shape,y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "n8CBRHqXBFFh",
        "outputId": "e3cf1a01-25a0-4f30-86d2-a12aac96a9ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-130-2e08bd4c0a6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x,y=val_dataset.take(1)"
      ],
      "metadata": {
        "id": "N7kEoVlWRqvB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "outputId": "62b45a85-7db9-40c9-a303-ce8f9d43d6df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-123-82d83064c036>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(val_dataset.range(1))\n"
      ],
      "metadata": {
        "id": "0_7v0t5_TsLX",
        "outputId": "e4b2e112-2e42-4550-f5a1-9e7769a97b97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<RangeDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "s2s.predict([val_enc_input_data,val_dec_input_data])"
      ],
      "metadata": {
        "id": "rspjiEnida96",
        "outputId": "7bcbea59-7118-4ab0-a7f0-1ae9ff60d9b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-153-3fb2d9bdfc29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms2s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_enc_input_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_dec_input_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_check_call_args\u001b[0;34m(self, method_name)\u001b[0m\n\u001b[1;32m   2951\u001b[0m       \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpositional_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2952\u001b[0m       raise ValueError(\n\u001b[0;32m-> 2953\u001b[0;31m           \u001b[0;34mf'Models passed to `{method_name}` can only have `training` '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2954\u001b[0m           \u001b[0;34m'and the first argument in `call()` as positional arguments, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2955\u001b[0m           f'found: {extra_args}.')\n",
            "\u001b[0;31mValueError\u001b[0m: Models passed to `predict` can only have `training` and the first argument in `call()` as positional arguments, found: ['dec_inp']."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s2s.compile(\n",
        "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[tf.keras.metrics.CategoricalAccuracy(name='acc')]\n",
        ")\n",
        "input_data = tf.data.Dataset.from_tensor_slices((enc_input_data, dec_input_data))\n",
        "target_data =  tf.data.Dataset.from_tensor_slices(dec_target_data)\n",
        "train_dataset  = tf.data.Dataset.zip((input_data, target_data)).batch(batch_size)\n",
        "#s2s.summary()\n",
        "s2s.fit(\n",
        "    train_dataset,\n",
        "    batch_size=64,\n",
        "    epochs=1,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "qK-34q8xNQi_",
        "outputId": "38b5c0d0-2dde-4c04-f009-fd524fbe8e12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-46072227eb7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/integration/keras/keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_check_call_args\u001b[0;34m(self, method_name)\u001b[0m\n\u001b[1;32m   2951\u001b[0m       \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpositional_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2952\u001b[0m       raise ValueError(\n\u001b[0;32m-> 2953\u001b[0;31m           \u001b[0;34mf'Models passed to `{method_name}` can only have `training` '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2954\u001b[0m           \u001b[0;34m'and the first argument in `call()` as positional arguments, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2955\u001b[0m           f'found: {extra_args}.')\n",
            "\u001b[0;31mValueError\u001b[0m: Models passed to `fit` can only have `training` and the first argument in `call()` as positional arguments, found: ['dec_inp']."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Seq2seq(tf.keras.Model):\n",
        "  def __init__(self, num_encoder_tokens, num_decoder_tokens,embedding_dim,num_of_layers,unit_type, dropout , recurrent_dropout):\n",
        "    super().__init__()\n",
        "    self.encoder_inputs = Input(shape = (None,), name = \"Input_layer_1\")\n",
        "    self.decoder_inputs = keras.Input(shape=(None,), name = \"Input_layer_2\")\n",
        "    self.num_encoder_tokens = num_encoder_tokens\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.dropout = dropout\n",
        "    self.recurrent_dropout = recurrent_dropout\n",
        "    self.num_decoder_tokens = num_decoder_tokens\n",
        "    self.num_of_encoder_layer  =num_of_layers\n",
        "    self.num_of_decoder_layer =num_of_layers\n",
        "    self.type_encoder_unit =unit_type \n",
        "    self.type_decoder_unit =unit_type\n",
        "    self.train_step()\n",
        "    self.build_model()\n",
        "\n",
        "  def get_embedding_layer(self, num_encoder_tokens, embedding_dim,  name):\n",
        "    return Embedding(num_encoder_tokens, embedding_dim, mask_zero = True, name =name )\n",
        "\n",
        "  def get_cell(self, cell_type = \"lstm\", num_of_cell = 1, name = None):\n",
        "    #print(cell_type)\n",
        "    if cell_type == \"lstm\":\n",
        "      return LSTMCell(num_of_cell, dropout = self.dropout, recurrent_dropout = self.recurrent_dropout, )\n",
        "    elif cell_type == \"rnn\":\n",
        "      return SimpleRNNCell(num_of_cell, dropout = self.dropout, recurrent_dropout = self.recurrent_dropout)\n",
        "    elif cell_type ==\"gru\":\n",
        "      return GRUCell(num_of_cell, dropout = self.dropout, recurrent_dropout = self.recurrent_dropout)\n",
        "    else:\n",
        "      print(f\"Invalid cell type: {cell_type}\")\n",
        "  def get_encoder(self,latent_dim, cell_type = \"lstm\", num_of_layer = 1, name = None ):\n",
        "    return tf.keras.layers.RNN(tf.keras.layers.StackedRNNCells( [self.get_cell(cell_type, latent_dim) for i in range(num_of_layer)],), return_sequences=True, return_state=True, name = name)\n",
        "\n",
        "  def get_decoder(self,latent_dim ,cell_type = \"lstm\", num_of_layer = 1, name = None ):\n",
        "    return tf.keras.layers.RNN(tf.keras.layers.StackedRNNCells( [self.get_cell(cell_type, latent_dim,) for i in range(num_of_layer)]), return_sequences=True, return_state=True)\n",
        "\n",
        "  def get_dense_layer(self, num_decoder_token, activation = \"softmax\"):\n",
        "    return Dense(num_decoder_tokens, activation= activation)\n",
        "\n",
        "  def train_step(self):\n",
        "    self.embedding_layer = self.get_embedding_layer( self.num_encoder_tokens, self.embedding_dim ,name = \"encoder_embedding\")\n",
        "    self.embedding_results = self.embedding_layer(self.encoder_inputs)\n",
        "    print(self.embedding_results.shape)\n",
        "    self.encoder = self.get_encoder( self.embedding_dim,self.type_encoder_unit, self.num_of_encoder_layer , name =\"encoder\" )\n",
        "    encoder_results = self.encoder(self.embedding_results)\n",
        "\n",
        "    self.encoder_outputs, self.encoder_states = encoder_results[0], encoder_results[1:]\n",
        "\n",
        "    self.embedding_layer2 = self.get_embedding_layer( self.num_decoder_tokens, self.embedding_dim, name = \"decoder_embedding\")\n",
        "    self.embedding_results2 = self.embedding_layer2(self.decoder_inputs,)\n",
        "\n",
        "    self.decoder = self.get_decoder( self.embedding_dim, self.type_decoder_unit, self.num_of_decoder_layer,)\n",
        "    self.decoder_results = self.decoder(self.embedding_results2, initial_state=self.encoder_states)\n",
        "\n",
        "    self.decoder_output = self.decoder_results[0]\n",
        "    self.decoder_dense = self.get_dense_layer(self.num_decoder_tokens)\n",
        "    self.dense_output = self.decoder_dense(self.decoder_output)\n",
        "\n",
        "  def build_model(self):\n",
        "    \n",
        "    self.model = keras.Model([self.encoder_inputs, self.decoder_inputs], self.dense_output, name = \"Seq2Seq_model\")\n",
        "    return self.model\n",
        "\n"
      ],
      "metadata": {
        "id": "x9fpzXhN7DMU",
        "execution": {
          "iopub.status.busy": "2022-06-19T14:57:09.043044Z",
          "iopub.execute_input": "2022-06-19T14:57:09.043462Z",
          "iopub.status.idle": "2022-06-19T14:57:09.068515Z",
          "shell.execute_reply.started": "2022-06-19T14:57:09.043428Z",
          "shell.execute_reply": "2022-06-19T14:57:09.067563Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "seq2seq = Seq2seq(num_encoder_tokens,num_decoder_tokens, 1024,1,\"rnn\", 0.0, 0.0).build_model()\n",
        "seq2seq.summary()"
      ],
      "metadata": {
        "id": "qJ07iEXsJr6K",
        "outputId": "f82e8d28-64d7-4a30-9437-d3dbaba684b5",
        "execution": {
          "iopub.status.busy": "2022-06-19T14:59:22.231672Z",
          "iopub.execute_input": "2022-06-19T14:59:22.232141Z",
          "iopub.status.idle": "2022-06-19T14:59:22.718772Z",
          "shell.execute_reply.started": "2022-06-19T14:59:22.232106Z",
          "shell.execute_reply": "2022-06-19T14:59:22.717672Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, None, 1024)\n",
            "Model: \"Seq2Seq_model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " Input_layer_1 (InputLayer)     [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " Input_layer_2 (InputLayer)     [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " encoder_embedding (Embedding)  (None, None, 1024)   26624       ['Input_layer_1[0][0]']          \n",
            "                                                                                                  \n",
            " decoder_embedding (Embedding)  (None, None, 1024)   66560       ['Input_layer_2[0][0]']          \n",
            "                                                                                                  \n",
            " encoder (RNN)                  [(None, None, 1024)  2098176     ['encoder_embedding[0][0]']      \n",
            "                                , (None, 1024)]                                                   \n",
            "                                                                                                  \n",
            " rnn (RNN)                      [(None, None, 1024)  2098176     ['decoder_embedding[0][0]',      \n",
            "                                , (None, 1024)]                   'encoder[0][1]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 65)     66625       ['rnn[0][0]']                    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,356,161\n",
            "Trainable params: 4,356,161\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model\n"
      ],
      "metadata": {
        "id": "HXZ2_xdsAQee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s2s.compile(\n",
        "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[tf.keras.metrics.CategoricalAccuracy(name='acc')]\n",
        ")\n",
        "\n",
        "s2s.fit(\n",
        "    [enc_input_data, dec_input_data],\n",
        "    dec_target_data,\n",
        "    batch_size=64,\n",
        "    epochs=1,\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-19T14:21:19.177217Z",
          "iopub.execute_input": "2022-06-19T14:21:19.177828Z",
          "iopub.status.idle": "2022-06-19T14:21:19.197353Z",
          "shell.execute_reply.started": "2022-06-19T14:21:19.177762Z",
          "shell.execute_reply": "2022-06-19T14:21:19.196282Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "Haec2CJvrP32",
        "outputId": "3f520910-41d6-464c-bbb4-6ebef57a7b5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-4e8aeed0a64f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdec_target_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/integration/keras/keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_check_call_args\u001b[0;34m(self, method_name)\u001b[0m\n\u001b[1;32m   2951\u001b[0m       \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpositional_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2952\u001b[0m       raise ValueError(\n\u001b[0;32m-> 2953\u001b[0;31m           \u001b[0;34mf'Models passed to `{method_name}` can only have `training` '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2954\u001b[0m           \u001b[0;34m'and the first argument in `call()` as positional arguments, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2955\u001b[0m           f'found: {extra_args}.')\n",
            "\u001b[0;31mValueError\u001b[0m: Models passed to `fit` can only have `training` and the first argument in `call()` as positional arguments, found: ['dec_inp']."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BeamSearch(keras.callbacks.Callback):\n",
        "\n",
        "  def __init__(self, beam_size):\n",
        "    self.beam_size = beam_size\n",
        "\n",
        "  def beam_search_decoder(aelf, data, k):\n",
        "    sequences = [[list(), 0.0]]\n",
        "    # walk over each step in sequence\n",
        "    for row in data:\n",
        "      all_candidates = list()\n",
        "      # expand each current candidate\n",
        "      for i in range(len(sequences)):\n",
        "        seq, score = sequences[i]\n",
        "        for j in range(len(row)):\n",
        "          candidate = [seq + [j], score - log(row[j])]\n",
        "          all_candidates.append(candidate)\n",
        "      # order all candidates by score\n",
        "      ordered = sorted(all_candidates, key=lambda tup:tup[1])\n",
        "      # select k best\n",
        "      sequences = ordered[:k]\n",
        "    return sequences\n",
        "  \n",
        "  def on_epoch_end(self, epoch, logs = None):\n",
        "    prediction = self.model.predict([val_enc_input_data , val_dec_input_data])\n",
        "    print(prediction.shape)\n",
        "    for i, pred in enumerate(prediction):\n",
        "      beam_search_prediction = self.beam_search_decoder(pred, self.beam_size)\n",
        "      correct_prediction = 0\n",
        "      for k in range(self.beam_size):\n",
        "        #translated_word = \"\\t\"+\"\".join([reverse_target_token[x] for x in beam_search_prediction[k][0][:len(validation_target[i])-1]])\n",
        "        #print(translated_word, validation_target[i])\n",
        "        #print(validation_target[i])\n",
        "        \n",
        "        def idx2char(idx_list):\n",
        "          return \"\".join([reverse_target_token[x] for x in idx_list])\n",
        "\n",
        "        if \"\\t\"+ idx2char(beam_search_prediction[k][0][:len(validation_target[i])-1]) == validation_target[i]:\n",
        "          correct_prediction+=1\n",
        "          break\n",
        "    mul = 10.0**2\n",
        "    logs[\"character_accuracy\"] = ((correct_prediction/prediction.shape[0])*mul)/mul\n",
        "    print(\"- character_accuracy\",logs[\"character_accuracy\"])\n",
        "    #print(f\"Accuracy by Beam Search {correct_prediction/len(validation_target)}\")\n",
        "      # print(len(beam_search_prediction))\n",
        "      # print(beam_search_prediction)\n"
      ],
      "metadata": {
        "id": "KPyDujbe-Brq",
        "execution": {
          "iopub.status.busy": "2022-06-19T15:10:18.730086Z",
          "iopub.execute_input": "2022-06-19T15:10:18.730979Z",
          "iopub.status.idle": "2022-06-19T15:10:18.745337Z",
          "shell.execute_reply.started": "2022-06-19T15:10:18.730935Z",
          "shell.execute_reply": "2022-06-19T15:10:18.744072Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def beam_search_decoder(data, k):\n",
        "    decodedWords = [[list(), 0.0]]\n",
        "    # walk over each step in sequence\n",
        "    for word in data:\n",
        "      candidates = list()\n",
        "      # expand each current candidate\n",
        "      for sequence in decodedWords:\n",
        "        seq, score = sequence\n",
        "        for j in range(len(word)):\n",
        "          candidate = [seq + [j], score - log(word[j])]\n",
        "          candidates.append(candidate)\n",
        "      # order all candidates by score\n",
        "      ordered = sorted(candidates, key=lambda a:a[1])\n",
        "      # select k best\n",
        "      decodedWords = ordered[:k]\n",
        "    return decodedWords\n",
        "  \n",
        "def translate(seq):\n",
        "  sentence = [] \n",
        "  for x in seq:\n",
        "    char = reverse_target_token[x]\n",
        "    sentence.append(char)\n",
        "  return \"\".join(sentence)\n",
        "class WordAccuracyCallback(keras.callbacks.Callback):\n",
        "  def __init__(self,beam_size):\n",
        "    self.beam_size=beam_size\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    pred=self.model.predict([val_enc_input_data , val_dec_input_data])\n",
        "    count=0\n",
        "    for i in range(pred.shape[0]):\n",
        "      pSequences=beam_search_decoder(pred[i],self.beam_size)\n",
        "      for j in range(self.beam_size):\n",
        "        if \"\\t\"+translate(pSequences[j][0][:len(validation_target[i])-1])==validation_target[i]:\n",
        "          count=count+1\n",
        "          break\n",
        "    factor = 10.0 ** 4\n",
        "    logs[\"WordAccuracy\"]=math.trunc((count/pred.shape[0])*factor)/factor\n",
        "    print(\"- wordAccuracy:\",logs[\"WordAccuracy\"])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-19T15:22:20.414711Z",
          "iopub.execute_input": "2022-06-19T15:22:20.415244Z",
          "iopub.status.idle": "2022-06-19T15:22:20.431301Z",
          "shell.execute_reply.started": "2022-06-19T15:22:20.415207Z",
          "shell.execute_reply": "2022-06-19T15:22:20.429988Z"
        },
        "trusted": true,
        "id": "FE8vtOJOrP33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    \n",
        "    'method':'bayes',\n",
        "    'metric': {\n",
        "        'name':'val_accuracy',\n",
        "        'goal':'maximize'\n",
        "    },\n",
        "    'parameters':{\n",
        "    \n",
        "    \"num_of_layer\" : {'values': [1,2,3]},\n",
        "    \"unit_size\": {\"values\":[16,32,64]},\n",
        "    \"unit_type\": {\"values\":[\"lstm\",\"rnn\",\"gru\"]},\n",
        "    \"dropout\": {\"values\": [0.0, 0.2, 0.4]},\n",
        "    'recurrent_dropout':{'values':[0.0,0.3]},\n",
        "    \"beam_size\" : {\"values\":[1,2,3,4]},\n",
        "    \"epochs\":{\"value\":20},  \n",
        "    \"optimizer\":{\"values\": [\"adam\",\"rmsprop\"]}             \n",
        "                   }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "pprint.pprint(sweep_config)"
      ],
      "metadata": {
        "id": "mIW2Ofow5Deo",
        "outputId": "0c99b3cb-eaac-4b1e-acfa-1aff5a6bad9e",
        "execution": {
          "iopub.status.busy": "2022-06-19T14:21:23.223786Z",
          "iopub.execute_input": "2022-06-19T14:21:23.224923Z",
          "iopub.status.idle": "2022-06-19T14:21:23.234457Z",
          "shell.execute_reply.started": "2022-06-19T14:21:23.224875Z",
          "shell.execute_reply": "2022-06-19T14:21:23.233323Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "{'method': 'bayes',\n 'metric': {'goal': 'maximize', 'name': 'val_accuracy'},\n 'parameters': {'beam_size': {'values': [1, 2, 3, 4]},\n                'dropout': {'values': [0.0, 0.2, 0.4]},\n                'epochs': {'value': 20},\n                'num_of_layer': {'values': [1, 2, 3]},\n                'optimizer': {'values': ['adam', 'rmsprop']},\n                'recurrent_dropout': {'values': [0.0, 0.3]},\n                'unit_size': {'values': [16, 32, 64]},\n                'unit_type': {'values': ['lstm', 'rnn', 'gru']}}}\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=\"seq2seq\")"
      ],
      "metadata": {
        "id": "x8YmtLZN_74p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(config = None):\n",
        "  with wandb.init(config=config):\n",
        "    config = wandb.config\n",
        "    #print(config)\n",
        "    seq2seq = Seq2seq(num_encoder_tokens,num_decoder_tokens, config.unit_size, config.num_of_layer,config.unit_type , config.dropout,config.recurrent_dropout).build_model()\n",
        "    seq2seq.compile(optimizer=config.optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\",])\n",
        "    seq2seq.fit(\n",
        "        [encoder_input_data, decoder_input_data],\n",
        "        decoder_target_data,\n",
        "        batch_size=batch_size,\n",
        "        epochs=config.epochs,\n",
        "        validation_data =  ([validation_encoder_input_data , validation_decoder_input_data] ,validation_decoder_target_data),\n",
        "        callbacks = [BeamSearch(config.beam_size), WandbCallback()],verbose = 1, \n",
        "        )\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "wandb.agent(sweep_id, train)"
      ],
      "metadata": {
        "id": "qYv2feSRAzW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq2seq.compile(\n",
        "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[tf.keras.metrics.CategoricalAccuracy(name='acc')]\n",
        ")\n",
        "seq2seq.metrics_names\n",
        "\n"
      ],
      "metadata": {
        "id": "DIrCXZTAGyTL",
        "execution": {
          "iopub.status.busy": "2022-06-19T15:22:24.717670Z",
          "iopub.execute_input": "2022-06-19T15:22:24.718289Z",
          "iopub.status.idle": "2022-06-19T15:22:24.738490Z",
          "shell.execute_reply.started": "2022-06-19T15:22:24.718252Z",
          "shell.execute_reply": "2022-06-19T15:22:24.737389Z"
        },
        "trusted": true,
        "outputId": "0b540428-89cc-4ac6-ed17-8fc3bffafd6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 290,
          "output_type": "execute_result",
          "data": {
            "text/plain": "[]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred=seq2seq.predict([val_enc_input_data , val_dec_input_data])\n",
        "count=0\n",
        "for i in range(pred.shape[0]//400):\n",
        "      pSequences=beam_search_decoder(pred[i],3)\n",
        "      for j in range(3):\n",
        "        print({\"\\t\"+translate(pSequences[j][0][:len(validation_target[i])-1])}, \"original =\", {validation_target[i]} )\n",
        "        if \"\\t\"+translate(pSequences[j][0][:len(validation_target[i])-1])==validation_target[i]:\n",
        "          count=count+1\n",
        "          print(\"yes\")\n",
        "          break\n",
        "factor = 10.0 ** 4\n"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2022-06-19T15:41:09.089308Z",
          "iopub.execute_input": "2022-06-19T15:41:09.089822Z",
          "iopub.status.idle": "2022-06-19T15:41:22.154791Z",
          "shell.execute_reply.started": "2022-06-19T15:41:09.089769Z",
          "shell.execute_reply": "2022-06-19T15:41:22.153760Z"
        },
        "trusted": true,
        "id": "xLTgqB68rP35",
        "outputId": "416e74fe-2665-4117-c579-56eb7c7beade"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "{'\\tकं\\nा'} original = {'\\tअंक\\n'}\n{'\\tवं\\nा'} original = {'\\tअंक\\n'}\n{'\\t्ं\\nा'} original = {'\\tअंक\\n'}\n{'\\tकं\\nा'} original = {'\\tअंक\\n'}\n{'\\tवं\\nा'} original = {'\\tअंक\\n'}\n{'\\t्ं\\nा'} original = {'\\tअंक\\n'}\n{'\\tकन\\n\\n\\n\\n'} original = {'\\tअंकित\\n'}\n{'\\tवन\\n\\n\\n\\n'} original = {'\\tअंकित\\n'}\n{'\\t्न\\n\\n\\n\\n'} original = {'\\tअंकित\\n'}\n{'\\tकन\\n\\n\\n\\n'} original = {'\\tअंकों\\n'}\n{'\\tवन\\n\\n\\n\\n'} original = {'\\tअंकों\\n'}\n{'\\t्न\\n\\n\\n\\n'} original = {'\\tअंकों\\n'}\n{'\\tकन\\n\\n\\n\\n'} original = {'\\tअंकों\\n'}\n{'\\tवन\\n\\n\\n\\n'} original = {'\\tअंकों\\n'}\n{'\\t्न\\n\\n\\n\\n'} original = {'\\tअंकों\\n'}\n{'\\tकन\\n\\n\\n\\n'} original = {'\\tअंकों\\n'}\n{'\\tवन\\n\\n\\n\\n'} original = {'\\tअंकों\\n'}\n{'\\t्न\\n\\n\\n\\n'} original = {'\\tअंकों\\n'}\n{'\\tकन\\n\\n\\n\\n'} original = {'\\tअंकोर\\n'}\n{'\\tवन\\n\\n\\n\\n'} original = {'\\tअंकोर\\n'}\n{'\\t्न\\n\\n\\n\\n'} original = {'\\tअंकोर\\n'}\n{'\\tकन\\n\\n\\n\\n'} original = {'\\tअंकोर\\n'}\n{'\\tवन\\n\\n\\n\\n'} original = {'\\tअंकोर\\n'}\n{'\\t्न\\n\\n\\n\\n'} original = {'\\tअंकोर\\n'}\n{'\\tकन\\n\\n\\n\\n\\n'} original = {'\\tअंगारक\\n'}\n{'\\tवन\\n\\n\\n\\n\\n'} original = {'\\tअंगारक\\n'}\n{'\\t्न\\n\\n\\n\\n\\n'} original = {'\\tअंगारक\\n'}\n{'\\tकन\\n\\n\\n\\n\\n'} original = {'\\tअंगारक\\n'}\n{'\\tवन\\n\\n\\n\\n\\n'} original = {'\\tअंगारक\\n'}\n{'\\t्न\\n\\n\\n\\n\\n'} original = {'\\tअंगारक\\n'}\n{'\\tकर\\n\\n\\n\\n\\n\\n\\n'} original = {'\\tअंग्रज़ी\\n'}\n{'\\tवर\\n\\n\\n\\n\\n\\n\\n'} original = {'\\tअंग्रज़ी\\n'}\n{'\\t्र\\n\\n\\n\\n\\n\\n\\n'} original = {'\\tअंग्रज़ी\\n'}\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = seq2seq.predict([val_enc_input_data , val_dec_input_data])\n",
        "x.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-19T15:33:14.072698Z",
          "iopub.execute_input": "2022-06-19T15:33:14.073169Z",
          "iopub.status.idle": "2022-06-19T15:33:26.484545Z",
          "shell.execute_reply.started": "2022-06-19T15:33:14.073134Z",
          "shell.execute_reply": "2022-06-19T15:33:26.483378Z"
        },
        "trusted": true,
        "id": "qnzLTsbxrP36",
        "outputId": "357821dd-b5f9-4924-add4-0ebd058f94a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 301,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(4502, 17, 65)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "histotry = seq2seq.fit(\n",
        "    [enc_input_data, dec_input_data],\n",
        "    dec_target_data,\n",
        "    batch_size=8192,\n",
        "    epochs=1,\n",
        "    callbacks = [WordAccuracyCallback(3), ],\n",
        ")\n",
        "# Save model\n",
        "seq2seq.save(\"s2s\")\n"
      ],
      "metadata": {
        "id": "ox_fyYUrAQef",
        "outputId": "f4da868c-355c-4132-8481-e4ffcb605de4",
        "execution": {
          "iopub.status.busy": "2022-06-19T15:22:25.394757Z",
          "iopub.execute_input": "2022-06-19T15:22:25.395410Z",
          "iopub.status.idle": "2022-06-19T15:28:55.450107Z",
          "shell.execute_reply.started": "2022-06-19T15:22:25.395375Z",
          "shell.execute_reply": "2022-06-19T15:28:55.448703Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "6/6 [==============================] - 214s 34s/step - loss: 1.1271 - acc: 0.1550\n- wordAccuracy: 0.0\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for key in histotry.history.keys():\n",
        "#       print(key , histotry.history[key])\n",
        "#       #wandb.log({key : histotry.history[key]})"
      ],
      "metadata": {
        "id": "2BnI7lHtQtnT",
        "execution": {
          "iopub.status.busy": "2022-06-19T14:17:37.411280Z",
          "iopub.status.idle": "2022-06-19T14:17:37.411991Z",
          "shell.execute_reply.started": "2022-06-19T14:17:37.411629Z",
          "shell.execute_reply": "2022-06-19T14:17:37.411665Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seq2seq.metrics_names"
      ],
      "metadata": {
        "id": "Npqd4if4HVZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run inference (sampling)\n",
        "\n",
        "1. encode input and retrieve initial decoder state\n",
        "2. run one step of decoder with this initial state\n",
        "and a \"start of sequence\" token as target.\n",
        "Output will be the next target token.\n",
        "3. Repeat with the current target token and current states\n"
      ],
      "metadata": {
        "id": "BC5CbwHlAQef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Define sampling models\n",
        "# # Restore the model and construct the encoder and decoder.\n",
        "# model = keras.models.load_model(\"s2s\")\n",
        "\n",
        "# encoder_inputs = model.input[0]  # input_1\n",
        "# temp = model.layers[2].output\n",
        "# encoder_outputs, state = temp[0], temp[1:]  # lstm_1\n",
        "# encoder_states = state\n",
        "# encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# decoder_inputs = model.input[1]  # input_2\n",
        "# decoder_state_input_h = keras.Input(shape=(latent_dim,))\n",
        "# decoder_state_input_c = keras.Input(shape=(latent_dim,))\n",
        "# decoder_states_inputs = state\n",
        "# decoder_lstm = model.layers[3]\n",
        "# temp = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "# decoder_outputs, state_dec = temp[0], temp[1:]\n",
        "# decoder_states = state_dec\n",
        "# decoder_dense = model.layers[4]\n",
        "# decoder_outputs = decoder_dense(decoder_outputs)\n",
        "# decoder_model = keras.Model(\n",
        "#     [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
        "# )\n",
        "\n",
        "# # Reverse-lookup token index to decode sequences back to\n",
        "# # something readable.\n",
        "# # reverse_input_char_index = dict((i, char) for char, i in num_encoder_tokens.items())\n",
        "# # reverse_target_char_index = dict((i, char) for char, i in num_decoder_tokens.items())\n",
        "# # print(reverse_input_char_index)\n",
        "# # print(input_token_index)\n",
        "\n",
        "# reverse_input_token = dict((i, char) for char, i in input_token.items())\n",
        "# reverse_target_token = dict((i, char) for char, i in target_token.items())\n",
        "# def decode_sequence(input_seq):\n",
        "#     # Encode the input as state vectors.\n",
        "#     states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "#     # Generate empty target sequence of length 1.\n",
        "#     target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "#     # Populate the first character of target sequence with the start character.\n",
        "#     target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
        "\n",
        "#     # Sampling loop for a batch of sequences\n",
        "#     # (to simplify, here we assume a batch of size 1).\n",
        "#     stop_condition = False\n",
        "#     decoded_sentence = \"\"\n",
        "#     while not stop_condition:\n",
        "#         temp = decoder_model.predict([target_seq] + states_value)\n",
        "#         output_tokens, state = temp[0],temp[1:]\n",
        "\n",
        "#         # Sample a token\n",
        "#         sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "#         #print(reverse_target_char_index)\n",
        "#         sampled_char = reverse_target_token[sampled_token_index]\n",
        "#         decoded_sentence += sampled_char\n",
        "\n",
        "#         # Exit condition: either hit max length\n",
        "#         # or find stop character.\n",
        "#         if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
        "#             stop_condition = True\n",
        "\n",
        "#         # Update the target sequence (of length 1).\n",
        "#         target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "#         target_seq[0, 0, sampled_token_index] = 1.0\n",
        "\n",
        "#         # Update states\n",
        "#         states_value = state\n",
        "#     return decoded_sentence\n",
        "\n"
      ],
      "metadata": {
        "id": "meuadqgkAQeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can now generate decoded sentences as such:\n"
      ],
      "metadata": {
        "id": "nSNoQ5AvAQeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for seq_index in range(20):\n",
        "#     # Take one sequence (part of the training set)\n",
        "#     # for trying out decoding.\n",
        "#     input_seq = encoder_input_data[seq_index : seq_index + 1]\n",
        "#     decoded_sentence = decode_sequence(input_seq)\n",
        "#     print(\"-\")\n",
        "#     print(\"Input sentence:\", input_texts[seq_index])\n",
        "#     print(\"Decoded sentence:\", decoded_sentence)\n"
      ],
      "metadata": {
        "id": "wjp__2oJAQeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git log"
      ],
      "metadata": {
        "id": "ygwmClalB8vI",
        "execution": {
          "iopub.status.busy": "2022-06-19T15:44:04.633143Z",
          "iopub.execute_input": "2022-06-19T15:44:04.633593Z",
          "iopub.status.idle": "2022-06-19T15:44:05.689112Z",
          "shell.execute_reply.started": "2022-06-19T15:44:04.633552Z",
          "shell.execute_reply": "2022-06-19T15:44:05.687915Z"
        },
        "trusted": true,
        "outputId": "09f6fff2-5b5d-42a4-e7b8-2e20df103971"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "fatal: not a git repository (or any parent up to mount point /kaggle)\nStopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lzaKcIYKrP39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oX52e6mtrP39"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}