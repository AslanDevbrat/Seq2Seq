{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/AslanDevbrat/Seq2Seq/blob/dev/seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"markdown","source":"## Setup\n","metadata":{"id":"XtD33RcAAQeV"}},{"cell_type":"code","source":"%%capture\n!pip install wandb --upgrade\n!pip install tensorflow-addons","metadata":{"id":"UBUz4pd87YeP","execution":{"iopub.status.busy":"2022-06-22T14:06:55.161843Z","iopub.execute_input":"2022-06-22T14:06:55.162285Z","iopub.status.idle":"2022-06-22T14:07:18.831442Z","shell.execute_reply.started":"2022-06-22T14:06:55.162196Z","shell.execute_reply":"2022-06-22T14:07:18.830028Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Embedding, SimpleRNNCell, GRUCell, Dense, LSTMCell\nfrom tensorflow.keras import Input\nimport pandas as pd\nfrom numpy import argmax\nfrom math import log\nimport pprint\nimport math\nimport wandb\nimport os\nimport io\nfrom wandb.keras import WandbCallback\nimport time\nimport sys\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nwandb_api = user_secrets.get_secret(\"wandb_api\")\n\n#wandb.login(key=wandb_api)\n! wandb login $wandb_api\n\nos.environ[\"WANDB_SILENT\"] = \"false\"\nwandb.login()","metadata":{"id":"EnvOeSibAQeV","outputId":"29e1a5a5-f33e-4558-bd51-d007e30b32a0","execution":{"iopub.status.busy":"2022-06-22T14:07:26.097301Z","iopub.execute_input":"2022-06-22T14:07:26.097722Z","iopub.status.idle":"2022-06-22T14:07:41.190773Z","shell.execute_reply.started":"2022-06-22T14:07:26.097685Z","shell.execute_reply":"2022-06-22T14:07:41.189331Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maslan\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"## Download the data\n","metadata":{"id":"NbOpYTqYAQeX"}},{"cell_type":"markdown","source":"## Configuration\n","metadata":{"id":"1rKnaKIZAQeZ"}},{"cell_type":"code","source":"!wget  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n!tar -xf 'dakshina_dataset_v1.0.tar'\ntrain_file_path = \"./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\"\nval_file_path= \"./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv\"\ntest_file_path  = \"./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv\"","metadata":{"id":"roFBlOuMAYkx","outputId":"835ba7da-83ac-4de8-acf2-5f90ce20440a","execution":{"iopub.status.busy":"2022-06-22T14:07:41.193834Z","iopub.execute_input":"2022-06-22T14:07:41.194725Z","iopub.status.idle":"2022-06-22T14:07:54.711028Z","shell.execute_reply.started":"2022-06-22T14:07:41.194671Z","shell.execute_reply":"2022-06-22T14:07:54.709880Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"--2022-06-22 14:07:41--  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\nResolving storage.googleapis.com (storage.googleapis.com)... 173.194.218.128, 142.250.97.128, 173.194.213.128, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|173.194.218.128|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2008340480 (1.9G) [application/x-tar]\nSaving to: ‘dakshina_dataset_v1.0.tar’\n\ndakshina_dataset_v1 100%[===================>]   1.87G   238MB/s    in 8.3s    \n\n2022-06-22 14:07:50 (230 MB/s) - ‘dakshina_dataset_v1.0.tar’ saved [2008340480/2008340480]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size = 64  # Batch size for training.\nepochs = 100  # Number of epochs to train for.\nlatent_dim = 256  # Latent dimensionality of the encoding space.\nnum_samples = 100000  # Number of samples to train on.\n# Path to the data txt file on disk.\ndata_path = train_file_path\n","metadata":{"id":"akMCxfVHAQeZ","execution":{"iopub.status.busy":"2022-06-22T14:07:54.712395Z","iopub.execute_input":"2022-06-22T14:07:54.713053Z","iopub.status.idle":"2022-06-22T14:07:54.719651Z","shell.execute_reply.started":"2022-06-22T14:07:54.713017Z","shell.execute_reply":"2022-06-22T14:07:54.718881Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Prepare the data\n","metadata":{"id":"U-3Djb36AQea"}},{"cell_type":"code","source":"def processData(filename,input_chars=set(),target_chars=set()):\n  input=[]\n  target=[]\n  with open(filename, \"r\", encoding=\"utf-8\") as f:\n    lines = f.read().split(\"\\n\")\n  for line in lines[:len(lines)-1]:\n      t_text,i_text, attestation = line.split(\"\\t\")\n       # We use \"\\t\" as the \"start sequence\" character and \"\\n\" as \"end sequence\" character for the target text.\n      input.append(i_text)\n      target.append(\"\\t\"+t_text+\"\\n\")\n      for char in i_text:\n        if char not in input_chars:\n            input_chars.add(char)\n      for char in t_text:\n        if char not in target_chars:\n            target_chars.add(char)\n  target_chars.add(\"\\t\")\n  target_chars.add(\"\\n\")\n\n  input_chars = sorted(list(input_chars))\n  target_chars = sorted(list(target_chars))\n  num_encoder_tokens = len(input_chars)\n  num_decoder_tokens = len(target_chars)\n  max_encoder_seq_length = max([len(txt) for txt in input])\n  max_decoder_seq_length = max([len(txt) for txt in target])\n  return input,target,input_chars,target_chars,num_encoder_tokens,num_decoder_tokens, max_encoder_seq_length, max_decoder_seq_length     ","metadata":{"id":"5CZtxlJmaYmb","execution":{"iopub.status.busy":"2022-06-22T14:07:54.722241Z","iopub.execute_input":"2022-06-22T14:07:54.722555Z","iopub.status.idle":"2022-06-22T14:08:02.164874Z","shell.execute_reply.started":"2022-06-22T14:07:54.722525Z","shell.execute_reply":"2022-06-22T14:08:02.163733Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Vectorize the data.\ninput,target,input_chars,target_chars,num_encoder_tokens,num_decoder_tokens, max_encoder_seq_length, max_decoder_seq_length=processData(train_file_path)\nprint(\"Number of samples:\", len(input))\nprint(\"Number of unique input tokens:\", num_encoder_tokens)\nprint(\"Number of unique output tokens:\", num_decoder_tokens)\nprint(\"Max sequence length for inputs:\", max_encoder_seq_length)\nprint(\"Max sequence length for outputs:\", max_decoder_seq_length)","metadata":{"id":"pg8AcuMoab8U","outputId":"17e4d632-c169-456a-dbd8-8ad4ccd3b3f4","execution":{"iopub.status.busy":"2022-06-22T14:08:02.166593Z","iopub.execute_input":"2022-06-22T14:08:02.167299Z","iopub.status.idle":"2022-06-22T14:08:02.334393Z","shell.execute_reply.started":"2022-06-22T14:08:02.167260Z","shell.execute_reply":"2022-06-22T14:08:02.333116Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Number of samples: 44204\nNumber of unique input tokens: 26\nNumber of unique output tokens: 65\nMax sequence length for inputs: 20\nMax sequence length for outputs: 21\n","output_type":"stream"}]},{"cell_type":"code","source":"# Vectorize the data.\n# Vectorize the data.\nvalidation_input,validation_target,input_chars,target_chars,num_encoder_tokens,num_decoder_tokens, validation_max_encoder_seq_length, validation_max_decoder_seq_length=processData(val_file_path,set(input_chars),set(target_chars))\n\nprint(\"Number of validation samples:\", len(validation_input))\nprint(\"Number of unique input tokens:\", num_encoder_tokens)\nprint(\"Number of unique output tokens:\", num_decoder_tokens)\nprint(\"validation Max sequence length for inputs:\", validation_max_encoder_seq_length)\nprint(\"validation Max sequence length for outputs:\", validation_max_decoder_seq_length)","metadata":{"id":"lmCnQKWNbsuh","outputId":"52ce3c82-4a02-48a0-9f02-b000ff849fa4","execution":{"iopub.status.busy":"2022-06-22T14:08:02.337138Z","iopub.execute_input":"2022-06-22T14:08:02.338026Z","iopub.status.idle":"2022-06-22T14:08:02.359208Z","shell.execute_reply.started":"2022-06-22T14:08:02.337978Z","shell.execute_reply":"2022-06-22T14:08:02.357734Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Number of validation samples: 4502\nNumber of unique input tokens: 26\nNumber of unique output tokens: 65\nvalidation Max sequence length for inputs: 16\nvalidation Max sequence length for outputs: 17\n","output_type":"stream"}]},{"cell_type":"code","source":"# Vectorize the data.\ntest_input,test_target,test_input_chars,test_target_chars,test_num_encoder_tokens,test_num_decoder_tokens, test_max_encoder_seq_length, test_max_decoder_seq_length=processData(test_file_path)\nprint(\"Number of validation samples:\", len(test_input))\nprint(\"Test Max sequence length for inputs:\", test_max_encoder_seq_length)\nprint(\"Test Max sequence length for outputs:\", test_max_decoder_seq_length)","metadata":{"id":"Q9tUFlovbz5i","outputId":"7f953ea3-61d2-47d6-9186-d54f2e298138","execution":{"iopub.status.busy":"2022-06-22T14:08:02.360667Z","iopub.execute_input":"2022-06-22T14:08:02.361047Z","iopub.status.idle":"2022-06-22T14:08:02.512952Z","shell.execute_reply.started":"2022-06-22T14:08:02.361014Z","shell.execute_reply":"2022-06-22T14:08:02.511905Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Number of validation samples: 4358\nTest Max sequence length for inputs: 18\nTest Max sequence length for outputs: 16\n","output_type":"stream"}]},{"cell_type":"code","source":"# input_token = dict([(char, i) for i, char in enumerate(input_chars)])\n# target_token = dict([(char, i) for i, char in enumerate(target_chars)])\n\n# reverse_input_token = dict((i, char) for char, i in input_token.items())\n# reverse_target_token = dict((i, char) for char, i in target_token.items())\n\n\n# encoder_input_data = np.zeros(\n#     (len(input), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n# )\n# validation_encoder_input_data=np.zeros(\n#     (len(validation_input), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n# )\n# test_encoder_input_data=np.zeros(\n#     (len(test_input), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n# )\n# decoder_input_data = np.zeros(\n#     (len(input), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n# )\n# validation_decoder_input_data =np.zeros(\n#     (len(validation_input), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n# )\n# decoder_target_data = np.zeros(\n#     (len(input), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n# )\n# validation_decoder_target_data = np.zeros(\n#     (len(validation_input), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n# )\n\n# for i, (input_text, target_text) in enumerate(zip(input, target)):\n#     for t, char in enumerate(input_text):\n#         encoder_input_data[i, t, input_token[char]] = 1.0\n#     for t, char in enumerate(target_text):\n#         # decoder_target_data is ahead of decoder_input_data by one timestep\n#         decoder_input_data[i, t, target_token[char]] = 1.0\n#         if t > 0:\n#             # decoder_target_data will be ahead by one timestep\n#             # and will not include the start character.\n#             decoder_target_data[i, t - 1, target_token[char]] = 1.0\n# # for validation data\n# for i, (validation_input_text, validation_target_text) in enumerate(zip(validation_input, validation_target)):\n#     for t, char in enumerate(validation_input_text):\n#         validation_encoder_input_data[i, t, input_token[char]] = 1.0\n#     for t, char in enumerate(validation_target_text):\n#         # decoder_target_data is ahead of decoder_input_data by one timestep\n#         validation_decoder_input_data[i, t, target_token[char]] = 1.0\n#         if t > 0:\n#             # decoder_target_data will be ahead by one timestep\n#             # and will not include the start character.\n#             validation_decoder_target_data[i, t - 1, target_token[char]] = 1.0\n\n# # for test data\n# for i, (test_input_text, test_target_text) in enumerate(zip(test_input, test_target)):\n#     for t, char in enumerate(test_input_text):\n#         test_encoder_input_data[i, t, input_token[char]] = 1.0","metadata":{"id":"oBF7Cdqrb5Hc","execution":{"iopub.status.busy":"2022-06-22T14:08:02.515563Z","iopub.execute_input":"2022-06-22T14:08:02.516281Z","iopub.status.idle":"2022-06-22T14:08:02.523752Z","shell.execute_reply.started":"2022-06-22T14:08:02.516216Z","shell.execute_reply":"2022-06-22T14:08:02.522782Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"2q7AdDj4P_8p","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_token = dict([(char, i) for i, char in enumerate(input_chars)])\ntarget_token = dict([(char, i) for i, char in enumerate(target_chars)])\n\nreverse_input_token = dict((i, char) for char, i in input_token.items())\nreverse_target_token = dict((i, char) for char, i in target_token.items())\n\nenc_input_data = np.zeros(\n    (len(input), max_encoder_seq_length), dtype=\"float32\"\n)\ndec_input_data = np.zeros(\n    (len(input), max_decoder_seq_length), dtype=\"float32\"\n)\ndec_target_data = np.ones(\n    (len(input), max_decoder_seq_length), dtype=\"float32\"\n)\n#Decoder Target Sequences are Padded to a maximum length of max_decoder SeqLen characters with a vocabulary of sizeofTeluguVocab different characters. \nfor i, (input_text, target_text) in enumerate(zip(input, target)):\n    for t, char in enumerate(input_text):\n        enc_input_data[i, t] = input_token[char]\n    #enc_input_data[i, t + 1 :] = input_token[\" \"]\n\n    for t, char in enumerate(target_text):\n        # dec_target_data is ahead of dec_input_data by one timestep\n        dec_input_data[i, t] = target_token[char]\n        if t > 0:\n            # dec_target_data will not include the start character.\n            dec_target_data[i, t - 1] = target_token[char]\n    #dec_input_data[i, t + 1: ] = target_token[\" \"]\n    #dec_target_data[i, t:, target_token[\" \"]] = 1.0\n    \nval_enc_input_data = np.zeros(\n    (len(validation_input), validation_max_encoder_seq_length), dtype=\"float32\"\n)\nval_dec_input_data = np.zeros(\n    (len(validation_input), validation_max_decoder_seq_length), dtype=\"float32\"\n)\nval_dec_target_data = np.ones(\n    (len(validation_input), validation_max_decoder_seq_length), dtype=\"float32\"\n)\n\nfor i, (input_text, target_text) in enumerate(zip(validation_input,validation_target)):\n    for t, char in enumerate(input_text):\n        # Enumerate() method adds a counter to an iterable and returns it in a form of enumerating object. \n        # This enumerated object can then be used directly for loops or converted into a list of tuples using the list() method.\n        val_enc_input_data[i, t] = input_token[char]\n    #val_enc_input_data[i, t + 1 :] = input_token_index[\" \"]\n\n    for t, char in enumerate(target_text):\n        val_dec_input_data[i, t] = target_token[char]\n        if t > 0:\n            # dec_target_data will be ahead by one timestep\n            # and will not include the start character.\n            val_dec_target_data[i, t - 1] =  target_token[char]\n    #val_dec_input_data[i, t + 1: ] = target_token_index[\" \"]","metadata":{"id":"6_L_o5BGrP3z","execution":{"iopub.status.busy":"2022-06-22T14:08:02.526008Z","iopub.execute_input":"2022-06-22T14:08:02.526568Z","iopub.status.idle":"2022-06-22T14:08:03.490454Z","shell.execute_reply.started":"2022-06-22T14:08:02.526517Z","shell.execute_reply":"2022-06-22T14:08:03.489300Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"xtmF5PX1Xo9u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class NMTDataset:\n#     def __init__(self, problem_type='en-hi'):\n#         self.problem_type = 'en-'\n#         self.inp_lang_tokenizer = None\n#         self.targ_lang_tokenizer = None\n    \n\n#     def unicode_to_ascii(self, s):\n#         return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n\n#     ## Step 1 and Step 2 \n#     def preprocess_sentence(self, w):\n#         # w = self.unicode_to_ascii(w.lower().strip())\n\n#         # # creating a space between a word and the punctuation following it\n#         # # eg: \"he is a boy.\" => \"he is a boy .\"\n#         # # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n#         # w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n#         # w = re.sub(r'[\" \"]+', \" \", w)\n\n#         # # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n#         # w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n\n#         # w = w.strip()\n\n#         # adding a start and an end token to the sentence\n#         # so that the model know when to start and stop predicting.\n#         #print(w)\n#         w = '\\t' + w + '\\n'\n        \n#         return w\n    \n#     def create_dataset(self, path, num_examples):\n#         # path : path to spa-eng.txt file\n#         # num_examples : Limit the total number of training example for faster training (set num_examples = len(lines) to use full data)\n#         #lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n#         #word_pairs = [[self.preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n#         data =  pd.read_csv(path,delimiter=\"\\t\", header= None, nrows = num_examples )\n#         data = data.dropna()\n#         print(data.info())\n#         return data[0].apply(self.preprocess_sentence).values.astype(str), data[1].apply(self.preprocess_sentence).values.astype(str)\n\n#     # Step 3 and Step 4\n#     def tokenize(self, lang):\n#         # lang = list of sentences in a language\n        \n#         # print(len(lang), \"example sentence: {}\".format(lang[0]))\n#         lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(char_level = True)\n#         lang_tokenizer.fit_on_texts(lang)\n\n#         ## tf.keras.preprocessing.text.Tokenizer.texts_to_sequences converts string (w1, w2, w3, ......, wn) \n#         ## to a list of correspoding integer ids of words (id_w1, id_w2, id_w3, ...., id_wn)\n#         tensor = lang_tokenizer.texts_to_sequences(lang) \n\n#         ## tf.keras.preprocessing.sequence.pad_sequences takes argument a list of integer id sequences \n#         ## and pads the sequences to match the longest sequences in the given input\n#         tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n\n#         return tensor, lang_tokenizer\n\n#     def load_dataset(self, path, num_examples=None):\n#         # creating cleaned input, output pairs\n#         targ_lang, inp_lang = self.create_dataset(path, num_examples)\n\n#         input_tensor, inp_lang_tokenizer = self.tokenize(inp_lang)\n#         target_tensor, targ_lang_tokenizer = self.tokenize(targ_lang)\n\n#         return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer\n\n#     def call(self, num_examples, BUFFER_SIZE, BATCH_SIZE):\n#         #file_path = download_dakshina()\n#         input_tensor_train, target_tensor_train, self.inp_lang_tokenizer, self.targ_lang_tokenizer = self.load_dataset(train_file_path, num_examples)\n#         input_tensor_val, target_tensor_val, self.inp_lang_tokenizer, self.targ_lang_tokenizer = self.load_dataset(val_file_path, num_examples)\n#         input_tensor_test, target_tensor_test, self.inp_lang_tokenizer, self.targ_lang_tokenizer = self.load_dataset(test_file_path, num_examples)\n#         x = input_tensor_train\n#         y  =target_tensor_train\n#         #input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.4)\n\n#         train_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train,target_tensor_train))\n#         train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n\n#         val_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_val, target_tensor_val))\n#         val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n\n#         test_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_test, target_tensor_test))\n#         test_dataset = test_dataset.batch(BATCH_SIZE, drop_remainder=True)\n#         return train_dataset, val_dataset, test_dataset, self.inp_lang_tokenizer, self.targ_lang_tokenizer\n","metadata":{"id":"EOIwk0-PrP3z","execution":{"iopub.status.busy":"2022-06-22T14:08:03.495911Z","iopub.execute_input":"2022-06-22T14:08:03.496317Z","iopub.status.idle":"2022-06-22T14:08:03.505009Z","shell.execute_reply.started":"2022-06-22T14:08:03.496283Z","shell.execute_reply":"2022-06-22T14:08:03.503846Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# BUFFER_SIZE = 32000\n# BATCH_SIZE = 64\n# # Let's limit the #training examples for faster training\n# num_examples = 300000\n\n# dataset_creator = NMTDataset('en-spa')\n# train_dataset, val_dataset,test_dataset, inp_lang, targ_lang = dataset_creator.call(num_examples, BUFFER_SIZE, BATCH_SIZE)","metadata":{"id":"s3Wn4CM1zgLH","outputId":"977b8f65-a1c2-4b15-e040-29a04fd3a88f","execution":{"iopub.status.busy":"2022-06-22T14:08:03.506531Z","iopub.execute_input":"2022-06-22T14:08:03.507709Z","iopub.status.idle":"2022-06-22T14:08:03.520362Z","shell.execute_reply.started":"2022-06-22T14:08:03.507659Z","shell.execute_reply":"2022-06-22T14:08:03.519125Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# next(iter(train_dataset))[1][0]","metadata":{"id":"9Rox45Q1hWgm","outputId":"05609fc2-54dc-4c20-e204-01bda96fe41e","execution":{"iopub.status.busy":"2022-06-22T14:08:03.521960Z","iopub.execute_input":"2022-06-22T14:08:03.522650Z","iopub.status.idle":"2022-06-22T14:08:03.532239Z","shell.execute_reply.started":"2022-06-22T14:08:03.522603Z","shell.execute_reply":"2022-06-22T14:08:03.531245Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# example_input_batch, example_target_batch = next(iter(train_dataset))\n# example_input_batch.shape, example_target_batch.shape","metadata":{"id":"9gaZrS4g1T5X","outputId":"97ad97b4-743b-44fc-81d2-ccd5ff884d00","execution":{"iopub.status.busy":"2022-06-22T14:08:03.533697Z","iopub.execute_input":"2022-06-22T14:08:03.534353Z","iopub.status.idle":"2022-06-22T14:08:03.544607Z","shell.execute_reply.started":"2022-06-22T14:08:03.534314Z","shell.execute_reply":"2022-06-22T14:08:03.543605Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Build the model\n","metadata":{"id":"eGM50wwWAQed"}},{"cell_type":"code","source":"class Encoder(tf.keras.Model):\n  def __init__(self, vocab_size, embedding_dim, enc_units, num_of_layers, enc_unit_type, batch_sz, recurrent_dropout, dropout):\n    super(Encoder, self).__init__()\n\n    self.batch_sz = batch_sz\n    self.enc_units = enc_units\n    self.enc_unit_type = enc_unit_type\n    self.num_of_layers = num_of_layers\n    self.recurrent_dropout = recurrent_dropout\n    self.dropout = dropout\n    self.embedding = Embedding( vocab_size, embedding_dim)\n\n    self.encoder_layer = self.get_encoder_layer(self.enc_units,\n                                                self.num_of_layers, self.enc_unit_type)\n    \n\n  def get_encoder_layer(self, enc_units, num_of_layers, enc_unit_type):\n    return tf.keras.layers.RNN(tf.keras.layers.StackedRNNCells( [self.get_cell(enc_unit_type, \n                                                                                 enc_units) for i in range(num_of_layers)],),\n                                  return_sequences=True, return_state=True, name = \"Encoder\")\n\n  def get_cell(self, cell_type = \"lstm\", num_of_cell = 1, name = None):\n      #print(cell_type)\n      if cell_type == \"lstm\":\n        return LSTMCell(num_of_cell, dropout = self.dropout, recurrent_dropout = self.recurrent_dropout, )\n      elif cell_type == \"rnn\":\n        return SimpleRNNCell(num_of_cell, dropout = self.dropout, recurrent_dropout = self.recurrent_dropout)\n      elif cell_type ==\"gru\":\n        return GRUCell(num_of_cell, dropout = self.dropout, recurrent_dropout = self.recurrent_dropout)\n      else:\n        print(f\"Invalid cell type: {cell_type}\")\n\n    \n  def call(self, x):\n      x = self.embedding(x)\n      output = self.encoder_layer(x,)\n\n      #print(output)\n      return output\n    \n  def initialize_hidden_state(self):\n      print(\"Called\")\n      return [tf.zeros((self.batch_sz, self.enc_units)), tf.zeros((self.batch_sz, self.enc_units))]","metadata":{"id":"-_IMrNwXsYR4","execution":{"iopub.status.busy":"2022-06-22T14:08:03.546071Z","iopub.execute_input":"2022-06-22T14:08:03.546443Z","iopub.status.idle":"2022-06-22T14:08:03.562561Z","shell.execute_reply.started":"2022-06-22T14:08:03.546411Z","shell.execute_reply":"2022-06-22T14:08:03.561665Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# enc_input_data[0].shape","metadata":{"id":"3iT2EuNf1TDo","outputId":"7a08f4c6-f141-4984-9b5f-544a2c3aceec","execution":{"iopub.status.busy":"2022-06-22T14:08:03.563858Z","iopub.execute_input":"2022-06-22T14:08:03.564668Z","iopub.status.idle":"2022-06-22T14:08:03.578498Z","shell.execute_reply.started":"2022-06-22T14:08:03.564610Z","shell.execute_reply":"2022-06-22T14:08:03.577311Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"\n# #encoder = Encoder( num_encoder_tokens, 1024, 1024, 3, \"lstm\", batch_size, 0.0, 0.0).build(input_shape =(None,22))\n# encoder = Encoder( num_encoder_tokens, 1, 16, 3, \"lstm\", 64, 0.0, 0.0)\n# #sample_hidden = encoder.initialize_hidden_state()\n# # encoder.build(input_shape =(None,26))\n# # encoder.summary()\n# sample_output = encoder(enc_input_data[:64])\n# out , state = sample_output[0], sample_output[1:]","metadata":{"id":"oG6E1qaLv92s","execution":{"iopub.status.busy":"2022-06-22T14:08:03.580018Z","iopub.execute_input":"2022-06-22T14:08:03.580369Z","iopub.status.idle":"2022-06-22T14:08:03.589715Z","shell.execute_reply.started":"2022-06-22T14:08:03.580337Z","shell.execute_reply":"2022-06-22T14:08:03.588572Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# out, state","metadata":{"id":"yHmvx-1zRHJ8","execution":{"iopub.status.busy":"2022-06-22T14:08:03.591447Z","iopub.execute_input":"2022-06-22T14:08:03.591785Z","iopub.status.idle":"2022-06-22T14:08:03.606515Z","shell.execute_reply.started":"2022-06-22T14:08:03.591756Z","shell.execute_reply":"2022-06-22T14:08:03.605495Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"class Decoder(tf.keras.Model):\n  def __init__(self, vocab_size, embedding_dim, dec_units, num_of_layers, \n               dec_unit_type, batch_sz, recurrent_dropout, dropout, \n               attention_type = \"luong\"):\n    \n    super(Decoder, self).__init__()\n    self.batch_sz = batch_sz\n    self.dec_units = dec_units\n    self.dec_unit_type = dec_unit_type\n    self.num_of_layers = num_of_layers\n    self.attention_type = attention_type\n    self.recurrent_dropout = recurrent_dropout\n    self.dropout = dropout\n    #print(\"decoder embedding dim\", embedding_dim)\n    self.embedding = Embedding( vocab_size, embedding_dim)\n\n    self.fc  = tf.keras.layers.Dense(vocab_size, activation = \"softmax\")\n\n    self.decoder_cells = self.get_stacked_rnn_cell()\n\n    self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n    self.attention_mechanism = self.build_attention_mechanism(self.dec_units, None\n                                                              , self.batch_sz*[max_encoder_seq_length], \n                                                              self.attention_type)\n\n    self.cell = self.build_cell()\n\n    #print(self.cell)\n\n    self.decoder = tfa.seq2seq.BasicDecoder(self.cell, sampler = self.sampler, output_layer = self.fc)\n\n\n\n  def build_cell(self):\n    cell = tfa.seq2seq.AttentionWrapper(self.decoder_cells, self.attention_mechanism,\n                                        attention_layer_size = self.dec_units)\n    return cell\n  \n  def build_attention_mechanism(self, dec_units, memory, memory_sequence_length, attention_type='luong'):\n    # ------------- #\n    # typ: Which sort of attention (Bahdanau, Luong)\n    # dec_units: final dimension of attention outputs \n    # memory: encoder hidden states of shape (batch_size, max_length_input, enc_units)\n    # memory_sequence_length: 1d array of shape (batch_size) with every element set to max_length_input (for masking purpose)\n\n    if(attention_type=='bahdanau'):\n      return tfa.seq2seq.BahdanauAttention(units=dec_units, memory=memory, memory_sequence_length=memory_sequence_length)\n    else:\n      return tfa.seq2seq.LuongAttention(units=dec_units, memory=memory, memory_sequence_length=memory_sequence_length)\n\n  def get_cell(self, cell_type = \"lstm\", num_of_cell = 1, name = None):\n      #print(cell_type)\n      if cell_type == \"lstm\":\n        return LSTMCell(num_of_cell, dropout = self.dropout, recurrent_dropout = self.recurrent_dropout, )\n      elif cell_type == \"rnn\":\n        return SimpleRNNCell(num_of_cell, dropout = self.dropout, recurrent_dropout = self.recurrent_dropout)\n      elif cell_type ==\"gru\":\n        return GRUCell(num_of_cell, dropout = self.dropout, recurrent_dropout = self.recurrent_dropout)\n      else:\n        print(f\"Invalid cell type: {cell_type}\")\n\n  def get_stacked_rnn_cell(self,):\n    return tf.keras.layers.StackedRNNCells( [self.get_cell(self.dec_unit_type, self.dec_units,) for i in range(self.num_of_layers)])\n\n  def build_initial_state(self, batch_sz, encoder_state, Dtype):\n    decoder_initial_state = self.cell.get_initial_state(batch_size=batch_sz, dtype=Dtype)\n    #print(batch_sz)\n    #print(len(encoder_state))\n    decoder_initial_state = decoder_initial_state.clone(cell_state=encoder_state)\n    return decoder_initial_state\n\n  def call(self, x, initial_state):\n    x = self.embedding(x)\n    #print(\"calles\")\n    output = self.decoder(x, initial_state=initial_state)\n    return output","metadata":{"id":"vPiwKS7P7A3X","execution":{"iopub.status.busy":"2022-06-22T14:08:03.608194Z","iopub.execute_input":"2022-06-22T14:08:03.608570Z","iopub.status.idle":"2022-06-22T14:08:03.628905Z","shell.execute_reply.started":"2022-06-22T14:08:03.608536Z","shell.execute_reply":"2022-06-22T14:08:03.627694Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"\n# #encoder = Encoder( num_encoder_tokens, 1024, 1024, 3, \"lstm\", batch_size, 0.0, 0.0).build(input_shape =(None,22))\n# decoder = Decoder( num_decoder_tokens,  1, 16, 3, \"lstm\", 64, 0.0, 0.0)\n# #sample_hidden = encoder.initialize_hidden_state()\n# #decoder.build(input_shape =(None, ))\n# # decoder.summary()\n# #sample_x = tf.random.uniform((2  ,max_decoder_seq_length))\n# decoder.attention_mechanism.setup_memory(out)\n# initial_state = decoder.build_initial_state(64, tuple(state), tf.float32)\n# # sample_output = decoder(dec_input_data[:8192], initial_state)\n# # out1 , state1 = sample_output[0], sample_output[1:]","metadata":{"id":"Fe8whQdYCdfZ","outputId":"62bd1aa0-6726-41c8-a941-25bf2702c4fa","execution":{"iopub.status.busy":"2022-06-22T14:08:03.630297Z","iopub.execute_input":"2022-06-22T14:08:03.631203Z","iopub.status.idle":"2022-06-22T14:08:03.644283Z","shell.execute_reply.started":"2022-06-22T14:08:03.631168Z","shell.execute_reply":"2022-06-22T14:08:03.643081Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# out1","metadata":{"id":"s1cQ1JBzWhth","execution":{"iopub.status.busy":"2022-06-22T14:08:03.645834Z","iopub.execute_input":"2022-06-22T14:08:03.646609Z","iopub.status.idle":"2022-06-22T14:08:03.661435Z","shell.execute_reply.started":"2022-06-22T14:08:03.646572Z","shell.execute_reply":"2022-06-22T14:08:03.660471Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"input_data = tf.data.Dataset.from_tensor_slices((enc_input_data, dec_input_data))\ntarget_data =  tf.data.Dataset.from_tensor_slices(dec_target_data)\ntrain_dataset  = tf.data.Dataset.zip((input_data, target_data)).batch(batch_size, drop_remainder=True)\n\ninput_data = tf.data.Dataset.from_tensor_slices((val_enc_input_data, val_dec_input_data))\ntarget_data =  tf.data.Dataset.from_tensor_slices(val_dec_target_data)\nval_dataset  = tf.data.Dataset.zip((input_data, target_data)).batch(batch_size, drop_remainder=True)","metadata":{"id":"Y-R5t0ex2M6v","execution":{"iopub.status.busy":"2022-06-22T14:08:03.663156Z","iopub.execute_input":"2022-06-22T14:08:03.663902Z","iopub.status.idle":"2022-06-22T14:08:03.745107Z","shell.execute_reply.started":"2022-06-22T14:08:03.663852Z","shell.execute_reply":"2022-06-22T14:08:03.744275Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"2022-06-22 14:08:03.692770: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n","output_type":"stream"}]},{"cell_type":"code","source":"class Seq2Seq():\n  def __init__(self, num_encoder_tokens, num_decoder_token, encoder_embedding_dim, decoder_embedding_dim,num_of_unit, num_of_layers, unit_type, batch_size, recurrent_dropout, dropout):\n    super().__init__()\n    self.batch_size = batch_size\n    self.encoder = Encoder(  num_encoder_tokens, encoder_embedding_dim, num_of_unit, num_of_layers, unit_type, self.batch_size,  recurrent_dropout, dropout)\n    #self.encoder.summary()\n    self.dec = Decoder( num_decoder_tokens,  decoder_embedding_dim, num_of_unit, num_of_layers, unit_type, self.batch_size, recurrent_dropout, dropout)\n    #sample_x = tf.random.uniform((batch_size  ,max_decoder_seq_length))\n\n  def call(self, enc_inp, dec_inp):\n    #print(\"fsdfa\",dec_inp.shape)\n    x = self.encoder(enc_inp)\n    enc_out, enc_state = x[0], x[1:]\n    #print(enc_out.shape)\n    self.dec.attention_mechanism.setup_memory(enc_out)\n    dec_initial_state = self.dec.build_initial_state(self.batch_size, tuple(enc_state), tf.float32)\n    #print(\"fucck\")\n    x = self.dec(dec_inp,dec_initial_state)\n    return x\n\n  @tf.function\n  def validation_step(self, val_enc_input_data, val_dec_input_data, targ):\n    #dec_input_data = val_dec_input_data[ : , :-1 ]\n    out = self.call(val_enc_input_data, val_dec_input_data)\n    logits = out[0].rnn_output\n    #print(logits.item())\n    loss = 0\n    for (i, (ta, pre)) in enumerate(zip(tf.unstack(targ),tf.unstack(logits))):\n        stop = tf.where( ta == 1)[0][0]\n        self.metric.update_state(ta[:stop], pre[:stop])\n        loss += self.loss_function(ta[:stop], pre[:stop])\n    #loss += self.loss_function(real, logits)\n    #print(\"Validation Loss = \", loss.numpy())\n    #self.metric.update_state(real, logits)\n    return loss/i, self.metric.result()\n\n  @tf.function\n  def train_step(self, enc_input_data, dec_input_data, targ):\n    loss = 0\n\n    with tf.GradientTape() as tape:\n      \n      out = self.call(enc_input_data, dec_input_data)\n      logits = out[0].rnn_output\n      loss = 0\n      for (i, (ta, pre)) in enumerate(zip(tf.unstack(targ),tf.unstack(logits))):\n        stop = tf.where( ta == 1)[0][0]\n        self.metric.update_state(ta[:stop], pre[:stop])\n        loss += self.loss_function(ta[:stop], pre[:stop])\n \n      \n    variables = self.encoder.variables + self.dec.variables\n    gradients = tape.gradient(loss, variables)\n    self.optimizer.apply_gradients(zip(gradients, variables))\n\n    return loss/i, self.metric.result()\n\n  def fit(self, train_dataset, val_dataset, epochs, loss, optimizer, checkpoint, metric):\n    self.metric = metric\n\n    \n    self.loss_function = loss\n    self.optimizer = optimizer\n    steps_per_epoch = len(input)//batch_size\n    step_per_val_epoch  = len(validation_input)//batch_size\n    print(steps_per_epoch)\n    for epoch in range(epochs):\n      start = time.time()\n\n      #enc_hidden = encoder.initialize_hidden_state()\n      total_loss = 0\n      total_acc = 0\n      # print(enc_hidden[0].shape, enc_hidden[1].shape)\n\n      self.metric.reset_states()\n      for (batch, (inp, targ)) in enumerate(train_dataset.take(steps_per_epoch)):\n        #print(\"targ\", targ)\n        batch_loss , acc = self.train_step(inp[0],inp[1] ,targ )\n        total_loss += batch_loss\n        total_acc += acc\n        if batch % 100 == 0:\n          #reak\n          print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n                                                      batch,\n                                                      batch_loss.numpy()))\n      # saving (checkpoint) the model every 2 epochs\n      #val_enc_inp, val_dec_inp , val_targ = val_dataset.take(-1)\n      #val_enc_inp, val_dec_inp = val_inp.take(-1)\n          #andb.log({\"Epoch {epoch + 1} Batch {batch}\": batch_loss.numpy()})\n      total_val_loss = 0\n      total_val_acc = 0\n\n      self.metric.reset_states()\n      for (batch, (inp, targ)) in enumerate(val_dataset.take(steps_per_epoch)):\n        #print(batch)\n       \n        val_batch_loss, val_acc = self.validation_step(inp[0],inp[1] ,targ)\n        total_val_loss +=val_batch_loss\n        total_val_acc += val_acc\n\n      print(f\"Validatiion loss:  {total_val_loss.numpy()/  step_per_val_epoch}\")\n      print((f\"Validatiion Acc:  {(total_val_acc.numpy()/  step_per_val_epoch)*100}\"))\n      # print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n      #                                                 batch,\n      #                                                 val_batch_loss.numpy()))\n      if (epoch + 1) % 2 == 0:\n        checkpoint.save(file_prefix = checkpoint_prefix)\n\n      print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n                                          total_loss / steps_per_epoch))\n      print(\"Accuracy \",(total_acc.numpy()/steps_per_epoch) *100)\n      print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n         \n#       #andb.log({\"Epoch\": epoch + 1,\n#                 \"Train loss\": total_loss / steps_per_epoch,\n#                  \"Train Accuracy\": (total_acc.numpy()/steps_per_epoch) *100,\n#                  \"Val Accuracy\": (total_val_acc.numpy()/  step_per_val_epoch)*100,\n#                  \"Val Loss\": total_val_loss.numpy()/  step_per_val_epoch\n#                 })\n\n\n    ","metadata":{"id":"cVoQMjKYYLX2","execution":{"iopub.status.busy":"2022-06-22T15:22:08.224118Z","iopub.execute_input":"2022-06-22T15:22:08.224608Z","iopub.status.idle":"2022-06-22T15:22:08.255333Z","shell.execute_reply.started":"2022-06-22T15:22:08.224569Z","shell.execute_reply":"2022-06-22T15:22:08.254201Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"batch_size = 64","metadata":{"execution":{"iopub.status.busy":"2022-06-22T15:22:09.994623Z","iopub.execute_input":"2022-06-22T15:22:09.995494Z","iopub.status.idle":"2022-06-22T15:22:10.002457Z","shell.execute_reply.started":"2022-06-22T15:22:09.995448Z","shell.execute_reply":"2022-06-22T15:22:10.001642Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"\ns2s = Seq2Seq(num_encoder_tokens, num_decoder_tokens,  encoder_embedding_dim =64,\n              decoder_embedding_dim= 1024,\n              num_of_unit =16,\n              num_of_layers = 1, \n              unit_type =\"lstm\",\n             batch_size = batch_size, \n              recurrent_dropout = 0.3,\n              dropout = 0 )\n\nsample_out = s2s.call(enc_input_data[:batch_size], dec_input_data[:batch_size])","metadata":{"id":"BRKTJEGid7MN","execution":{"iopub.status.busy":"2022-06-22T15:22:12.542294Z","iopub.execute_input":"2022-06-22T15:22:12.542684Z","iopub.status.idle":"2022-06-22T15:22:12.799697Z","shell.execute_reply.started":"2022-06-22T15:22:12.542652Z","shell.execute_reply":"2022-06-22T15:22:12.798713Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"#s2s.call(enc_input_data[:batch_size], dec_input_data[:batch_size])","metadata":{"id":"f_J78RufnWC0","execution":{"iopub.status.busy":"2022-06-22T14:20:00.956585Z","iopub.execute_input":"2022-06-22T14:20:00.957394Z","iopub.status.idle":"2022-06-22T14:20:00.965995Z","shell.execute_reply.started":"2022-06-22T14:20:00.957346Z","shell.execute_reply":"2022-06-22T14:20:00.964471Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.RMSprop()\n\n\ndef loss_function(real, pred):\n  # real shape = (BATCH_SIZE, max_length_output)\n  # pred shape = (BATCH_SIZE, max_length_output, tar_vocab_size )\n  #print(pred,\"fucck\", real)\n  cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n  loss = cross_entropy(y_true=real, y_pred=pred)\n  mask = tf.logical_not(tf.math.equal(real,0))   #output 0 for y=0 else output 1\n  mask = tf.cast(mask, dtype=loss.dtype)  \n  loss = mask* loss\n  loss = tf.reduce_mean(loss)\n  return loss  ","metadata":{"id":"CD30sG2dRTLD","execution":{"iopub.status.busy":"2022-06-22T14:20:01.441195Z","iopub.execute_input":"2022-06-22T14:20:01.441608Z","iopub.status.idle":"2022-06-22T14:20:01.453528Z","shell.execute_reply.started":"2022-06-22T14:20:01.441571Z","shell.execute_reply":"2022-06-22T14:20:01.452228Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"checkpoint_dir = './training_checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(optimizer=optimizer,\n                                 encoder=s2s.encoder,\n                                 decoder=s2s.dec,\n                                 )","metadata":{"id":"25sIIGGxRVC2","execution":{"iopub.status.busy":"2022-06-22T14:20:01.715657Z","iopub.execute_input":"2022-06-22T14:20:01.716991Z","iopub.status.idle":"2022-06-22T14:20:01.723997Z","shell.execute_reply.started":"2022-06-22T14:20:01.716938Z","shell.execute_reply":"2022-06-22T14:20:01.722907Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"tf.config.run_functions_eagerly(False)\ns2s.fit(train_dataset, val_dataset, 100, loss_function, optimizer, checkpoint , metric =  tf.keras.metrics.SparseCategoricalAccuracy())","metadata":{"id":"fHckm-8X2qG2","outputId":"9c76069e-108a-4b88-835a-5ac1222b9bc0","scrolled":true,"execution":{"iopub.status.busy":"2022-06-22T15:16:18.924690Z","iopub.execute_input":"2022-06-22T15:16:18.925129Z","iopub.status.idle":"2022-06-22T15:18:45.049175Z","shell.execute_reply.started":"2022-06-22T15:16:18.925096Z","shell.execute_reply":"2022-06-22T15:18:45.047670Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"690\nEpoch 1 Batch 0 Loss 3.8253\nEpoch 1 Batch 100 Loss 3.8604\nEpoch 1 Batch 200 Loss 3.9974\nEpoch 1 Batch 300 Loss 3.7728\nEpoch 1 Batch 400 Loss 3.8832\nEpoch 1 Batch 500 Loss 3.8866\nEpoch 1 Batch 600 Loss 3.9975\nValidatiion loss:  3.844636753627232\nValidatiion Acc:  42.87739617483957\nEpoch 1 Loss 3.8309\nAccuracy  41.27513940783514\nTime taken for 1 epoch 71.72304368019104 sec\n\nEpoch 2 Batch 0 Loss 3.8046\nEpoch 2 Batch 100 Loss 3.8301\nEpoch 2 Batch 200 Loss 3.9943\nEpoch 2 Batch 300 Loss 3.7562\nEpoch 2 Batch 400 Loss 3.8836\nEpoch 2 Batch 500 Loss 3.8671\nEpoch 2 Batch 600 Loss 4.0015\nValidatiion loss:  3.8411599295479912\nValidatiion Acc:  43.34643772670201\nEpoch 2 Loss 3.8236\nAccuracy  42.913698942764945\nTime taken for 1 epoch 74.18663215637207 sec\n\n","output_type":"stream"},{"name":"stderr","text":"2022-06-22 15:18:44.913538: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at resource_variable_ops.cc:548 : Not found: Resource localhost/_AnonymousVar98/N10tensorflow3VarE does not exist.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_33/3611484383.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_functions_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ms2s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseCategoricalAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_33/3758152967.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_dataset, val_dataset, epochs, loss, optimizer, checkpoint, metric)\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m#print(\"targ\", targ)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mbatch_loss\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtarg\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mtotal_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFoundError\u001b[0m:  Resource localhost/_AnonymousVar98/N10tensorflow3VarE does not exist.\n\t [[node AssignAddVariableOp (defined at tmp/ipykernel_33/3758152967.py:48) ]] [Op:__inference_train_step_75187]\n\nFunction call stack:\ntrain_step\n"],"ename":"NotFoundError","evalue":" Resource localhost/_AnonymousVar98/N10tensorflow3VarE does not exist.\n\t [[node AssignAddVariableOp (defined at tmp/ipykernel_33/3758152967.py:48) ]] [Op:__inference_train_step_75187]\n\nFunction call stack:\ntrain_step\n","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sweep_config = {\n    \n    'method':'bayes',\n    'metric': {\n        'name':'Val Accuracy',\n        'goal':'maximize'\n    },\n    'parameters':{\n    \n    \"num_of_layer\" : {'values': [1,2,3]},\n    \"unit_size\": {\"values\":[16,32,64]},\n    \"unit_type\": {\"values\":[\"lstm\",\"rnn\",\"gru\"]},\n    \"dropout\": {\"values\": [0.0, 0.2, 0.4]},\n    'recurrent_dropout':{'values':[0.0,0.3]},\n    \"epochs\":{\"value\":20},\n    \"encoder_embedding_dim\":{\"values\": [64, 128, 1024]},\n    \"decoder_embedding_dim\":{\"values\": [64, 128, 1024]},\n    \"optimizer\":{\"values\": [\"adam\",\"rmsprop\"]}             \n                   }\n}\npprint.pprint(sweep_config)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-22T14:15:21.984340Z","iopub.status.idle":"2022-06-22T14:15:21.985066Z","shell.execute_reply.started":"2022-06-22T14:15:21.984850Z","shell.execute_reply":"2022-06-22T14:15:21.984873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sweep_id = wandb.sweep(sweep_config, project=\"Sweep_with_Attention\")\n","metadata":{"execution":{"iopub.status.busy":"2022-06-22T08:43:55.959860Z","iopub.execute_input":"2022-06-22T08:43:55.960842Z","iopub.status.idle":"2022-06-22T08:43:56.269760Z","shell.execute_reply.started":"2022-06-22T08:43:55.960792Z","shell.execute_reply":"2022-06-22T08:43:56.268773Z"},"trusted":true},"execution_count":156,"outputs":[{"name":"stdout","text":"Create sweep with ID: ldn2b7uj\nSweep URL: https://wandb.ai/aslan/Sweep_with_Attention/sweeps/ldn2b7uj\n","output_type":"stream"}]},{"cell_type":"code","source":"checkpoint_dir = './training_checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")","metadata":{"execution":{"iopub.status.busy":"2022-06-22T08:47:00.062429Z","iopub.execute_input":"2022-06-22T08:47:00.062777Z","iopub.status.idle":"2022-06-22T08:47:00.068454Z","shell.execute_reply.started":"2022-06-22T08:47:00.062742Z","shell.execute_reply":"2022-06-22T08:47:00.067382Z"},"trusted":true},"execution_count":158,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Synced <strong style=\"color:#cdcd00\">zany-sweep-6</strong>: <a href=\"https://wandb.ai/aslan/Sweep_with_Attention/runs/yehgdtam\" target=\"_blank\">https://wandb.ai/aslan/Sweep_with_Attention/runs/yehgdtam</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20220622_084643-yehgdtam/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"\ndef train(config = None):\n  with wandb.init(config=config):\n    config = wandb.config\n    #print(config)\n    s2s = Seq2Seq(num_encoder_tokens,num_decoder_tokens,config.encoder_embedding_dim, config.decoder_embedding_dim, config.unit_size, config.num_of_layer,config.unit_type , batch_size, config.dropout,config.recurrent_dropout)\n    if config.optimizer == \"adm\":\n        optimizer = tf.keras.optimizers.Adam()\n    else:\n        optimizer = tf.keras.optimizers.RMSprop()\n    checkpoint_dir = './training_checkpoints'\n    checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n    checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n                                 encoder=s2s.encoder,\n                                 decoder=s2s.dec,\n                                 )\n\n    # seq2seq.compile(optimizer=config.optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\",])\n    s2s.fit(\n        train_dataset,\n        val_dataset,\n        config.epochs,\n        loss_function,\n        optimizer,\n        checkpoint,\n        metric = tf.keras.metrics.SparseCategoricalAccuracy()\n        )\nwandb.agent(sweep_id, train)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T08:47:03.725899Z","iopub.execute_input":"2022-06-22T08:47:03.726698Z","iopub.status.idle":"2022-06-22T08:47:40.843588Z","shell.execute_reply.started":"2022-06-22T08:47:03.726658Z","shell.execute_reply":"2022-06-22T08:47:40.842563Z"},"trusted":true},"execution_count":159,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: q3uz0vdt with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_embedding_dim: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_embedding_dim: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_of_layer: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n\u001b[34m\u001b[1mwandb\u001b[0m: \trecurrent_dropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tunit_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tunit_type: gru\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.12.18"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20220622_084705-q3uz0vdt</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href=\"https://wandb.ai/aslan/Sweep_with_Attention/runs/q3uz0vdt\" target=\"_blank\">cerulean-sweep-7</a></strong> to <a href=\"https://wandb.ai/aslan/Sweep_with_Attention\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/aslan/Sweep_with_Attention/sweeps/ldn2b7uj\" target=\"_blank\">https://wandb.ai/aslan/Sweep_with_Attention/sweeps/ldn2b7uj</a>"},"metadata":{}},{"name":"stdout","text":"690\nValidatiion loss:  4.24052254813058\nValidatiion Acc:  6.773874419076102\nEpoch 1 Loss 0.0061\nAccuracy  0.0\nTime taken for 1 epoch 22.77253532409668 sec\n\nValidatiion loss:  4.239996337890625\nValidatiion Acc:  7.739323888506208\nEpoch 2 Loss 0.0061\nAccuracy  0.02769557678181192\nTime taken for 1 epoch 5.066967487335205 sec\n\nValidatiion loss:  4.237364850725446\nValidatiion Acc:  7.760850361415319\nEpoch 3 Loss 0.0061\nAccuracy  0.05197662806165391\nTime taken for 1 epoch 4.28864049911499 sec\n\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▅█</td></tr><tr><td>Train Accuracy</td><td>▁▅█</td></tr><tr><td>Train loss</td><td>█▆▁</td></tr><tr><td>Val Accuracy</td><td>▁██</td></tr><tr><td>Val Loss</td><td>█▇▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>3</td></tr><tr><td>Train Accuracy</td><td>0.05198</td></tr><tr><td>Train loss</td><td>0.00614</td></tr><tr><td>Val Accuracy</td><td>7.76085</td></tr><tr><td>Val Loss</td><td>4.23736</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Synced <strong style=\"color:#cdcd00\">cerulean-sweep-7</strong>: <a href=\"https://wandb.ai/aslan/Sweep_with_Attention/runs/q3uz0vdt\" target=\"_blank\">https://wandb.ai/aslan/Sweep_with_Attention/runs/q3uz0vdt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20220622_084705-q3uz0vdt/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"# !cat ./wandb/run-20220622_082243-tv6u3ywu/logs/debug.log","metadata":{"execution":{"iopub.status.busy":"2022-06-22T08:40:53.524413Z","iopub.execute_input":"2022-06-22T08:40:53.525141Z","iopub.status.idle":"2022-06-22T08:40:54.230409Z","shell.execute_reply.started":"2022-06-22T08:40:53.525094Z","shell.execute_reply":"2022-06-22T08:40:54.229187Z"},"trusted":true},"execution_count":106,"outputs":[{"name":"stdout","text":"cat: ./wandb/run-20220622_082243-tv6u3ywu/logs/debug.log: No such file or directory\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Visualisation","metadata":{}},{"cell_type":"code","source":"# def idx_to_word(word, translate_dict):\n#   return  \"\".join([translate_dict[char] for char in word])\n\n\n# idx_to_word(next(iter(train_dataset))[1][0].numpy(), reverse_target_token)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T15:13:03.197348Z","iopub.execute_input":"2022-06-22T15:13:03.197726Z","iopub.status.idle":"2022-06-22T15:13:03.219604Z","shell.execute_reply.started":"2022-06-22T15:13:03.197695Z","shell.execute_reply":"2022-06-22T15:13:03.218442Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stderr","text":"2022-06-22 15:13:03.212100: W tensorflow/core/data/root_dataset.cc:167] Optimization loop failed: Cancelled: Operation was cancelled\n","output_type":"stream"},{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"'अं\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'"},"metadata":{}}]},{"cell_type":"code","source":"# sample_out = s2s.call(val_enc_input_data[:batch_size], dec_input_data[:batch_size])","metadata":{"execution":{"iopub.status.busy":"2022-06-22T15:05:35.714418Z","iopub.execute_input":"2022-06-22T15:05:35.714834Z","iopub.status.idle":"2022-06-22T15:05:35.900777Z","shell.execute_reply.started":"2022-06-22T15:05:35.714778Z","shell.execute_reply":"2022-06-22T15:05:35.899881Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"# next(iter(train_dataset))[1][0].numpy()","metadata":{"execution":{"iopub.status.busy":"2022-06-22T15:12:39.864280Z","iopub.execute_input":"2022-06-22T15:12:39.864671Z","iopub.status.idle":"2022-06-22T15:12:39.887317Z","shell.execute_reply.started":"2022-06-22T15:12:39.864642Z","shell.execute_reply":"2022-06-22T15:12:39.886166Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stderr","text":"2022-06-22 15:12:39.879604: W tensorflow/core/data/root_dataset.cc:167] Optimization loop failed: Cancelled: Operation was cancelled\n","output_type":"stream"},{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"array([5., 3., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1.], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"# argmax(sample_out[0].rnn_output[], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T15:15:16.070342Z","iopub.execute_input":"2022-06-22T15:15:16.070774Z","iopub.status.idle":"2022-06-22T15:15:16.080627Z","shell.execute_reply.started":"2022-06-22T15:15:16.070737Z","shell.execute_reply":"2022-06-22T15:15:16.079502Z"},"trusted":true},"execution_count":70,"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"array([45,  3, 17, 43, 43, 51, 43, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51])"},"metadata":{}}]},{"cell_type":"code","source":"reverse_target_token","metadata":{"execution":{"iopub.status.busy":"2022-06-22T15:15:41.730527Z","iopub.execute_input":"2022-06-22T15:15:41.730948Z","iopub.status.idle":"2022-06-22T15:15:41.740387Z","shell.execute_reply.started":"2022-06-22T15:15:41.730913Z","shell.execute_reply":"2022-06-22T15:15:41.739138Z"},"trusted":true},"execution_count":71,"outputs":[{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"{0: '\\t',\n 1: '\\n',\n 2: 'ँ',\n 3: 'ं',\n 4: 'ः',\n 5: 'अ',\n 6: 'आ',\n 7: 'इ',\n 8: 'ई',\n 9: 'उ',\n 10: 'ऊ',\n 11: 'ऋ',\n 12: 'ए',\n 13: 'ऐ',\n 14: 'ऑ',\n 15: 'ओ',\n 16: 'औ',\n 17: 'क',\n 18: 'ख',\n 19: 'ग',\n 20: 'घ',\n 21: 'ङ',\n 22: 'च',\n 23: 'छ',\n 24: 'ज',\n 25: 'झ',\n 26: 'ञ',\n 27: 'ट',\n 28: 'ठ',\n 29: 'ड',\n 30: 'ढ',\n 31: 'ण',\n 32: 'त',\n 33: 'थ',\n 34: 'द',\n 35: 'ध',\n 36: 'न',\n 37: 'प',\n 38: 'फ',\n 39: 'ब',\n 40: 'भ',\n 41: 'म',\n 42: 'य',\n 43: 'र',\n 44: 'ल',\n 45: 'व',\n 46: 'श',\n 47: 'ष',\n 48: 'स',\n 49: 'ह',\n 50: '़',\n 51: 'ा',\n 52: 'ि',\n 53: 'ी',\n 54: 'ु',\n 55: 'ू',\n 56: 'ृ',\n 57: 'ॅ',\n 58: 'े',\n 59: 'ै',\n 60: 'ॉ',\n 61: 'ो',\n 62: 'ौ',\n 63: '्',\n 64: 'ॐ'}"},"metadata":{}}]},{"cell_type":"code","source":"idx_to_word(argmax(sample_out[0].rnn_output[0], axis = 1), reverse_target_token)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T15:08:36.085839Z","iopub.execute_input":"2022-06-22T15:08:36.086393Z","iopub.status.idle":"2022-06-22T15:08:36.095769Z","shell.execute_reply.started":"2022-06-22T15:08:36.086345Z","shell.execute_reply":"2022-06-22T15:08:36.094676Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"'वंकाााााााााााााा'"},"metadata":{}}]},{"cell_type":"code","source":"# val_enc_input_data[0]","metadata":{"id":"U-wA0D4dX2t4","outputId":"722a2932-202c-4ab3-867e-66cf6832e304","execution":{"iopub.status.busy":"2022-06-22T08:40:54.231991Z","iopub.execute_input":"2022-06-22T08:40:54.232765Z","iopub.status.idle":"2022-06-22T08:40:54.238258Z","shell.execute_reply.started":"2022-06-22T08:40:54.232718Z","shell.execute_reply":"2022-06-22T08:40:54.236892Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"# val_dec_input_data.shape","metadata":{"id":"SQOKJ5t2XxOr","outputId":"f0ba6934-b2c2-4f0b-8f50-ebb4d17d46a9","execution":{"iopub.status.busy":"2022-06-22T08:40:54.240229Z","iopub.execute_input":"2022-06-22T08:40:54.240604Z","iopub.status.idle":"2022-06-22T08:40:54.248328Z","shell.execute_reply.started":"2022-06-22T08:40:54.240569Z","shell.execute_reply":"2022-06-22T08:40:54.247316Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"# val_dec_target_data[110]","metadata":{"id":"0HDvOkuGWkWB","outputId":"dac5d6d6-afba-4c40-8124-560f0cfa7cdd","execution":{"iopub.status.busy":"2022-06-22T08:40:54.251633Z","iopub.execute_input":"2022-06-22T08:40:54.252469Z","iopub.status.idle":"2022-06-22T08:40:54.259440Z","shell.execute_reply.started":"2022-06-22T08:40:54.252439Z","shell.execute_reply":"2022-06-22T08:40:54.257999Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"# sample_out = s2s.call(val_enc_input_data[:batch_size], val_dec_input_data[:batch_size])","metadata":{"id":"QImBhPbTV9OG","outputId":"caa04bfb-856f-40fd-b42f-828c44ce851e","execution":{"iopub.status.busy":"2022-06-22T08:40:54.261490Z","iopub.execute_input":"2022-06-22T08:40:54.262325Z","iopub.status.idle":"2022-06-22T08:40:54.269448Z","shell.execute_reply.started":"2022-06-22T08:40:54.262287Z","shell.execute_reply":"2022-06-22T08:40:54.268335Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"# np.dot(1,np.equal(val_dec_target_data[0][:3], np.argmax(sample_out[0].rnn_output[0][:3], axis =1)))","metadata":{"id":"-e_OlFyHbqkM","outputId":"1351f30a-f6d4-4687-8253-5313265f860a","execution":{"iopub.status.busy":"2022-06-22T08:40:54.270615Z","iopub.execute_input":"2022-06-22T08:40:54.272280Z","iopub.status.idle":"2022-06-22T08:40:54.279550Z","shell.execute_reply.started":"2022-06-22T08:40:54.272243Z","shell.execute_reply":"2022-06-22T08:40:54.278601Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"code","source":"# sample_out[0].rnn_output[0].shape","metadata":{"id":"VS5o8Whhmf6n","outputId":"54830daa-2431-41e3-8a40-627459ad5fb9","execution":{"iopub.status.busy":"2022-06-22T08:40:54.281174Z","iopub.execute_input":"2022-06-22T08:40:54.281934Z","iopub.status.idle":"2022-06-22T08:40:54.291187Z","shell.execute_reply.started":"2022-06-22T08:40:54.281897Z","shell.execute_reply":"2022-06-22T08:40:54.290105Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"# val_dec_target_data[0][:3]","metadata":{"id":"MxvkjOlObMrK","outputId":"b54a4b1c-cefc-4924-8082-30f5d7cecd75","execution":{"iopub.status.busy":"2022-06-22T08:40:54.293030Z","iopub.execute_input":"2022-06-22T08:40:54.293853Z","iopub.status.idle":"2022-06-22T08:40:54.301355Z","shell.execute_reply.started":"2022-06-22T08:40:54.293815Z","shell.execute_reply":"2022-06-22T08:40:54.300392Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"# validation_target[0]","metadata":{"id":"f8e2y3aAbo69","outputId":"54e8f2b6-1444-41c6-82ba-4b8e08e97819","execution":{"iopub.status.busy":"2022-06-22T08:40:54.303165Z","iopub.execute_input":"2022-06-22T08:40:54.303438Z","iopub.status.idle":"2022-06-22T08:40:54.311303Z","shell.execute_reply.started":"2022-06-22T08:40:54.303402Z","shell.execute_reply":"2022-06-22T08:40:54.310315Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"# target_token","metadata":{"id":"FgavI_web2HG","execution":{"iopub.status.busy":"2022-06-22T08:40:54.312716Z","iopub.execute_input":"2022-06-22T08:40:54.313646Z","iopub.status.idle":"2022-06-22T08:40:54.322091Z","shell.execute_reply.started":"2022-06-22T08:40:54.313606Z","shell.execute_reply":"2022-06-22T08:40:54.321112Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"# #m = tf.keras.metrics.SparseCategoricalAccuracy()\n# m.update_state(val_dec_target_data[0], sample_out[0].rnn_output[0][:3])\n# m.result().numpy()","metadata":{"id":"ZdmMny5tcgsk","outputId":"13531154-fde4-463f-d351-779da7e42345","execution":{"iopub.status.busy":"2022-06-22T08:40:54.323631Z","iopub.execute_input":"2022-06-22T08:40:54.324459Z","iopub.status.idle":"2022-06-22T08:40:54.330950Z","shell.execute_reply.started":"2022-06-22T08:40:54.324383Z","shell.execute_reply":"2022-06-22T08:40:54.330032Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"# np.where(val_dec_target_data[0] == 1)","metadata":{"id":"NlSvaPXRg6eq","outputId":"71fe8e85-c003-4937-b33e-e8b302f81563","execution":{"iopub.status.busy":"2022-06-22T08:40:54.332304Z","iopub.execute_input":"2022-06-22T08:40:54.332862Z","iopub.status.idle":"2022-06-22T08:40:54.340248Z","shell.execute_reply.started":"2022-06-22T08:40:54.332825Z","shell.execute_reply":"2022-06-22T08:40:54.339065Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"# zip(val_dec_target_data, sample_out[0].rnn_output)","metadata":{"id":"V4t5mn2ff9fn","outputId":"7c43a97a-dbe0-48c2-bbd7-064332ff864a","execution":{"iopub.status.busy":"2022-06-22T08:40:54.341869Z","iopub.execute_input":"2022-06-22T08:40:54.342275Z","iopub.status.idle":"2022-06-22T08:40:54.350187Z","shell.execute_reply.started":"2022-06-22T08:40:54.342238Z","shell.execute_reply":"2022-06-22T08:40:54.349270Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"# loss_function(val_dec_input_data[:64], sample_out[0].rnn_output)","metadata":{"id":"GNf_vGipbGDC","outputId":"16d4ebbd-4c0c-4512-b94a-75d5ce403a9f","execution":{"iopub.status.busy":"2022-06-22T08:40:54.351586Z","iopub.execute_input":"2022-06-22T08:40:54.352637Z","iopub.status.idle":"2022-06-22T08:40:54.360820Z","shell.execute_reply.started":"2022-06-22T08:40:54.352599Z","shell.execute_reply":"2022-06-22T08:40:54.359829Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"# m = tf.keras.metrics.SparseCategoricalAccuracy()\n# step_per_val_epoch  = len(validation_input)//batch_size\n# m.update_state(val_dec_input_data[:64], sample_out[0].rnn_output)/step_per_val_epoch","metadata":{"id":"jnWZHZ3LcjuK","outputId":"98642f71-b68d-4383-ead7-3ed727c7df59","execution":{"iopub.status.busy":"2022-06-22T08:40:54.362369Z","iopub.execute_input":"2022-06-22T08:40:54.362889Z","iopub.status.idle":"2022-06-22T08:40:54.370603Z","shell.execute_reply.started":"2022-06-22T08:40:54.362853Z","shell.execute_reply":"2022-06-22T08:40:54.369671Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"#  dec_input_data[0]","metadata":{"id":"whKn8yCHhJqx","execution":{"iopub.status.busy":"2022-06-22T08:40:54.371991Z","iopub.execute_input":"2022-06-22T08:40:54.372577Z","iopub.status.idle":"2022-06-22T08:40:54.383628Z","shell.execute_reply.started":"2022-06-22T08:40:54.372541Z","shell.execute_reply":"2022-06-22T08:40:54.382410Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"# t = list(val_dataset)[:2]\n# x, y , z = t[0][0], t[0][1], t[1]","metadata":{"id":"IjsQSX3ICgBx","execution":{"iopub.status.busy":"2022-06-22T08:40:54.386945Z","iopub.execute_input":"2022-06-22T08:40:54.388167Z","iopub.status.idle":"2022-06-22T08:40:54.394437Z","shell.execute_reply.started":"2022-06-22T08:40:54.388108Z","shell.execute_reply":"2022-06-22T08:40:54.393189Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"# for val in t:\n#   enc_inp\n#   print(len(val[0]))","metadata":{"id":"Mh3Use5VC0lz","outputId":"a02d59e5-698d-49ca-f0d6-04ef44cd57fe","execution":{"iopub.status.busy":"2022-06-22T08:40:54.397056Z","iopub.execute_input":"2022-06-22T08:40:54.397540Z","iopub.status.idle":"2022-06-22T08:40:54.403271Z","shell.execute_reply.started":"2022-06-22T08:40:54.397476Z","shell.execute_reply":"2022-06-22T08:40:54.402205Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"# cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n# loss = cross_entropy(y_true=dec_target_data[:64], y_pred=sample_out[0].rnn_output)\n# loss","metadata":{"id":"Xd7eP7r0gNsA","outputId":"bedc2e89-acdb-4272-8b64-67579ed11384","execution":{"iopub.status.busy":"2022-06-22T08:40:54.404666Z","iopub.execute_input":"2022-06-22T08:40:54.406668Z","iopub.status.idle":"2022-06-22T08:40:54.412572Z","shell.execute_reply.started":"2022-06-22T08:40:54.406631Z","shell.execute_reply":"2022-06-22T08:40:54.411703Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"# for x, y in val_dataset:\n#   print(x.shape,y.shape)","metadata":{"id":"n8CBRHqXBFFh","outputId":"e3cf1a01-25a0-4f30-86d2-a12aac96a9ea","execution":{"iopub.status.busy":"2022-06-22T08:40:54.415765Z","iopub.execute_input":"2022-06-22T08:40:54.416580Z","iopub.status.idle":"2022-06-22T08:40:54.422092Z","shell.execute_reply.started":"2022-06-22T08:40:54.416546Z","shell.execute_reply":"2022-06-22T08:40:54.421110Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"code","source":"# x,y=val_dataset.take(1)","metadata":{"id":"N7kEoVlWRqvB","outputId":"62b45a85-7db9-40c9-a303-ce8f9d43d6df","execution":{"iopub.status.busy":"2022-06-22T08:40:54.423636Z","iopub.execute_input":"2022-06-22T08:40:54.424253Z","iopub.status.idle":"2022-06-22T08:40:54.431587Z","shell.execute_reply.started":"2022-06-22T08:40:54.424216Z","shell.execute_reply":"2022-06-22T08:40:54.430626Z"},"trusted":true},"execution_count":126,"outputs":[]},{"cell_type":"code","source":"# print(val_dataset.range(1))\n","metadata":{"id":"0_7v0t5_TsLX","outputId":"e4b2e112-2e42-4550-f5a1-9e7769a97b97","execution":{"iopub.status.busy":"2022-06-22T08:40:54.434832Z","iopub.execute_input":"2022-06-22T08:40:54.435272Z","iopub.status.idle":"2022-06-22T08:40:54.441950Z","shell.execute_reply.started":"2022-06-22T08:40:54.435243Z","shell.execute_reply":"2022-06-22T08:40:54.440996Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"\n# s2s.predict([val_enc_input_data,val_dec_input_data])","metadata":{"id":"rspjiEnida96","outputId":"7bcbea59-7118-4ab0-a7f0-1ae9ff60d9b8","execution":{"iopub.status.busy":"2022-06-22T08:40:54.443111Z","iopub.execute_input":"2022-06-22T08:40:54.444292Z","iopub.status.idle":"2022-06-22T08:40:54.451733Z","shell.execute_reply.started":"2022-06-22T08:40:54.444255Z","shell.execute_reply":"2022-06-22T08:40:54.450799Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"# s2s.compile(\n#     optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[tf.keras.metrics.CategoricalAccuracy(name='acc')]\n# )\n# input_data = tf.data.Dataset.from_tensor_slices((enc_input_data, dec_input_data))\n# target_data =  tf.data.Dataset.from_tensor_slices(dec_target_data)\n# train_dataset  = tf.data.Dataset.zip((input_data, target_data)).batch(batch_size)\n# #s2s.summary()\n# s2s.fit(\n#     train_dataset,\n#     batch_size=64,\n#     epochs=1,\n# )","metadata":{"id":"qK-34q8xNQi_","outputId":"38b5c0d0-2dde-4c04-f009-fd524fbe8e12","execution":{"iopub.status.busy":"2022-06-22T08:40:54.452756Z","iopub.execute_input":"2022-06-22T08:40:54.453013Z","iopub.status.idle":"2022-06-22T08:40:54.461777Z","shell.execute_reply.started":"2022-06-22T08:40:54.452988Z","shell.execute_reply":"2022-06-22T08:40:54.460656Z"},"trusted":true},"execution_count":129,"outputs":[]},{"cell_type":"code","source":"\n# class Seq2seq(tf.keras.Model):\n#   def __init__(self, num_encoder_tokens, num_decoder_tokens,embedding_dim,num_of_layers,unit_type, dropout , recurrent_dropout):\n#     super().__init__()\n#     self.encoder_inputs = Input(shape = (None,), name = \"Input_layer_1\")\n#     self.decoder_inputs = keras.Input(shape=(None,), name = \"Input_layer_2\")\n#     self.num_encoder_tokens = num_encoder_tokens\n#     self.embedding_dim = embedding_dim\n#     self.dropout = dropout\n#     self.recurrent_dropout = recurrent_dropout\n#     self.num_decoder_tokens = num_decoder_tokens\n#     self.num_of_encoder_layer  =num_of_layers\n#     self.num_of_decoder_layer =num_of_layers\n#     self.type_encoder_unit =unit_type \n#     self.type_decoder_unit =unit_type\n#     self.train_step()\n#     self.build_model()\n\n#   def get_embedding_layer(self, num_encoder_tokens, embedding_dim,  name):\n#     return Embedding(num_encoder_tokens, embedding_dim, mask_zero = True, name =name )\n\n#   def get_cell(self, cell_type = \"lstm\", num_of_cell = 1, name = None):\n#     #print(cell_type)\n#     if cell_type == \"lstm\":\n#       return LSTMCell(num_of_cell, dropout = self.dropout, recurrent_dropout = self.recurrent_dropout, )\n#     elif cell_type == \"rnn\":\n#       return SimpleRNNCell(num_of_cell, dropout = self.dropout, recurrent_dropout = self.recurrent_dropout)\n#     elif cell_type ==\"gru\":\n#       return GRUCell(num_of_cell, dropout = self.dropout, recurrent_dropout = self.recurrent_dropout)\n#     else:\n#       print(f\"Invalid cell type: {cell_type}\")\n#   def get_encoder(self,latent_dim, cell_type = \"lstm\", num_of_layer = 1, name = None ):\n#     return tf.keras.layers.RNN(tf.keras.layers.StackedRNNCells( [self.get_cell(cell_type, latent_dim) for i in range(num_of_layer)],), return_sequences=True, return_state=True, name = name)\n\n#   def get_decoder(self,latent_dim ,cell_type = \"lstm\", num_of_layer = 1, name = None ):\n#     return tf.keras.layers.RNN(tf.keras.layers.StackedRNNCells( [self.get_cell(cell_type, latent_dim,) for i in range(num_of_layer)]), return_sequences=True, return_state=True)\n\n#   def get_dense_layer(self, num_decoder_token, activation = \"softmax\"):\n#     return Dense(num_decoder_tokens, activation= activation)\n\n#   def train_step(self):\n#     self.embedding_layer = self.get_embedding_layer( self.num_encoder_tokens, self.embedding_dim ,name = \"encoder_embedding\")\n#     self.embedding_results = self.embedding_layer(self.encoder_inputs)\n#     print(self.embedding_results.shape)\n#     self.encoder = self.get_encoder( self.embedding_dim,self.type_encoder_unit, self.num_of_encoder_layer , name =\"encoder\" )\n#     encoder_results = self.encoder(self.embedding_results)\n\n#     self.encoder_outputs, self.encoder_states = encoder_results[0], encoder_results[1:]\n\n#     self.embedding_layer2 = self.get_embedding_layer( self.num_decoder_tokens, self.embedding_dim, name = \"decoder_embedding\")\n#     self.embedding_results2 = self.embedding_layer2(self.decoder_inputs,)\n\n#     self.decoder = self.get_decoder( self.embedding_dim, self.type_decoder_unit, self.num_of_decoder_layer,)\n#     self.decoder_results = self.decoder(self.embedding_results2, initial_state=self.encoder_states)\n\n#     self.decoder_output = self.decoder_results[0]\n#     self.decoder_dense = self.get_dense_layer(self.num_decoder_tokens)\n#     self.dense_output = self.decoder_dense(self.decoder_output)\n\n#   def build_model(self):\n    \n#     self.model = keras.Model([self.encoder_inputs, self.decoder_inputs], self.dense_output, name = \"Seq2Seq_model\")\n#     return self.model\n\n","metadata":{"id":"x9fpzXhN7DMU","execution":{"iopub.status.busy":"2022-06-22T08:40:54.464660Z","iopub.execute_input":"2022-06-22T08:40:54.464946Z","iopub.status.idle":"2022-06-22T08:40:54.474270Z","shell.execute_reply.started":"2022-06-22T08:40:54.464922Z","shell.execute_reply":"2022-06-22T08:40:54.473317Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"code","source":"\n# seq2seq = Seq2seq(num_encoder_tokens,num_decoder_tokens, 1024,1,\"rnn\", 0.0, 0.0).build_model()\n# seq2seq.summary()","metadata":{"id":"qJ07iEXsJr6K","outputId":"f82e8d28-64d7-4a30-9437-d3dbaba684b5","execution":{"iopub.status.busy":"2022-06-22T08:40:54.475595Z","iopub.execute_input":"2022-06-22T08:40:54.476619Z","iopub.status.idle":"2022-06-22T08:40:54.487298Z","shell.execute_reply.started":"2022-06-22T08:40:54.476582Z","shell.execute_reply":"2022-06-22T08:40:54.486306Z"},"trusted":true},"execution_count":131,"outputs":[]},{"cell_type":"markdown","source":"## Train the model\n","metadata":{"id":"HXZ2_xdsAQee"}},{"cell_type":"code","source":"# s2s.compile(\n#     optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[tf.keras.metrics.CategoricalAccuracy(name='acc')]\n# )\n\n# s2s.fit(\n#     [enc_input_data, dec_input_data],\n#     dec_target_data,\n#     batch_size=64,\n#     epochs=1,\n# )","metadata":{"id":"Haec2CJvrP32","outputId":"3f520910-41d6-464c-bbb4-6ebef57a7b5d","execution":{"iopub.status.busy":"2022-06-22T08:40:54.488811Z","iopub.execute_input":"2022-06-22T08:40:54.489835Z","iopub.status.idle":"2022-06-22T08:40:54.497421Z","shell.execute_reply.started":"2022-06-22T08:40:54.489759Z","shell.execute_reply":"2022-06-22T08:40:54.496393Z"},"trusted":true},"execution_count":132,"outputs":[]},{"cell_type":"code","source":"# class BeamSearch(keras.callbacks.Callback):\n\n#   def __init__(self, beam_size):\n#     self.beam_size = beam_size\n\n#   def beam_search_decoder(aelf, data, k):\n#     sequences = [[list(), 0.0]]\n#     # walk over each step in sequence\n#     for row in data:\n#       all_candidates = list()\n#       # expand each current candidate\n#       for i in range(len(sequences)):\n#         seq, score = sequences[i]\n#         for j in range(len(row)):\n#           candidate = [seq + [j], score - log(row[j])]\n#           all_candidates.append(candidate)\n#       # order all candidates by score\n#       ordered = sorted(all_candidates, key=lambda tup:tup[1])\n#       # select k best\n#       sequences = ordered[:k]\n#     return sequences\n  \n#   def on_epoch_end(self, epoch, logs = None):\n#     prediction = self.model.predict([val_enc_input_data , val_dec_input_data])\n#     print(prediction.shape)\n#     for i, pred in enumerate(prediction):\n#       beam_search_prediction = self.beam_search_decoder(pred, self.beam_size)\n#       correct_prediction = 0\n#       for k in range(self.beam_size):\n#         #translated_word = \"\\t\"+\"\".join([reverse_target_token[x] for x in beam_search_prediction[k][0][:len(validation_target[i])-1]])\n#         #print(translated_word, validation_target[i])\n#         #print(validation_target[i])\n        \n#         def idx2char(idx_list):\n#           return \"\".join([reverse_target_token[x] for x in idx_list])\n\n#         if \"\\t\"+ idx2char(beam_search_prediction[k][0][:len(validation_target[i])-1]) == validation_target[i]:\n#           correct_prediction+=1\n#           break\n#     mul = 10.0**2\n#     logs[\"character_accuracy\"] = ((correct_prediction/prediction.shape[0])*mul)/mul\n#     print(\"- character_accuracy\",logs[\"character_accuracy\"])\n#     #print(f\"Accuracy by Beam Search {correct_prediction/len(validation_target)}\")\n#       # print(len(beam_search_prediction))\n#       # print(beam_search_prediction)\n","metadata":{"id":"KPyDujbe-Brq","execution":{"iopub.status.busy":"2022-06-22T08:40:54.498965Z","iopub.execute_input":"2022-06-22T08:40:54.499402Z","iopub.status.idle":"2022-06-22T08:40:54.508679Z","shell.execute_reply.started":"2022-06-22T08:40:54.499367Z","shell.execute_reply":"2022-06-22T08:40:54.507682Z"},"trusted":true},"execution_count":133,"outputs":[]},{"cell_type":"code","source":"# def beam_search_decoder(data, k):\n#     decodedWords = [[list(), 0.0]]\n#     # walk over each step in sequence\n#     for word in data:\n#       candidates = list()\n#       # expand each current candidate\n#       for sequence in decodedWords:\n#         seq, score = sequence\n#         for j in range(len(word)):\n#           candidate = [seq + [j], score - log(word[j])]\n#           candidates.append(candidate)\n#       # order all candidates by score\n#       ordered = sorted(candidates, key=lambda a:a[1])\n#       # select k best\n#       decodedWords = ordered[:k]\n#     return decodedWords\n  \n# def translate(seq):\n#   sentence = [] \n#   for x in seq:\n#     char = reverse_target_token[x]\n#     sentence.append(char)\n#   return \"\".join(sentence)\n# class WordAccuracyCallback(keras.callbacks.Callback):\n#   def __init__(self,beam_size):\n#     self.beam_size=beam_size\n#   def on_epoch_end(self, epoch, logs=None):\n#     pred=self.model.predict([val_enc_input_data , val_dec_input_data])\n#     count=0\n#     for i in range(pred.shape[0]):\n#       pSequences=beam_search_decoder(pred[i],self.beam_size)\n#       for j in range(self.beam_size):\n#         if \"\\t\"+translate(pSequences[j][0][:len(validation_target[i])-1])==validation_target[i]:\n#           count=count+1\n#           break\n#     factor = 10.0 ** 4\n#     logs[\"WordAccuracy\"]=math.trunc((count/pred.shape[0])*factor)/factor\n#     print(\"- wordAccuracy:\",logs[\"WordAccuracy\"])","metadata":{"id":"FE8vtOJOrP33","execution":{"iopub.status.busy":"2022-06-22T08:40:54.511515Z","iopub.execute_input":"2022-06-22T08:40:54.512413Z","iopub.status.idle":"2022-06-22T08:40:54.523285Z","shell.execute_reply.started":"2022-06-22T08:40:54.512372Z","shell.execute_reply":"2022-06-22T08:40:54.522209Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"code","source":"# sweep_config = {\n    \n#     'method':'bayes',\n#     'metric': {\n#         'name':'val_accuracy',\n#         'goal':'maximize'\n#     },\n#     'parameters':{\n    \n#     \"num_of_layer\" : {'values': [1,2,3]},\n#     \"unit_size\": {\"values\":[16,32,64]},\n#     \"unit_type\": {\"values\":[\"lstm\",\"rnn\",\"gru\"]},\n#     \"dropout\": {\"values\": [0.0, 0.2, 0.4]},\n#     'recurrent_dropout':{'values':[0.0,0.3]},\n#     \"beam_size\" : {\"values\":[1,2,3,4]},\n#     \"epochs\":{\"value\":20},  \n#     \"optimizer\":{\"values\": [\"adam\",\"rmsprop\"]}             \n#                    }\n# }\n\n\n\n# pprint.pprint(sweep_config)","metadata":{"id":"mIW2Ofow5Deo","outputId":"0c99b3cb-eaac-4b1e-acfa-1aff5a6bad9e","execution":{"iopub.status.busy":"2022-06-22T08:40:54.524966Z","iopub.execute_input":"2022-06-22T08:40:54.525496Z","iopub.status.idle":"2022-06-22T08:40:54.536165Z","shell.execute_reply.started":"2022-06-22T08:40:54.525411Z","shell.execute_reply":"2022-06-22T08:40:54.535173Z"},"trusted":true},"execution_count":135,"outputs":[]},{"cell_type":"code","source":"# sweep_id = wandb.sweep(sweep_config, project=\"seq2seq\")","metadata":{"id":"x8YmtLZN_74p","execution":{"iopub.status.busy":"2022-06-22T08:40:54.537711Z","iopub.execute_input":"2022-06-22T08:40:54.538120Z","iopub.status.idle":"2022-06-22T08:40:54.545489Z","shell.execute_reply.started":"2022-06-22T08:40:54.538084Z","shell.execute_reply":"2022-06-22T08:40:54.544525Z"},"trusted":true},"execution_count":136,"outputs":[]},{"cell_type":"code","source":"# def train(config = None):\n#   with wandb.init(config=config):\n#     config = wandb.config\n#     #print(config)\n#     seq2seq = Seq2seq(num_encoder_tokens,num_decoder_tokens, config.unit_size, config.num_of_layer,config.unit_type , config.dropout,config.recurrent_dropout).build_model()\n#     seq2seq.compile(optimizer=config.optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\",])\n#     seq2seq.fit(\n#         [encoder_input_data, decoder_input_data],\n#         decoder_target_data,\n#         batch_size=batch_size,\n#         epochs=config.epochs,\n#         validation_data =  ([validation_encoder_input_data , validation_decoder_input_data] ,validation_decoder_target_data),\n#         callbacks = [BeamSearch(config.beam_size), WandbCallback()],verbose = 1, \n#         )\n\n\n    \n    \n# wandb.agent(sweep_id, train)","metadata":{"id":"qYv2feSRAzW_","execution":{"iopub.status.busy":"2022-06-22T08:40:54.547019Z","iopub.execute_input":"2022-06-22T08:40:54.549119Z","iopub.status.idle":"2022-06-22T08:40:54.559107Z","shell.execute_reply.started":"2022-06-22T08:40:54.549080Z","shell.execute_reply":"2022-06-22T08:40:54.558099Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"code","source":"# seq2seq.compile(\n#     optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[tf.keras.metrics.CategoricalAccuracy(name='acc')]\n# )\n# seq2seq.metrics_names\n\n","metadata":{"id":"DIrCXZTAGyTL","outputId":"0b540428-89cc-4ac6-ed17-8fc3bffafd6c","execution":{"iopub.status.busy":"2022-06-22T08:40:54.560462Z","iopub.execute_input":"2022-06-22T08:40:54.561904Z","iopub.status.idle":"2022-06-22T08:40:54.570362Z","shell.execute_reply.started":"2022-06-22T08:40:54.561875Z","shell.execute_reply":"2022-06-22T08:40:54.569403Z"},"trusted":true},"execution_count":138,"outputs":[]},{"cell_type":"code","source":"# pred=seq2seq.predict([val_enc_input_data , val_dec_input_data])\n# count=0\n# for i in range(pred.shape[0]//400):\n#       pSequences=beam_search_decoder(pred[i],3)\n#       for j in range(3):\n#         print({\"\\t\"+translate(pSequences[j][0][:len(validation_target[i])-1])}, \"original =\", {validation_target[i]} )\n#         if \"\\t\"+translate(pSequences[j][0][:len(validation_target[i])-1])==validation_target[i]:\n#           count=count+1\n#           print(\"yes\")\n#           break\n# factor = 10.0 ** 4\n","metadata":{"scrolled":true,"id":"xLTgqB68rP35","outputId":"416e74fe-2665-4117-c579-56eb7c7beade","execution":{"iopub.status.busy":"2022-06-22T08:40:54.571737Z","iopub.execute_input":"2022-06-22T08:40:54.572805Z","iopub.status.idle":"2022-06-22T08:40:54.585190Z","shell.execute_reply.started":"2022-06-22T08:40:54.572766Z","shell.execute_reply":"2022-06-22T08:40:54.584271Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"code","source":"# x = seq2seq.predict([val_enc_input_data , val_dec_input_data])\n# x.shape","metadata":{"id":"qnzLTsbxrP36","outputId":"357821dd-b5f9-4924-add4-0ebd058f94a7","execution":{"iopub.status.busy":"2022-06-22T08:40:54.586627Z","iopub.execute_input":"2022-06-22T08:40:54.587428Z","iopub.status.idle":"2022-06-22T08:40:54.595067Z","shell.execute_reply.started":"2022-06-22T08:40:54.587383Z","shell.execute_reply":"2022-06-22T08:40:54.594095Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"\n# histotry = seq2seq.fit(\n#     [enc_input_data, dec_input_data],\n#     dec_target_data,\n#     batch_size=8192,\n#     epochs=1,\n#     callbacks = [WordAccuracyCallback(3), ],\n# )\n# # Save model\n# seq2seq.save(\"s2s\")\n","metadata":{"id":"ox_fyYUrAQef","outputId":"f4da868c-355c-4132-8481-e4ffcb605de4","execution":{"iopub.status.busy":"2022-06-22T08:40:54.596529Z","iopub.execute_input":"2022-06-22T08:40:54.597146Z","iopub.status.idle":"2022-06-22T08:40:54.604963Z","shell.execute_reply.started":"2022-06-22T08:40:54.597110Z","shell.execute_reply":"2022-06-22T08:40:54.604015Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"code","source":"# for key in histotry.history.keys():\n#       print(key , histotry.history[key])\n#       #wandb.log({key : histotry.history[key]})","metadata":{"id":"2BnI7lHtQtnT","execution":{"iopub.status.busy":"2022-06-22T08:40:54.607382Z","iopub.execute_input":"2022-06-22T08:40:54.610450Z","iopub.status.idle":"2022-06-22T08:40:54.614888Z","shell.execute_reply.started":"2022-06-22T08:40:54.610409Z","shell.execute_reply":"2022-06-22T08:40:54.613941Z"},"trusted":true},"execution_count":142,"outputs":[]},{"cell_type":"code","source":"# seq2seq.metrics_names","metadata":{"id":"Npqd4if4HVZT","execution":{"iopub.status.busy":"2022-06-22T08:40:54.616603Z","iopub.execute_input":"2022-06-22T08:40:54.617516Z","iopub.status.idle":"2022-06-22T08:40:54.624584Z","shell.execute_reply.started":"2022-06-22T08:40:54.617387Z","shell.execute_reply":"2022-06-22T08:40:54.623466Z"},"trusted":true},"execution_count":143,"outputs":[]},{"cell_type":"markdown","source":"## Run inference (sampling)\n\n1. encode input and retrieve initial decoder state\n2. run one step of decoder with this initial state\nand a \"start of sequence\" token as target.\nOutput will be the next target token.\n3. Repeat with the current target token and current states\n","metadata":{"id":"BC5CbwHlAQef"}},{"cell_type":"code","source":"# # Define sampling models\n# # Restore the model and construct the encoder and decoder.\n# model = keras.models.load_model(\"s2s\")\n\n# encoder_inputs = model.input[0]  # input_1\n# temp = model.layers[2].output\n# encoder_outputs, state = temp[0], temp[1:]  # lstm_1\n# encoder_states = state\n# encoder_model = keras.Model(encoder_inputs, encoder_states)\n\n# decoder_inputs = model.input[1]  # input_2\n# decoder_state_input_h = keras.Input(shape=(latent_dim,))\n# decoder_state_input_c = keras.Input(shape=(latent_dim,))\n# decoder_states_inputs = state\n# decoder_lstm = model.layers[3]\n# temp = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n# decoder_outputs, state_dec = temp[0], temp[1:]\n# decoder_states = state_dec\n# decoder_dense = model.layers[4]\n# decoder_outputs = decoder_dense(decoder_outputs)\n# decoder_model = keras.Model(\n#     [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n# )\n\n# # Reverse-lookup token index to decode sequences back to\n# # something readable.\n# # reverse_input_char_index = dict((i, char) for char, i in num_encoder_tokens.items())\n# # reverse_target_char_index = dict((i, char) for char, i in num_decoder_tokens.items())\n# # print(reverse_input_char_index)\n# # print(input_token_index)\n\n# reverse_input_token = dict((i, char) for char, i in input_token.items())\n# reverse_target_token = dict((i, char) for char, i in target_token.items())\n# def decode_sequence(input_seq):\n#     # Encode the input as state vectors.\n#     states_value = encoder_model.predict(input_seq)\n\n#     # Generate empty target sequence of length 1.\n#     target_seq = np.zeros((1, 1, num_decoder_tokens))\n#     # Populate the first character of target sequence with the start character.\n#     target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n\n#     # Sampling loop for a batch of sequences\n#     # (to simplify, here we assume a batch of size 1).\n#     stop_condition = False\n#     decoded_sentence = \"\"\n#     while not stop_condition:\n#         temp = decoder_model.predict([target_seq] + states_value)\n#         output_tokens, state = temp[0],temp[1:]\n\n#         # Sample a token\n#         sampled_token_index = np.argmax(output_tokens[0, -1, :])\n#         #print(reverse_target_char_index)\n#         sampled_char = reverse_target_token[sampled_token_index]\n#         decoded_sentence += sampled_char\n\n#         # Exit condition: either hit max length\n#         # or find stop character.\n#         if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n#             stop_condition = True\n\n#         # Update the target sequence (of length 1).\n#         target_seq = np.zeros((1, 1, num_decoder_tokens))\n#         target_seq[0, 0, sampled_token_index] = 1.0\n\n#         # Update states\n#         states_value = state\n#     return decoded_sentence\n\n","metadata":{"id":"meuadqgkAQeg","execution":{"iopub.status.busy":"2022-06-22T08:40:54.626328Z","iopub.execute_input":"2022-06-22T08:40:54.626998Z","iopub.status.idle":"2022-06-22T08:40:54.637456Z","shell.execute_reply.started":"2022-06-22T08:40:54.626963Z","shell.execute_reply":"2022-06-22T08:40:54.636537Z"},"trusted":true},"execution_count":144,"outputs":[]},{"cell_type":"markdown","source":"You can now generate decoded sentences as such:\n","metadata":{"id":"nSNoQ5AvAQeh"}},{"cell_type":"code","source":"# for seq_index in range(20):\n#     # Take one sequence (part of the training set)\n#     # for trying out decoding.\n#     input_seq = encoder_input_data[seq_index : seq_index + 1]\n#     decoded_sentence = decode_sequence(input_seq)\n#     print(\"-\")\n#     print(\"Input sentence:\", input_texts[seq_index])\n#     print(\"Decoded sentence:\", decoded_sentence)\n","metadata":{"id":"wjp__2oJAQeh","execution":{"iopub.status.busy":"2022-06-22T08:40:54.640429Z","iopub.execute_input":"2022-06-22T08:40:54.640681Z","iopub.status.idle":"2022-06-22T08:40:54.650442Z","shell.execute_reply.started":"2022-06-22T08:40:54.640650Z","shell.execute_reply":"2022-06-22T08:40:54.649491Z"},"trusted":true},"execution_count":145,"outputs":[]},{"cell_type":"code","source":"# ! git log","metadata":{"id":"ygwmClalB8vI","outputId":"09f6fff2-5b5d-42a4-e7b8-2e20df103971","execution":{"iopub.status.busy":"2022-06-22T08:40:54.651773Z","iopub.execute_input":"2022-06-22T08:40:54.652760Z","iopub.status.idle":"2022-06-22T08:40:54.659890Z","shell.execute_reply.started":"2022-06-22T08:40:54.652699Z","shell.execute_reply":"2022-06-22T08:40:54.658996Z"},"trusted":true},"execution_count":146,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"lzaKcIYKrP39"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"oX52e6mtrP39"},"execution_count":null,"outputs":[]}]}