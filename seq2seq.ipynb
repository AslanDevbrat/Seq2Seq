{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Setup\n","metadata":{"id":"XtD33RcAAQeV"}},{"cell_type":"code","source":"%%capture\n!pip install wandb --upgrade\n!pip install tensorflow-addons","metadata":{"id":"UBUz4pd87YeP","execution":{"iopub.status.busy":"2022-06-19T11:46:04.715027Z","iopub.execute_input":"2022-06-19T11:46:04.715895Z","iopub.status.idle":"2022-06-19T11:46:36.340025Z","shell.execute_reply.started":"2022-06-19T11:46:04.715742Z","shell.execute_reply":"2022-06-19T11:46:36.338600Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Embedding, SimpleRNNCell, GRUCell, Dense, LSTMCell\nfrom tensorflow.keras import Input\nimport pandas as pd\nfrom numpy import argmax\nfrom math import log\nimport pprint\nimport math\nimport wandb\nimport os\nimport io\nfrom wandb.keras import WandbCallback\n\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nwandb_api = user_secrets.get_secret(\"wandb_api\")\n\n#wandb.login(key=wandb_api)\n! wandb login $wandb_api\n\nos.environ[\"WANDB_SILENT\"] = \"true\"\n#wandb.login()","metadata":{"id":"EnvOeSibAQeV","outputId":"f95e4ee6-b5fe-4d8c-d213-09537e181a3a","execution":{"iopub.status.busy":"2022-06-19T14:55:00.466081Z","iopub.execute_input":"2022-06-19T14:55:00.466557Z","iopub.status.idle":"2022-06-19T14:55:04.846701Z","shell.execute_reply.started":"2022-06-19T14:55:00.466520Z","shell.execute_reply":"2022-06-19T14:55:04.844596Z"},"trusted":true},"execution_count":241,"outputs":[]},{"cell_type":"markdown","source":"## Download the data\n","metadata":{"id":"NbOpYTqYAQeX"}},{"cell_type":"markdown","source":"## Configuration\n","metadata":{"id":"1rKnaKIZAQeZ"}},{"cell_type":"code","source":"!wget  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n!tar -xf 'dakshina_dataset_v1.0.tar'\ntrain_file_path = \"./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\"\nval_file_path= \"./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv\"\ntest_file_path  = \"./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv\"","metadata":{"id":"roFBlOuMAYkx","outputId":"f350e9d6-8977-40bf-8b2e-053cb1d9eccc","execution":{"iopub.status.busy":"2022-06-19T11:47:33.470862Z","iopub.execute_input":"2022-06-19T11:47:33.471940Z","iopub.status.idle":"2022-06-19T11:47:49.677198Z","shell.execute_reply.started":"2022-06-19T11:47:33.471901Z","shell.execute_reply":"2022-06-19T11:47:49.676010Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"--2022-06-19 11:47:34--  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\nResolving storage.googleapis.com (storage.googleapis.com)... 74.125.141.128, 172.217.193.128, 142.250.97.128, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|74.125.141.128|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2008340480 (1.9G) [application/x-tar]\nSaving to: ‘dakshina_dataset_v1.0.tar’\n\ndakshina_dataset_v1 100%[===================>]   1.87G   204MB/s    in 9.0s    \n\n2022-06-19 11:47:43 (214 MB/s) - ‘dakshina_dataset_v1.0.tar’ saved [2008340480/2008340480]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size = 256  # Batch size for training.\nepochs = 100  # Number of epochs to train for.\nlatent_dim = 256  # Latent dimensionality of the encoding space.\nnum_samples = 100000  # Number of samples to train on.\n# Path to the data txt file on disk.\ndata_path = train_file_path\n","metadata":{"id":"akMCxfVHAQeZ","execution":{"iopub.status.busy":"2022-06-19T09:33:02.211259Z","iopub.execute_input":"2022-06-19T09:33:02.211737Z","iopub.status.idle":"2022-06-19T09:33:02.219013Z","shell.execute_reply.started":"2022-06-19T09:33:02.211682Z","shell.execute_reply":"2022-06-19T09:33:02.217846Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Prepare the data\n","metadata":{"id":"U-3Djb36AQea"}},{"cell_type":"code","source":"def processData(filename,input_chars=set(),target_chars=set()):\n  input=[]\n  target=[]\n  with open(filename, \"r\", encoding=\"utf-8\") as f:\n    lines = f.read().split(\"\\n\")\n  for line in lines[:len(lines) -1]:\n      t_text,i_text, attestation = line.split(\"\\t\")\n       # We use \"\\t\" as the \"start sequence\" character and \"\\n\" as \"end sequence\" character for the target text.\n      input.append(i_text)\n      target.append(\"\\t\"+t_text+\"\\n\")\n      for char in i_text:\n        if char not in input_chars:\n            input_chars.add(char)\n      for char in t_text:\n        if char not in target_chars:\n            target_chars.add(char)\n  target_chars.add(\"\\t\")\n  target_chars.add(\"\\n\")\n\n  input_chars = sorted(list(input_chars))\n  target_chars = sorted(list(target_chars))\n  num_encoder_tokens = len(input_chars)\n  num_decoder_tokens = len(target_chars)\n  max_encoder_seq_length = max([len(txt) for txt in input])\n  max_decoder_seq_length = max([len(txt) for txt in target])\n  return input,target,input_chars,target_chars,num_encoder_tokens,num_decoder_tokens, max_encoder_seq_length, max_decoder_seq_length     ","metadata":{"id":"5CZtxlJmaYmb","execution":{"iopub.status.busy":"2022-06-19T15:21:54.385136Z","iopub.execute_input":"2022-06-19T15:21:54.385606Z","iopub.status.idle":"2022-06-19T15:21:54.397778Z","shell.execute_reply.started":"2022-06-19T15:21:54.385570Z","shell.execute_reply":"2022-06-19T15:21:54.396551Z"},"trusted":true},"execution_count":287,"outputs":[]},{"cell_type":"code","source":"# Vectorize the data.\ninput,target,input_chars,target_chars,num_encoder_tokens,num_decoder_tokens, max_encoder_seq_length, max_decoder_seq_length=processData(train_file_path)\nprint(\"Number of samples:\", len(input))\nprint(\"Number of unique input tokens:\", num_encoder_tokens)\nprint(\"Number of unique output tokens:\", num_decoder_tokens)\nprint(\"Max sequence length for inputs:\", max_encoder_seq_length)\nprint(\"Max sequence length for outputs:\", max_decoder_seq_length)","metadata":{"id":"pg8AcuMoab8U","outputId":"94042a09-cb1c-4182-8175-481f6b21296b","execution":{"iopub.status.busy":"2022-06-19T15:21:56.055100Z","iopub.execute_input":"2022-06-19T15:21:56.055975Z","iopub.status.idle":"2022-06-19T15:21:56.181503Z","shell.execute_reply.started":"2022-06-19T15:21:56.055922Z","shell.execute_reply":"2022-06-19T15:21:56.179927Z"},"trusted":true},"execution_count":288,"outputs":[{"name":"stdout","text":"Number of samples: 44204\nNumber of unique input tokens: 26\nNumber of unique output tokens: 65\nMax sequence length for inputs: 20\nMax sequence length for outputs: 21\n","output_type":"stream"}]},{"cell_type":"code","source":"# Vectorize the data.\n# Vectorize the data.\nvalidation_input,validation_target,input_chars,target_chars,num_encoder_tokens,num_decoder_tokens, validation_max_encoder_seq_length, validation_max_decoder_seq_length=processData(val_file_path,set(input_chars),set(target_chars))\n\nprint(\"Number of validation samples:\", len(validation_input))\nprint(\"Number of unique input tokens:\", num_encoder_tokens)\nprint(\"Number of unique output tokens:\", num_decoder_tokens)\nprint(\"validation Max sequence length for inputs:\", validation_max_encoder_seq_length)\nprint(\"validation Max sequence length for outputs:\", validation_max_decoder_seq_length)","metadata":{"id":"lmCnQKWNbsuh","outputId":"b5e3c96e-e6be-484d-8f4d-1fd73bcd49e2","execution":{"iopub.status.busy":"2022-06-19T15:32:00.457765Z","iopub.execute_input":"2022-06-19T15:32:00.458307Z","iopub.status.idle":"2022-06-19T15:32:00.484257Z","shell.execute_reply.started":"2022-06-19T15:32:00.458272Z","shell.execute_reply":"2022-06-19T15:32:00.482872Z"},"trusted":true},"execution_count":297,"outputs":[{"name":"stdout","text":"Number of validation samples: 4502\nNumber of unique input tokens: 26\nNumber of unique output tokens: 65\nvalidation Max sequence length for inputs: 16\nvalidation Max sequence length for outputs: 17\n","output_type":"stream"}]},{"cell_type":"code","source":"# Vectorize the data.\ntest_input,test_target,test_input_chars,test_target_chars,test_num_encoder_tokens,test_num_decoder_tokens, test_max_encoder_seq_length, test_max_decoder_seq_length=processData(test_file_path)\nprint(\"Number of validation samples:\", len(test_input))\nprint(\"Test Max sequence length for inputs:\", test_max_encoder_seq_length)\nprint(\"Test Max sequence length for outputs:\", test_max_decoder_seq_length)","metadata":{"id":"Q9tUFlovbz5i","outputId":"e3075907-8f4a-4445-efce-1a9db0c360cb","execution":{"iopub.status.busy":"2022-06-19T15:05:18.181757Z","iopub.execute_input":"2022-06-19T15:05:18.182569Z","iopub.status.idle":"2022-06-19T15:05:18.200082Z","shell.execute_reply.started":"2022-06-19T15:05:18.182519Z","shell.execute_reply":"2022-06-19T15:05:18.199204Z"},"trusted":true},"execution_count":263,"outputs":[{"name":"stdout","text":"Number of validation samples: 4358\nTest Max sequence length for inputs: 18\nTest Max sequence length for outputs: 16\n","output_type":"stream"}]},{"cell_type":"code","source":"input_token = dict([(char, i) for i, char in enumerate(input_chars)])\ntarget_token = dict([(char, i) for i, char in enumerate(target_chars)])\n\nreverse_input_token = dict((i, char) for char, i in input_token.items())\nreverse_target_token = dict((i, char) for char, i in target_token.items())\n\n\nencoder_input_data = np.zeros(\n    (len(input), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n)\nvalidation_encoder_input_data=np.zeros(\n    (len(validation_input), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n)\ntest_encoder_input_data=np.zeros(\n    (len(test_input), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n)\ndecoder_input_data = np.zeros(\n    (len(input), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n)\nvalidation_decoder_input_data =np.zeros(\n    (len(validation_input), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n)\ndecoder_target_data = np.zeros(\n    (len(input), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n)\nvalidation_decoder_target_data = np.zeros(\n    (len(validation_input), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n)\n\nfor i, (input_text, target_text) in enumerate(zip(input, target)):\n    for t, char in enumerate(input_text):\n        encoder_input_data[i, t, input_token[char]] = 1.0\n    for t, char in enumerate(target_text):\n        # decoder_target_data is ahead of decoder_input_data by one timestep\n        decoder_input_data[i, t, target_token[char]] = 1.0\n        if t > 0:\n            # decoder_target_data will be ahead by one timestep\n            # and will not include the start character.\n            decoder_target_data[i, t - 1, target_token[char]] = 1.0\n# for validation data\nfor i, (validation_input_text, validation_target_text) in enumerate(zip(validation_input, validation_target)):\n    for t, char in enumerate(validation_input_text):\n        validation_encoder_input_data[i, t, input_token[char]] = 1.0\n    for t, char in enumerate(validation_target_text):\n        # decoder_target_data is ahead of decoder_input_data by one timestep\n        validation_decoder_input_data[i, t, target_token[char]] = 1.0\n        if t > 0:\n            # decoder_target_data will be ahead by one timestep\n            # and will not include the start character.\n            validation_decoder_target_data[i, t - 1, target_token[char]] = 1.0\n\n# for test data\nfor i, (test_input_text, test_target_text) in enumerate(zip(test_input, test_target)):\n    for t, char in enumerate(test_input_text):\n        test_encoder_input_data[i, t, input_token[char]] = 1.0","metadata":{"id":"oBF7Cdqrb5Hc","execution":{"iopub.status.busy":"2022-06-19T14:30:35.223556Z","iopub.execute_input":"2022-06-19T14:30:35.224039Z","iopub.status.idle":"2022-06-19T14:30:36.884489Z","shell.execute_reply.started":"2022-06-19T14:30:35.224003Z","shell.execute_reply":"2022-06-19T14:30:36.883493Z"},"trusted":true},"execution_count":229,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"2q7AdDj4P_8p","outputId":"194ddb5e-1081-4f6b-da4f-bc4c99a8aad7","execution":{"iopub.status.busy":"2022-06-19T14:30:37.301677Z","iopub.execute_input":"2022-06-19T14:30:37.302743Z","iopub.status.idle":"2022-06-19T14:30:38.242257Z","shell.execute_reply.started":"2022-06-19T14:30:37.302700Z","shell.execute_reply":"2022-06-19T14:30:38.241015Z"},"trusted":true},"execution_count":230,"outputs":[]},{"cell_type":"code","source":"enc_input_data = np.zeros(\n    (len(input), max_encoder_seq_length), dtype=\"float32\"\n)\ndec_input_data = np.zeros(\n    (len(input), max_decoder_seq_length), dtype=\"float32\"\n)\ndec_target_data = np.zeros(\n    (len(input), max_decoder_seq_length,num_decoder_tokens), dtype=\"float32\"\n)\n#Decoder Target Sequences are Padded to a maximum length of max_decoder SeqLen characters with a vocabulary of sizeofTeluguVocab different characters. \nfor i, (input_text, target_text) in enumerate(zip(input, target)):\n    for t, char in enumerate(input_text):\n        enc_input_data[i, t] = input_token[char]\n    #enc_input_data[i, t + 1 :] = input_token[\" \"]\n\n    for t, char in enumerate(target_text):\n        # dec_target_data is ahead of dec_input_data by one timestep\n        dec_input_data[i, t] = target_token[char]\n        if t > 0:\n            # dec_target_data will not include the start character.\n            dec_target_data[i, t - 1, target_token[char]] = 1.0\n    #dec_input_data[i, t + 1: ] = target_token[\" \"]\n    #dec_target_data[i, t:, target_token[\" \"]] = 1.0\n    \nval_enc_input_data = np.zeros(\n    (len(validation_input), validation_max_encoder_seq_length), dtype=\"float32\"\n)\nval_dec_input_data = np.zeros(\n    (len(validation_input), validation_max_decoder_seq_length), dtype=\"float32\"\n)\nval_dec_target_data = np.zeros(\n    (len(validation_input), validation_max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n)\n\nfor i, (input_text, target_text) in enumerate(zip(validation_input,validation_target)):\n    for t, char in enumerate(input_text):\n        # Enumerate() method adds a counter to an iterable and returns it in a form of enumerating object. \n        # This enumerated object can then be used directly for loops or converted into a list of tuples using the list() method.\n        val_enc_input_data[i, t] = input_token[char]\n    #val_enc_input_data[i, t + 1 :] = input_token_index[\" \"]\n\n    for t, char in enumerate(target_text):\n        val_dec_input_data[i, t] = target_token[char]\n        if t > 0:\n            # dec_target_data will be ahead by one timestep\n            # and will not include the start character.\n            val_dec_target_data[i, t - 1, target_token[char]] = 1.0\n    #val_dec_input_data[i, t + 1: ] = target_token_index[\" \"]","metadata":{"execution":{"iopub.status.busy":"2022-06-19T15:33:00.750838Z","iopub.execute_input":"2022-06-19T15:33:00.751958Z","iopub.status.idle":"2022-06-19T15:33:01.589162Z","shell.execute_reply.started":"2022-06-19T15:33:00.751901Z","shell.execute_reply":"2022-06-19T15:33:01.588102Z"},"trusted":true},"execution_count":299,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build the model\n","metadata":{"id":"eGM50wwWAQed"}},{"cell_type":"code","source":"class Seq2seq(tf.keras.Model):\n  def __init__(self, num_encoder_tokens, num_decoder_tokens,embedding_dim,num_of_layers,unit_type, dropout , recurrent_dropout):\n    super().__init__()\n    self.encoder_inputs = Input(shape = (None,), name = \"Input_layer_1\")\n    self.decoder_inputs = keras.Input(shape=(None,), name = \"Input_layer_2\")\n    self.num_encoder_tokens = num_encoder_tokens\n    self.embedding_dim = embedding_dim\n    self.dropout = dropout\n    self.recurrent_dropout = recurrent_dropout\n    self.num_decoder_tokens = num_decoder_tokens\n    self.num_of_encoder_layer  =num_of_layers\n    self.num_of_decoder_layer =num_of_layers\n    self.type_encoder_unit =unit_type \n    self.type_decoder_unit =unit_type\n    self.train_step()\n    self.build_model()\n\n  def get_embedding_layer(self, num_encoder_tokens, embedding_dim,  name):\n    return Embedding(num_encoder_tokens, embedding_dim, mask_zero = True, name =name )\n\n  def get_cell(self, cell_type = \"lstm\", num_of_cell = 1, name = None):\n    #print(cell_type)\n    if cell_type == \"lstm\":\n      return LSTMCell(num_of_cell, dropout = self.dropout, recurrent_dropout = self.recurrent_dropout, )\n    elif cell_type == \"rnn\":\n      return SimpleRNNCell(num_of_cell, dropout = self.dropout, recurrent_dropout = self.recurrent_dropout)\n    elif cell_type ==\"gru\":\n      return GRUCell(num_of_cell, dropout = self.dropout, recurrent_dropout = self.recurrent_dropout)\n    else:\n      print(f\"Invalid cell type: {cell_type}\")\n  def get_encoder(self,latent_dim, cell_type = \"lstm\", num_of_layer = 1, name = None ):\n    return tf.keras.layers.RNN(tf.keras.layers.StackedRNNCells( [self.get_cell(cell_type, latent_dim) for i in range(num_of_layer)],), return_sequences=True, return_state=True, name = name)\n\n  def get_decoder(self,latent_dim ,cell_type = \"lstm\", num_of_layer = 1, name = None ):\n    return tf.keras.layers.RNN(tf.keras.layers.StackedRNNCells( [self.get_cell(cell_type, latent_dim,) for i in range(num_of_layer)]), return_sequences=True, return_state=True)\n\n  def get_dense_layer(self, num_decoder_token, activation = \"softmax\"):\n    return Dense(num_decoder_tokens, activation= activation)\n\n  def train_step(self):\n    self.embedding_layer = self.get_embedding_layer( self.num_encoder_tokens, self.embedding_dim ,name = \"encoder_embedding\")\n    self.embedding_results = self.embedding_layer(self.encoder_inputs)\n    print(self.embedding_results.shape)\n    self.encoder = self.get_encoder( self.embedding_dim,self.type_encoder_unit, self.num_of_encoder_layer , name =\"encoder\" )\n    encoder_results = self.encoder(self.embedding_results)\n\n    self.encoder_outputs, self.encoder_states = encoder_results[0], encoder_results[1:]\n\n    self.embedding_layer2 = self.get_embedding_layer( self.num_decoder_tokens, self.embedding_dim, name = \"decoder_embedding\")\n    self.embedding_results2 = self.embedding_layer2(self.decoder_inputs,)\n\n    self.decoder = self.get_decoder( self.embedding_dim, self.type_decoder_unit, self.num_of_decoder_layer,)\n    self.decoder_results = self.decoder(self.embedding_results2, initial_state=self.encoder_states)\n\n    self.decoder_output = self.decoder_results[0]\n    self.decoder_dense = self.get_dense_layer(self.num_decoder_tokens)\n    self.dense_output = self.decoder_dense(self.decoder_output)\n\n  def build_model(self):\n    \n    self.model = keras.Model([self.encoder_inputs, self.decoder_inputs], self.dense_output, name = \"Seq2Seq_model\")\n    return self.model\n\n","metadata":{"id":"x9fpzXhN7DMU","execution":{"iopub.status.busy":"2022-06-19T14:57:09.043044Z","iopub.execute_input":"2022-06-19T14:57:09.043462Z","iopub.status.idle":"2022-06-19T14:57:09.068515Z","shell.execute_reply.started":"2022-06-19T14:57:09.043428Z","shell.execute_reply":"2022-06-19T14:57:09.067563Z"},"trusted":true},"execution_count":248,"outputs":[]},{"cell_type":"code","source":"\nseq2seq = Seq2seq(num_encoder_tokens,num_decoder_tokens, 1024,1,\"rnn\", 0.0, 0.0).build_model()\nseq2seq.summary()","metadata":{"id":"qJ07iEXsJr6K","outputId":"1b7444e5-88c9-4492-8067-1ebb103347b9","execution":{"iopub.status.busy":"2022-06-19T14:59:22.231672Z","iopub.execute_input":"2022-06-19T14:59:22.232141Z","iopub.status.idle":"2022-06-19T14:59:22.718772Z","shell.execute_reply.started":"2022-06-19T14:59:22.232106Z","shell.execute_reply":"2022-06-19T14:59:22.717672Z"},"trusted":true},"execution_count":252,"outputs":[{"name":"stdout","text":"(None, None, 1024)\nModel: \"Seq2Seq_model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nInput_layer_1 (InputLayer)      [(None, None)]       0                                            \n__________________________________________________________________________________________________\nInput_layer_2 (InputLayer)      [(None, None)]       0                                            \n__________________________________________________________________________________________________\nencoder_embedding (Embedding)   (None, None, 1024)   26624       Input_layer_1[0][0]              \n__________________________________________________________________________________________________\ndecoder_embedding (Embedding)   (None, None, 1024)   66560       Input_layer_2[0][0]              \n__________________________________________________________________________________________________\nencoder (RNN)                   [(None, None, 1024), 2098176     encoder_embedding[0][0]          \n__________________________________________________________________________________________________\nrnn_63 (RNN)                    [(None, None, 1024), 2098176     decoder_embedding[0][0]          \n                                                                 encoder[0][1]                    \n__________________________________________________________________________________________________\ndense_35 (Dense)                (None, None, 65)     66625       rnn_63[0][0]                     \n==================================================================================================\nTotal params: 4,356,161\nTrainable params: 4,356,161\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Train the model\n","metadata":{"id":"HXZ2_xdsAQee"}},{"cell_type":"code","source":"seq2seq.compile(\n    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[tf.keras.metrics.CategoricalAccuracy(name='acc')]\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-19T14:21:19.177217Z","iopub.execute_input":"2022-06-19T14:21:19.177828Z","iopub.status.idle":"2022-06-19T14:21:19.197353Z","shell.execute_reply.started":"2022-06-19T14:21:19.177762Z","shell.execute_reply":"2022-06-19T14:21:19.196282Z"},"trusted":true},"execution_count":182,"outputs":[]},{"cell_type":"code","source":"class BeamSearch(keras.callbacks.Callback):\n\n  def __init__(self, beam_size):\n    self.beam_size = beam_size\n\n  def beam_search_decoder(aelf, data, k):\n    sequences = [[list(), 0.0]]\n    # walk over each step in sequence\n    for row in data:\n      all_candidates = list()\n      # expand each current candidate\n      for i in range(len(sequences)):\n        seq, score = sequences[i]\n        for j in range(len(row)):\n          candidate = [seq + [j], score - log(row[j])]\n          all_candidates.append(candidate)\n      # order all candidates by score\n      ordered = sorted(all_candidates, key=lambda tup:tup[1])\n      # select k best\n      sequences = ordered[:k]\n    return sequences\n  \n  def on_epoch_end(self, epoch, logs = None):\n    prediction = self.model.predict([val_enc_input_data , val_dec_input_data])\n    print(prediction.shape)\n    for i, pred in enumerate(prediction):\n      beam_search_prediction = self.beam_search_decoder(pred, self.beam_size)\n      correct_prediction = 0\n      for k in range(self.beam_size):\n        #translated_word = \"\\t\"+\"\".join([reverse_target_token[x] for x in beam_search_prediction[k][0][:len(validation_target[i])-1]])\n        #print(translated_word, validation_target[i])\n        #print(validation_target[i])\n        \n        def idx2char(idx_list):\n          return \"\".join([reverse_target_token[x] for x in idx_list])\n\n        if \"\\t\"+ idx2char(beam_search_prediction[k][0][:len(validation_target[i])-1]) == validation_target[i]:\n          correct_prediction+=1\n          break\n    mul = 10.0**2\n    logs[\"character_accuracy\"] = ((correct_prediction/prediction.shape[0])*mul)/mul\n    print(\"- character_accuracy\",logs[\"character_accuracy\"])\n    #print(f\"Accuracy by Beam Search {correct_prediction/len(validation_target)}\")\n      # print(len(beam_search_prediction))\n      # print(beam_search_prediction)\n","metadata":{"id":"KPyDujbe-Brq","execution":{"iopub.status.busy":"2022-06-19T15:10:18.730086Z","iopub.execute_input":"2022-06-19T15:10:18.730979Z","iopub.status.idle":"2022-06-19T15:10:18.745337Z","shell.execute_reply.started":"2022-06-19T15:10:18.730935Z","shell.execute_reply":"2022-06-19T15:10:18.744072Z"},"trusted":true},"execution_count":270,"outputs":[]},{"cell_type":"code","source":"def beam_search_decoder(data, k):\n    decodedWords = [[list(), 0.0]]\n    # walk over each step in sequence\n    for word in data:\n      candidates = list()\n      # expand each current candidate\n      for sequence in decodedWords:\n        seq, score = sequence\n        for j in range(len(word)):\n          candidate = [seq + [j], score - log(word[j])]\n          candidates.append(candidate)\n      # order all candidates by score\n      ordered = sorted(candidates, key=lambda a:a[1])\n      # select k best\n      decodedWords = ordered[:k]\n    return decodedWords\n  \ndef translate(seq):\n  sentence = [] \n  for x in seq:\n    char = reverse_target_token[x]\n    sentence.append(char)\n  return \"\".join(sentence)\nclass WordAccuracyCallback(keras.callbacks.Callback):\n  def __init__(self,beam_size):\n    self.beam_size=beam_size\n  def on_epoch_end(self, epoch, logs=None):\n    pred=self.model.predict([val_enc_input_data , val_dec_input_data])\n    count=0\n    for i in range(pred.shape[0]):\n      pSequences=beam_search_decoder(pred[i],self.beam_size)\n      for j in range(self.beam_size):\n        if \"\\t\"+translate(pSequences[j][0][:len(validation_target[i])-1])==validation_target[i]:\n          count=count+1\n          break\n    factor = 10.0 ** 4\n    logs[\"WordAccuracy\"]=math.trunc((count/pred.shape[0])*factor)/factor\n    print(\"- wordAccuracy:\",logs[\"WordAccuracy\"])","metadata":{"execution":{"iopub.status.busy":"2022-06-19T15:22:20.414711Z","iopub.execute_input":"2022-06-19T15:22:20.415244Z","iopub.status.idle":"2022-06-19T15:22:20.431301Z","shell.execute_reply.started":"2022-06-19T15:22:20.415207Z","shell.execute_reply":"2022-06-19T15:22:20.429988Z"},"trusted":true},"execution_count":289,"outputs":[]},{"cell_type":"code","source":"sweep_config = {\n    \n    'method':'bayes',\n    'metric': {\n        'name':'val_accuracy',\n        'goal':'maximize'\n    },\n    'parameters':{\n    \n    \"num_of_layer\" : {'values': [1,2,3]},\n    \"unit_size\": {\"values\":[16,32,64]},\n    \"unit_type\": {\"values\":[\"lstm\",\"rnn\",\"gru\"]},\n    \"dropout\": {\"values\": [0.0, 0.2, 0.4]},\n    'recurrent_dropout':{'values':[0.0,0.3]},\n    \"beam_size\" : {\"values\":[1,2,3,4]},\n    \"epochs\":{\"value\":20},  \n    \"optimizer\":{\"values\": [\"adam\",\"rmsprop\"]}             \n                   }\n}\n\n\n\npprint.pprint(sweep_config)","metadata":{"id":"mIW2Ofow5Deo","outputId":"0c99b3cb-eaac-4b1e-acfa-1aff5a6bad9e","execution":{"iopub.status.busy":"2022-06-19T14:21:23.223786Z","iopub.execute_input":"2022-06-19T14:21:23.224923Z","iopub.status.idle":"2022-06-19T14:21:23.234457Z","shell.execute_reply.started":"2022-06-19T14:21:23.224875Z","shell.execute_reply":"2022-06-19T14:21:23.233323Z"},"trusted":true},"execution_count":185,"outputs":[{"name":"stdout","text":"{'method': 'bayes',\n 'metric': {'goal': 'maximize', 'name': 'val_accuracy'},\n 'parameters': {'beam_size': {'values': [1, 2, 3, 4]},\n                'dropout': {'values': [0.0, 0.2, 0.4]},\n                'epochs': {'value': 20},\n                'num_of_layer': {'values': [1, 2, 3]},\n                'optimizer': {'values': ['adam', 'rmsprop']},\n                'recurrent_dropout': {'values': [0.0, 0.3]},\n                'unit_size': {'values': [16, 32, 64]},\n                'unit_type': {'values': ['lstm', 'rnn', 'gru']}}}\n","output_type":"stream"}]},{"cell_type":"code","source":"sweep_id = wandb.sweep(sweep_config, project=\"seq2seq\")","metadata":{"id":"x8YmtLZN_74p","outputId":"0a29a711-1d11-4ee2-d0db-3ce9002c86db"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(config = None):\n  with wandb.init(config=config):\n    config = wandb.config\n    #print(config)\n    seq2seq = Seq2seq(num_encoder_tokens,num_decoder_tokens, config.unit_size, config.num_of_layer,config.unit_type , config.dropout,config.recurrent_dropout).build_model()\n    seq2seq.compile(optimizer=config.optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\",])\n    seq2seq.fit(\n        [encoder_input_data, decoder_input_data],\n        decoder_target_data,\n        batch_size=batch_size,\n        epochs=config.epochs,\n        validation_data =  ([validation_encoder_input_data , validation_decoder_input_data] ,validation_decoder_target_data),\n        callbacks = [BeamSearch(config.beam_size), WandbCallback()],verbose = 1, \n        )\n\n\n    \n    \nwandb.agent(sweep_id, train)","metadata":{"id":"qYv2feSRAzW_","outputId":"591913ca-f97e-47b5-e93e-b26993f4ffe9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seq2seq.compile(\n    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[tf.keras.metrics.CategoricalAccuracy(name='acc')]\n)\nseq2seq.metrics_names\n\n","metadata":{"id":"DIrCXZTAGyTL","execution":{"iopub.status.busy":"2022-06-19T15:22:24.717670Z","iopub.execute_input":"2022-06-19T15:22:24.718289Z","iopub.status.idle":"2022-06-19T15:22:24.738490Z","shell.execute_reply.started":"2022-06-19T15:22:24.718252Z","shell.execute_reply":"2022-06-19T15:22:24.737389Z"},"trusted":true},"execution_count":290,"outputs":[{"execution_count":290,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}]},{"cell_type":"code","source":"pred=seq2seq.predict([val_enc_input_data , val_dec_input_data])\ncount=0\nfor i in range(pred.shape[0]//400):\n      pSequences=beam_search_decoder(pred[i],3)\n      for j in range(3):\n        print({\"\\t\"+translate(pSequences[j][0][:len(validation_target[i])-1])}, \"original =\", {validation_target[i]} )\n        if \"\\t\"+translate(pSequences[j][0][:len(validation_target[i])-1])==validation_target[i]:\n          count=count+1\n          print(\"yes\")\n          break\nfactor = 10.0 ** 4\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-06-19T15:41:09.089308Z","iopub.execute_input":"2022-06-19T15:41:09.089822Z","iopub.status.idle":"2022-06-19T15:41:22.154791Z","shell.execute_reply.started":"2022-06-19T15:41:09.089769Z","shell.execute_reply":"2022-06-19T15:41:22.153760Z"},"trusted":true},"execution_count":312,"outputs":[{"name":"stdout","text":"{'\\tकं\\nा'} original = {'\\tअंक\\n'}\n{'\\tवं\\nा'} original = {'\\tअंक\\n'}\n{'\\t्ं\\nा'} original = {'\\tअंक\\n'}\n{'\\tकं\\nा'} original = {'\\tअंक\\n'}\n{'\\tवं\\nा'} original = {'\\tअंक\\n'}\n{'\\t्ं\\nा'} original = {'\\tअंक\\n'}\n{'\\tकन\\n\\n\\n\\n'} original = {'\\tअंकित\\n'}\n{'\\tवन\\n\\n\\n\\n'} original = {'\\tअंकित\\n'}\n{'\\t्न\\n\\n\\n\\n'} original = {'\\tअंकित\\n'}\n{'\\tकन\\n\\n\\n\\n'} original = {'\\tअंकों\\n'}\n{'\\tवन\\n\\n\\n\\n'} original = {'\\tअंकों\\n'}\n{'\\t्न\\n\\n\\n\\n'} original = {'\\tअंकों\\n'}\n{'\\tकन\\n\\n\\n\\n'} original = {'\\tअंकों\\n'}\n{'\\tवन\\n\\n\\n\\n'} original = {'\\tअंकों\\n'}\n{'\\t्न\\n\\n\\n\\n'} original = {'\\tअंकों\\n'}\n{'\\tकन\\n\\n\\n\\n'} original = {'\\tअंकों\\n'}\n{'\\tवन\\n\\n\\n\\n'} original = {'\\tअंकों\\n'}\n{'\\t्न\\n\\n\\n\\n'} original = {'\\tअंकों\\n'}\n{'\\tकन\\n\\n\\n\\n'} original = {'\\tअंकोर\\n'}\n{'\\tवन\\n\\n\\n\\n'} original = {'\\tअंकोर\\n'}\n{'\\t्न\\n\\n\\n\\n'} original = {'\\tअंकोर\\n'}\n{'\\tकन\\n\\n\\n\\n'} original = {'\\tअंकोर\\n'}\n{'\\tवन\\n\\n\\n\\n'} original = {'\\tअंकोर\\n'}\n{'\\t्न\\n\\n\\n\\n'} original = {'\\tअंकोर\\n'}\n{'\\tकन\\n\\n\\n\\n\\n'} original = {'\\tअंगारक\\n'}\n{'\\tवन\\n\\n\\n\\n\\n'} original = {'\\tअंगारक\\n'}\n{'\\t्न\\n\\n\\n\\n\\n'} original = {'\\tअंगारक\\n'}\n{'\\tकन\\n\\n\\n\\n\\n'} original = {'\\tअंगारक\\n'}\n{'\\tवन\\n\\n\\n\\n\\n'} original = {'\\tअंगारक\\n'}\n{'\\t्न\\n\\n\\n\\n\\n'} original = {'\\tअंगारक\\n'}\n{'\\tकर\\n\\n\\n\\n\\n\\n\\n'} original = {'\\tअंग्रज़ी\\n'}\n{'\\tवर\\n\\n\\n\\n\\n\\n\\n'} original = {'\\tअंग्रज़ी\\n'}\n{'\\t्र\\n\\n\\n\\n\\n\\n\\n'} original = {'\\tअंग्रज़ी\\n'}\n","output_type":"stream"}]},{"cell_type":"code","source":"x = seq2seq.predict([val_enc_input_data , val_dec_input_data])\nx.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-19T15:33:14.072698Z","iopub.execute_input":"2022-06-19T15:33:14.073169Z","iopub.status.idle":"2022-06-19T15:33:26.484545Z","shell.execute_reply.started":"2022-06-19T15:33:14.073134Z","shell.execute_reply":"2022-06-19T15:33:26.483378Z"},"trusted":true},"execution_count":301,"outputs":[{"execution_count":301,"output_type":"execute_result","data":{"text/plain":"(4502, 17, 65)"},"metadata":{}}]},{"cell_type":"code","source":"\nhistotry = seq2seq.fit(\n    [enc_input_data, dec_input_data],\n    dec_target_data,\n    batch_size=8192,\n    epochs=1,\n    callbacks = [WordAccuracyCallback(3), ],\n)\n# Save model\nseq2seq.save(\"s2s\")\n","metadata":{"id":"ox_fyYUrAQef","outputId":"f4da868c-355c-4132-8481-e4ffcb605de4","execution":{"iopub.status.busy":"2022-06-19T15:22:25.394757Z","iopub.execute_input":"2022-06-19T15:22:25.395410Z","iopub.status.idle":"2022-06-19T15:28:55.450107Z","shell.execute_reply.started":"2022-06-19T15:22:25.395375Z","shell.execute_reply":"2022-06-19T15:28:55.448703Z"},"trusted":true},"execution_count":291,"outputs":[{"name":"stdout","text":"6/6 [==============================] - 214s 34s/step - loss: 1.1271 - acc: 0.1550\n- wordAccuracy: 0.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# for key in histotry.history.keys():\n#       print(key , histotry.history[key])\n#       #wandb.log({key : histotry.history[key]})","metadata":{"id":"2BnI7lHtQtnT","outputId":"c28f05b7-5b95-4944-f96e-89ac5d15e63f","execution":{"iopub.status.busy":"2022-06-19T14:17:37.411280Z","iopub.status.idle":"2022-06-19T14:17:37.411991Z","shell.execute_reply.started":"2022-06-19T14:17:37.411629Z","shell.execute_reply":"2022-06-19T14:17:37.411665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# seq2seq.metrics_names","metadata":{"id":"Npqd4if4HVZT","outputId":"f62ebf51-0592-4b85-bfc3-a1cc8e80b770"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Run inference (sampling)\n\n1. encode input and retrieve initial decoder state\n2. run one step of decoder with this initial state\nand a \"start of sequence\" token as target.\nOutput will be the next target token.\n3. Repeat with the current target token and current states\n","metadata":{"id":"BC5CbwHlAQef"}},{"cell_type":"code","source":"# # Define sampling models\n# # Restore the model and construct the encoder and decoder.\n# model = keras.models.load_model(\"s2s\")\n\n# encoder_inputs = model.input[0]  # input_1\n# temp = model.layers[2].output\n# encoder_outputs, state = temp[0], temp[1:]  # lstm_1\n# encoder_states = state\n# encoder_model = keras.Model(encoder_inputs, encoder_states)\n\n# decoder_inputs = model.input[1]  # input_2\n# decoder_state_input_h = keras.Input(shape=(latent_dim,))\n# decoder_state_input_c = keras.Input(shape=(latent_dim,))\n# decoder_states_inputs = state\n# decoder_lstm = model.layers[3]\n# temp = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n# decoder_outputs, state_dec = temp[0], temp[1:]\n# decoder_states = state_dec\n# decoder_dense = model.layers[4]\n# decoder_outputs = decoder_dense(decoder_outputs)\n# decoder_model = keras.Model(\n#     [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n# )\n\n# # Reverse-lookup token index to decode sequences back to\n# # something readable.\n# # reverse_input_char_index = dict((i, char) for char, i in num_encoder_tokens.items())\n# # reverse_target_char_index = dict((i, char) for char, i in num_decoder_tokens.items())\n# # print(reverse_input_char_index)\n# # print(input_token_index)\n\n# reverse_input_token = dict((i, char) for char, i in input_token.items())\n# reverse_target_token = dict((i, char) for char, i in target_token.items())\n# def decode_sequence(input_seq):\n#     # Encode the input as state vectors.\n#     states_value = encoder_model.predict(input_seq)\n\n#     # Generate empty target sequence of length 1.\n#     target_seq = np.zeros((1, 1, num_decoder_tokens))\n#     # Populate the first character of target sequence with the start character.\n#     target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n\n#     # Sampling loop for a batch of sequences\n#     # (to simplify, here we assume a batch of size 1).\n#     stop_condition = False\n#     decoded_sentence = \"\"\n#     while not stop_condition:\n#         temp = decoder_model.predict([target_seq] + states_value)\n#         output_tokens, state = temp[0],temp[1:]\n\n#         # Sample a token\n#         sampled_token_index = np.argmax(output_tokens[0, -1, :])\n#         #print(reverse_target_char_index)\n#         sampled_char = reverse_target_token[sampled_token_index]\n#         decoded_sentence += sampled_char\n\n#         # Exit condition: either hit max length\n#         # or find stop character.\n#         if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n#             stop_condition = True\n\n#         # Update the target sequence (of length 1).\n#         target_seq = np.zeros((1, 1, num_decoder_tokens))\n#         target_seq[0, 0, sampled_token_index] = 1.0\n\n#         # Update states\n#         states_value = state\n#     return decoded_sentence\n\n","metadata":{"id":"meuadqgkAQeg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can now generate decoded sentences as such:\n","metadata":{"id":"nSNoQ5AvAQeh"}},{"cell_type":"code","source":"# for seq_index in range(20):\n#     # Take one sequence (part of the training set)\n#     # for trying out decoding.\n#     input_seq = encoder_input_data[seq_index : seq_index + 1]\n#     decoded_sentence = decode_sequence(input_seq)\n#     print(\"-\")\n#     print(\"Input sentence:\", input_texts[seq_index])\n#     print(\"Decoded sentence:\", decoded_sentence)\n","metadata":{"id":"wjp__2oJAQeh","outputId":"f892034f-9120-4f42-f893-e17883870cc7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! git log","metadata":{"id":"ygwmClalB8vI","execution":{"iopub.status.busy":"2022-06-19T15:44:04.633143Z","iopub.execute_input":"2022-06-19T15:44:04.633593Z","iopub.status.idle":"2022-06-19T15:44:05.689112Z","shell.execute_reply.started":"2022-06-19T15:44:04.633552Z","shell.execute_reply":"2022-06-19T15:44:05.687915Z"},"trusted":true},"execution_count":314,"outputs":[{"name":"stdout","text":"fatal: not a git repository (or any parent up to mount point /kaggle)\nStopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}