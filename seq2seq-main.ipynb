{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Setup","metadata":{"id":"MpySVYWJhxaV"}},{"cell_type":"code","source":"!pip install tensorflow-addons==0.11.2","metadata":{"id":"_kxfdP4hJUPB","outputId":"c397bd2f-354d-4158-a1d5-2d312e072eab","execution":{"iopub.status.busy":"2022-06-27T14:36:10.208245Z","iopub.execute_input":"2022-06-27T14:36:10.209087Z","iopub.status.idle":"2022-06-27T14:36:36.424726Z","shell.execute_reply.started":"2022-06-27T14:36:10.208990Z","shell.execute_reply":"2022-06-27T14:36:36.423283Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_addons as tfa\nfrom IPython.display import HTML as html_print\nfrom IPython.display import display\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nimport unicodedata\nimport re\nimport numpy as np\nimport os\nimport io\nimport time\nimport pandas as pd\nfrom tensorflow.keras.layers import Embedding, SimpleRNNCell, GRUCell, Dense, LSTMCell","metadata":{"id":"tnxXKDjq3jEL","outputId":"2502e056-0940-4570-abd3-1a0fdf37795f","execution":{"iopub.status.busy":"2022-06-27T14:36:36.427733Z","iopub.execute_input":"2022-06-27T14:36:36.428525Z","iopub.status.idle":"2022-06-27T14:36:42.393535Z","shell.execute_reply.started":"2022-06-27T14:36:36.428480Z","shell.execute_reply":"2022-06-27T14:36:42.392209Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Data Cleaning and Data Preparation \n","metadata":{"id":"Ii_vg-XNXTil"}},{"cell_type":"code","source":"","metadata":{"id":"ckjyipboLFwf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def download_nmt():\n#     path_to_zip = tf.keras.utils.get_file(\n#     'dakshina_dataset_v1.0.tar', origin='https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar',\n#     extract=True, untar = True)\n\n#     path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\"\n#     return path_to_file\n# download_nmt()","metadata":{"id":"PvRnGWnvXm6l","execution":{"iopub.status.busy":"2022-06-27T14:36:48.446711Z","iopub.execute_input":"2022-06-27T14:36:48.447373Z","iopub.status.idle":"2022-06-27T14:36:48.453783Z","shell.execute_reply.started":"2022-06-27T14:36:48.447342Z","shell.execute_reply":"2022-06-27T14:36:48.452051Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Define a DakshinaDataset class with necessary functions to follow Step 1 to Step 4. \nThe ```call()``` will return:\n1. ```train_dataset```  and ```val_dataset``` : ```tf.data.Dataset``` objects\n2. ```inp_lang_tokenizer``` and ```targ_lang_tokenizer``` : ```tf.keras.preprocessing.text.Tokenizer``` objects ","metadata":{"id":"NFKB2c_tX4wU"}},{"cell_type":"code","source":"!wget  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n!tar -xf 'dakshina_dataset_v1.0.tar'\ntrain_file_path = \"./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\"\nval_file_path= \"./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv\"\ntest_file_path  = \"./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv\"","metadata":{"id":"rZal_kwQLurS","outputId":"f824fe77-d039-472d-8601-1b7b26020077","execution":{"iopub.status.busy":"2022-06-27T14:38:33.296425Z","iopub.execute_input":"2022-06-27T14:38:33.296904Z","iopub.status.idle":"2022-06-27T14:39:04.776316Z","shell.execute_reply.started":"2022-06-27T14:38:33.296865Z","shell.execute_reply":"2022-06-27T14:39:04.774549Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class DakshinaDataset:\n    def __init__(self, problem_type='en-spa'):\n        self.problem_type = 'en-spa'\n        self.inp_lang_tokenizer = None\n        self.targ_lang_tokenizer = None\n        self.num_of_train = 0\n        self.num_of_test = 0\n        self.num_of_val = 0\n    \n\n    def unicode_to_ascii(self, s):\n        return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n\n    ## Step 1 and Step 2 \n    def preprocess_sentence(self, w):\n        # w = self.unicode_to_ascii(w.lower().strip())\n\n        # # creating a space between a word and the punctuation following it\n        # # eg: \"he is a boy.\" => \"he is a boy .\"\n        # # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n        # w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n        # w = re.sub(r'[\" \"]+', \" \", w)\n\n        # # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n        # w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n\n        # w = w.strip()\n\n        # adding a start and an end token to the sentence\n        # so that the model know when to start and stop predicting.\n        w = '\\t' + w + '\\n'\n        return w\n    \n    def create_dataset(self, path, data_name):\n        # path : path to spa-eng.txt file\n        # num_examples : Limit the total number of training example for faster training (set num_examples = len(lines) to use full data)\n        lines = io.open(path, encoding='UTF-8').read().split('\\n')\n        #print(lines)\n        if data_name == \"train\":\n          self.num_of_train = len(lines) -1\n        elif data_name == \"val\":\n          self.num_of_val = len(lines) -1\n        else:\n          self.num_of_test = len(lines) -1\n        word_pairs = [[self.preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:len(lines)-1]]\n        #print(word_pairs)\n\n        \n        return zip(*word_pairs)\n\n    # Step 3 and Step 4\n    def tokenize(self, lang):\n        # lang = list of sentences in a language\n        \n        # print(len(lang), \"example sentence: {}\".format(lang[0]))\n        lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(char_level = True)\n        lang_tokenizer.fit_on_texts(lang)\n\n        ## tf.keras.preprocessing.text.Tokenizer.texts_to_sequences converts string (w1, w2, w3, ......, wn) \n        ## to a list of correspoding integer ids of words (id_w1, id_w2, id_w3, ...., id_wn)\n        tensor = lang_tokenizer.texts_to_sequences(lang) \n\n        ## tf.keras.preprocessing.sequence.pad_sequences takes argument a list of integer id sequences \n        ## and pads the sequences to match the longest sequences in the given input\n        tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n\n        return tensor, lang_tokenizer\n\n    def load_dataset(self, path, data_name = None, ):\n        targ_lang, inp_lang ,_= self.create_dataset(path, data_name)\n        if data_name == \"train\":\n            # creating cleaned input, output pairs\n            \n            #print(targ_lang, inp_lang)\n            input_tensor, inp_lang_tokenizer = self.tokenize(inp_lang)\n            #print(input_tensor, inp_lang_tokenizer.word_index)\n            target_tensor, targ_lang_tokenizer = self.tokenize(targ_lang)\n            return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer\n        else:\n            \n            #print(targ_lang, inp_lang)\n            input_tensor= self.inp_lang_tokenizer.texts_to_sequences(inp_lang)\n            #print(input_tensor)\n            input_tensor = tf.keras.preprocessing.sequence.pad_sequences(input_tensor, padding='post', maxlen = 22)\n            #print(input_tensor, inp_lang_tokenizer.word_index)\n            target_tensor = self.targ_lang_tokenizer.texts_to_sequences(targ_lang)\n            target_tensor = tf.keras.preprocessing.sequence.pad_sequences(target_tensor, padding='post', maxlen =21)\n            #print(target_tensor, targ_lang_tokenizer.word_index)\n            return input_tensor, target_tensor\n        \n\n    def call(self,  BUFFER_SIZE, BATCH_SIZE):\n        file_path = train_file_path\n        input_tensor_train, target_tensor_train, self.inp_lang_tokenizer, self.targ_lang_tokenizer = self.load_dataset(train_file_path, data_name =\"train\" )\n        train_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train))\n        train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n        print(\"val\")\n        file_path = val_file_path\n        input_tensor_val, target_tensor_val = self.load_dataset(val_file_path, \"val\")\n        val_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_val, target_tensor_val))\n        val_dataset = val_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n        print(\"test\")\n        file_path = test_file_path\n        input_tensor_test, target_tensor_test = self.load_dataset(test_file_path,  \"test\")\n        test_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_test, target_tensor_test))\n        test_dataset = test_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n        # val_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_val, target_tensor_val))\n        # val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n\n        return train_dataset, val_dataset, test_dataset, self.inp_lang_tokenizer, self.targ_lang_tokenizer","metadata":{"id":"JMAHz7kJXc5N","execution":{"iopub.status.busy":"2022-06-27T14:39:04.780807Z","iopub.execute_input":"2022-06-27T14:39:04.781760Z","iopub.status.idle":"2022-06-27T14:39:04.807538Z","shell.execute_reply.started":"2022-06-27T14:39:04.781682Z","shell.execute_reply":"2022-06-27T14:39:04.806122Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"BUFFER_SIZE = 32000\nBATCH_SIZE = 512\n# Let's limit the #training examples for faster training\nnum_examples = 500\n\ndataset_creator = DakshinaDataset('en-hi')\ntrain_dataset, val_dataset, test_dataset, inp_lang, targ_lang = dataset_creator.call( BUFFER_SIZE, BATCH_SIZE)","metadata":{"id":"EIW4NVBmJ25k","outputId":"eb43bd4e-0efc-4d29-d160-09f5415e0edc","execution":{"iopub.status.busy":"2022-06-27T14:39:04.809025Z","iopub.execute_input":"2022-06-27T14:39:04.810342Z","iopub.status.idle":"2022-06-27T14:39:10.173130Z","shell.execute_reply.started":"2022-06-27T14:39:04.810297Z","shell.execute_reply":"2022-06-27T14:39:10.171550Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"Qi37WHhrNtEr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example_input_batch, example_target_batch = next(iter(train_dataset))\nexample_input_batch.shape, example_target_batch.shape","metadata":{"id":"w2lCTy4vKOkB","outputId":"b6061227-1cde-4160-94b6-2a825fa47811","execution":{"iopub.status.busy":"2022-06-27T14:39:10.177765Z","iopub.execute_input":"2022-06-27T14:39:10.178089Z","iopub.status.idle":"2022-06-27T14:39:10.306169Z","shell.execute_reply.started":"2022-06-27T14:39:10.178058Z","shell.execute_reply":"2022-06-27T14:39:10.304818Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Some important parameters","metadata":{"id":"rgCLkfv5uO3d"}},{"cell_type":"code","source":"vocab_inp_size = len(inp_lang.word_index)+1\nvocab_tar_size = len(targ_lang.word_index)+1\nmax_length_input = example_input_batch.shape[1]\nmax_length_output = example_target_batch.shape[1]\n\nembedding_dim = 256\nunits = 1024\n\n","metadata":{"id":"TqHsArVZ3jFS","execution":{"iopub.status.busy":"2022-06-27T14:39:10.308050Z","iopub.execute_input":"2022-06-27T14:39:10.308441Z","iopub.status.idle":"2022-06-27T14:39:10.698105Z","shell.execute_reply.started":"2022-06-27T14:39:10.308413Z","shell.execute_reply":"2022-06-27T14:39:10.696694Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(\"max_length_english, max_length_spanish, vocab_size_english, vocab_size_spanish\")\nmax_length_input, max_length_output, vocab_inp_size, vocab_tar_size","metadata":{"id":"g-yY9c6aIu1h","outputId":"28e9dc00-5de5-404e-9a5b-aa7c0fdb3a66","execution":{"iopub.status.busy":"2022-06-27T14:39:10.699617Z","iopub.execute_input":"2022-06-27T14:39:10.701001Z","iopub.status.idle":"2022-06-27T14:39:10.714018Z","shell.execute_reply.started":"2022-06-27T14:39:10.700958Z","shell.execute_reply":"2022-06-27T14:39:10.712614Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"##### \n\nclass Encoder(tf.keras.Model):\n  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz, num_of_layers, enc_unit_type, dropout, recurrent_dropout):\n    super(Encoder, self).__init__()\n    self.batch_sz = batch_sz\n    self.enc_units = enc_units\n    self.num_of_layers = num_of_layers\n    self.enc_unit_type = enc_unit_type\n    self.dropout = dropout\n    self.recurrent_dropout = recurrent_dropout\n    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n\n    ##-------- LSTM layer in Encoder ------- ##\n    self.encoder_layer = self.get_encoder_layer(self.enc_units,\n                                                self.num_of_layers, self.enc_unit_type)\n    \n  def get_encoder_layer(self, enc_units, num_of_layers, enc_unit_type):\n    return tf.keras.layers.RNN(tf.keras.layers.StackedRNNCells( [self.get_cell(enc_unit_type, \n                                                                                 enc_units) for i in range(num_of_layers)],),\n                                  return_sequences=True, return_state=True, name = \"Encoder\")\n  def get_cell(self, cell_type = \"lstm\", num_of_cell = 1, name = None):\n      #print(cell_type)\n      if cell_type == \"lstm\":\n        return LSTMCell(num_of_cell, dropout = self.dropout, recurrent_dropout = self.recurrent_dropout, )\n      elif cell_type == \"rnn\":\n        return SimpleRNNCell(num_of_cell, dropout = self.dropout, recurrent_dropout = self.recurrent_dropout)\n      elif cell_type ==\"gru\":\n        return GRUCell(num_of_cell, dropout = self.dropout, recurrent_dropout = self.recurrent_dropout)\n      else:\n        print(f\"Invalid cell type: {cell_type}\")\n\n  def call(self, x, hidden):\n    x = self.embedding(x)\n    output = self.encoder_layer(x, initial_state = hidden)\n    return output[0], output[1:]\n\n  def initialize_hidden_state(self):\n    if self.enc_unit_type == 'rnn' or self.enc_unit_type == \"gru\":\n        return [tf.zeros((self.batch_sz, self.enc_units))]*self.num_of_layers\n    else:\n        return [[tf.zeros((self.batch_sz, self.enc_units)),tf.zeros((self.batch_sz, self.enc_units))]]*self.num_of_layers","metadata":{"id":"nZ2rI24i3jFg","execution":{"iopub.status.busy":"2022-06-27T14:39:10.715960Z","iopub.execute_input":"2022-06-27T14:39:10.716840Z","iopub.status.idle":"2022-06-27T14:39:10.735549Z","shell.execute_reply.started":"2022-06-27T14:39:10.716777Z","shell.execute_reply":"2022-06-27T14:39:10.734473Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"## Test Encoder Stack\n\nencoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE, 1, \"lstm\", 0.2,0.2)\n\n\n# sample input\nsample_hidden = encoder.initialize_hidden_state()\nsample_output, sample_state= encoder(example_input_batch, sample_hidden)\nprint ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\nprint(len(sample_state))\n# print ('Encoder h vecotr shape: (batch size, units) {}'.format(sample_state[0].shape))\n# print ('Encoder c vector shape: (batch size, units) {}'.format(sample_state[1].shape))","metadata":{"id":"60gSVh05Jl6l","outputId":"83f44279-d16b-47a2-b2fc-eecd27f242c9","execution":{"iopub.status.busy":"2022-06-27T14:39:10.739974Z","iopub.execute_input":"2022-06-27T14:39:10.740709Z","iopub.status.idle":"2022-06-27T14:39:13.122721Z","shell.execute_reply.started":"2022-06-27T14:39:10.740663Z","shell.execute_reply":"2022-06-27T14:39:13.120613Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"class Decoder(tf.keras.Model):\n  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz, num_of_layers, dec_unit_type, dropout, recurrent_dropout, attention_type='luong',):\n    super(Decoder, self).__init__()\n    self.batch_sz = batch_sz\n    self.dec_units = dec_units\n    self.attention_type = attention_type\n    self.num_of_layers = num_of_layers\n    self.dec_unit_type = dec_unit_type\n    self.dropout = dropout\n    self.recurrent_dropout = recurrent_dropout\n    # Embedding Layer\n    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n    \n    #Final Dense layer on which softmax will be applied\n    self.fc = tf.keras.layers.Dense(vocab_size)\n\n    # Define the fundamental cell for decoder recurrent structure\n    self.decoder_rnn_cell =  self.get_stacked_rnn_cell()\n   \n\n\n    # Sampler\n    self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n\n    # Create attention mechanism with memory = None\n    self.attention_mechanism = self.build_attention_mechanism(self.dec_units, \n                                                              None, self.batch_sz*[max_length_input], self.attention_type)\n\n    # Wrap attention mechanism with the fundamental rnn cell of decoder\n    self.rnn_cell = self.build_rnn_cell(batch_sz)\n\n    # Define the decoder with respect to fundamental rnn cell\n    self.decoder = tfa.seq2seq.BasicDecoder(self.rnn_cell, sampler=self.sampler, output_layer=self.fc)\n\n    \n  def build_rnn_cell(self, batch_sz):\n    rnn_cell = tfa.seq2seq.AttentionWrapper(self.decoder_rnn_cell, \n                                  self.attention_mechanism, attention_layer_size=self.dec_units, alignment_history = True)\n    return rnn_cell\n\n  def build_attention_mechanism(self, dec_units, memory, memory_sequence_length, attention_type='luong'):\n    # ------------- #\n    # typ: Which sort of attention (Bahdanau, Luong)\n    # dec_units: final dimension of attention outputs \n    # memory: encoder hidden states of shape (batch_size, max_length_input, enc_units)\n    # memory_sequence_length: 1d array of shape (batch_size) with every element set to max_length_input (for masking purpose)\n\n    if(attention_type=='bahdanau'):\n      return tfa.seq2seq.BahdanauAttention(units=dec_units, memory=memory, memory_sequence_length=memory_sequence_length)\n    else:\n      return tfa.seq2seq.LuongAttention(units=dec_units, memory=memory, memory_sequence_length=memory_sequence_length)\n\n  def build_initial_state(self, batch_sz, encoder_state, Dtype):\n    decoder_initial_state = self.rnn_cell.get_initial_state(batch_size=batch_sz, dtype=Dtype)\n    decoder_initial_state = decoder_initial_state.clone(cell_state=encoder_state)\n    return decoder_initial_state\n\n\n  def call(self, inputs, initial_state):\n    x = self.embedding(inputs)\n    outputs, _, _ = self.decoder(x, initial_state=initial_state, sequence_length=self.batch_sz*[max_length_output-1])\n    return outputs\n  def get_cell(self, cell_type = \"lstm\", num_of_cell = 1, name = None):\n      #print(cell_type)\n      if cell_type == \"lstm\":\n        return LSTMCell(num_of_cell, dropout = self.dropout, recurrent_dropout = self.recurrent_dropout, )\n      elif cell_type == \"rnn\":\n        return SimpleRNNCell(num_of_cell, dropout = self.dropout, recurrent_dropout = self.recurrent_dropout)\n      elif cell_type ==\"gru\":\n        return GRUCell(num_of_cell, dropout = self.dropout, recurrent_dropout = self.recurrent_dropout)\n      else:\n        print(f\"Invalid cell type: {cell_type}\")\n\n  def get_stacked_rnn_cell(self,):\n    return tf.keras.layers.StackedRNNCells( [self.get_cell(self.dec_unit_type, self.dec_units,) for i in range(self.num_of_layers)])\n","metadata":{"id":"yJ_B3mhW3jFk","execution":{"iopub.status.busy":"2022-06-27T14:39:13.125143Z","iopub.execute_input":"2022-06-27T14:39:13.125625Z","iopub.status.idle":"2022-06-27T14:39:13.146576Z","shell.execute_reply.started":"2022-06-27T14:39:13.125581Z","shell.execute_reply":"2022-06-27T14:39:13.145062Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Test decoder stack\n\ndecoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE,1, \"lstm\", 0.2,0.2,  'luong')\nsample_x = tf.random.uniform((BATCH_SIZE, max_length_output))\ndecoder.attention_mechanism.setup_memory(sample_output)\ninitial_state = decoder.build_initial_state(BATCH_SIZE,tuple(sample_state), tf.float32)\n\n\nsample_decoder_outputs = decoder(sample_x, initial_state)\n\nprint(\"Decoder Outputs Shape: \", sample_decoder_outputs.rnn_output.shape)\n","metadata":{"id":"DaiO0Z6_Ml1c","outputId":"34e00c20-6b5d-471e-d9f0-7641f592ab81","execution":{"iopub.status.busy":"2022-06-27T14:39:13.151489Z","iopub.execute_input":"2022-06-27T14:39:13.152863Z","iopub.status.idle":"2022-06-27T14:39:14.693847Z","shell.execute_reply.started":"2022-06-27T14:39:13.152820Z","shell.execute_reply":"2022-06-27T14:39:14.692476Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## Define the optimizer and the loss function","metadata":{"id":"_ch_71VbIRfK"}},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.RMSprop()\n\n\ndef loss_function(real, pred):\n  # real shape = (BATCH_SIZE, max_length_output)\n  # pred shape = (BATCH_SIZE, max_length_output, tar_vocab_size )\n  cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n  loss = cross_entropy(y_true=real, y_pred=pred)\n  mask = tf.logical_not(tf.math.equal(real,0))   #output 0 for y=0 else output 1\n  mask = tf.cast(mask, dtype=loss.dtype)  \n  loss = mask* loss\n  loss = tf.reduce_mean(loss)\n  return loss  ","metadata":{"id":"WmTHr5iV3jFr","execution":{"iopub.status.busy":"2022-06-27T14:39:14.695678Z","iopub.execute_input":"2022-06-27T14:39:14.696100Z","iopub.status.idle":"2022-06-27T14:39:14.706615Z","shell.execute_reply.started":"2022-06-27T14:39:14.696071Z","shell.execute_reply":"2022-06-27T14:39:14.704998Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Checkpoints (Object-based saving)","metadata":{"id":"DMVWzzsfNl4e"}},{"cell_type":"code","source":"checkpoint_dir = './training_checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(optimizer=optimizer,\n                                 encoder=encoder,\n                                 decoder=decoder)","metadata":{"id":"Zj8bXQTgNwrF","execution":{"iopub.status.busy":"2022-06-27T14:39:14.708658Z","iopub.execute_input":"2022-06-27T14:39:14.709404Z","iopub.status.idle":"2022-06-27T14:39:14.718447Z","shell.execute_reply.started":"2022-06-27T14:39:14.709359Z","shell.execute_reply":"2022-06-27T14:39:14.716917Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## One train_step operations","metadata":{"id":"8Bw95utNiFHa"}},{"cell_type":"code","source":"@tf.function\ndef val_step(inp, targ, enc_hidden):\n  loss = 0\n\n  with tf.GradientTape() as tape:\n    enc_output, enc_state= encoder(inp, enc_hidden)\n\n\n    dec_input = targ[ : , :-1 ] # Ignore <end> token\n    real = targ[ : , 1: ]         # ignore <start> token\n\n    # Set the AttentionMechanism object with encoder_outputs\n    decoder.attention_mechanism.setup_memory(enc_output)\n\n    # Create AttentionWrapperState as initial_state for decoder\n    decoder_initial_state = decoder.build_initial_state(BATCH_SIZE, tuple(enc_state) ,tf.float32)\n    pred = decoder(dec_input, decoder_initial_state)\n    logits = pred.rnn_output\n    loss = loss_function(real, logits)\n    metric.update_state(real, logits)\n  return loss, metric.result().numpy()","metadata":{"id":"Rz9qNDCYcWUj","execution":{"iopub.status.busy":"2022-06-27T14:39:14.720378Z","iopub.execute_input":"2022-06-27T14:39:14.720993Z","iopub.status.idle":"2022-06-27T14:39:14.731997Z","shell.execute_reply.started":"2022-06-27T14:39:14.720948Z","shell.execute_reply":"2022-06-27T14:39:14.730507Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef train_step(inp, targ, enc_hidden):\n  loss = 0\n\n  with tf.GradientTape() as tape:\n    enc_output, enc_state= encoder(inp, enc_hidden)\n\n\n    dec_input = targ[ : , :-1 ] # Ignore <end> token\n    real = targ[ : , 1: ]         # ignore <start> token\n\n    # Set the AttentionMechanism object with encoder_outputs\n    decoder.attention_mechanism.setup_memory(enc_output)\n\n    # Create AttentionWrapperState as initial_state for decoder\n    decoder_initial_state = decoder.build_initial_state(BATCH_SIZE, tuple(enc_state) ,tf.float32)\n    pred = decoder(dec_input, decoder_initial_state)\n    logits = pred.rnn_output\n    loss = loss_function(real, logits)\n    metric.update_state(real, logits)\n\n  variables = encoder.trainable_variables + decoder.trainable_variables\n  gradients = tape.gradient(loss, variables)\n  optimizer.apply_gradients(zip(gradients, variables))\n\n  return loss, metric.result().numpy()","metadata":{"id":"sC9ArXSsVfqn","execution":{"iopub.status.busy":"2022-06-27T14:39:14.734204Z","iopub.execute_input":"2022-06-27T14:39:14.735106Z","iopub.status.idle":"2022-06-27T14:39:14.746535Z","shell.execute_reply.started":"2022-06-27T14:39:14.735061Z","shell.execute_reply":"2022-06-27T14:39:14.745299Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Train the model","metadata":{"id":"pey8eb9piMMg"}},{"cell_type":"code","source":"EPOCHS = 20\nmetric = tf.keras.metrics.SparseCategoricalAccuracy()\ntf.config.run_functions_eagerly(True)\n\nstep_per_val_epoch = dataset_creator.num_of_val//BATCH_SIZE\nsteps_per_epoch = dataset_creator.num_of_train//BATCH_SIZE\n\n# step_per_val_epoch = 500//BATCH_SIZE\n# steps_per_epoch = 500//BATCH_SIZE\n\nfor epoch in range(EPOCHS):\n  start = time.time()\n  \n  enc_hidden = encoder.initialize_hidden_state()\n  total_loss = 0\n  total_accuracy = 0\n  # print(enc_hidden[0].shape, enc_hidden[1].shape)\n  metric.reset_state()\n  print(\"=\"*80)\n  print(\"TRAINING\")\n  for (batch, (inp, targ)) in enumerate(train_dataset.take(steps_per_epoch)):\n    batch_loss, batch_acc= train_step(inp, targ, enc_hidden)\n    total_loss += batch_loss\n    total_accuracy+=batch_acc\n\n    if batch % 10 == 0:\n      print('\\t Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1,\n                                                   batch,\n                                                   batch_loss.numpy(), batch_acc*100 ))\n  # saving (checkpoint) the model every 2 epochs\n  metric.reset_state()\n  total_val_loss = 0\n  total_val_accuracy = 0\n  print(\"=\"*80)\n  print(\"VALIDATING\")\n  for (batch, (inp, targ)) in enumerate(val_dataset.take(steps_per_epoch)):\n    val_batch_loss, val_batch_acc= val_step(inp, targ, enc_hidden)\n    total_val_loss += val_batch_loss\n    total_val_accuracy += val_batch_acc\n  \n  print(f\"Validatiion loss:  {total_val_loss.numpy()/  step_per_val_epoch}\")\n  print((f\"Validatiion Acc:  {(total_val_accuracy/  step_per_val_epoch)*100}\"))\n  if (epoch + 1) % 2 == 0:\n    checkpoint.save(file_prefix = checkpoint_prefix)\n  print(\"Accuracy \",(total_accuracy/steps_per_epoch) *100)\n  print('Epoch {} Loss {:.4f} Acc {:.4f}'.format(epoch + 1,\n                                      total_loss / steps_per_epoch,\n                                      (total_accuracy/ steps_per_epoch)*100\n                                      ))\n  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))","metadata":{"id":"ddefjBMa3jF0","outputId":"3d4c8ede-f14e-4b81-fda7-482917893e27","execution":{"iopub.status.busy":"2022-06-27T14:39:14.748645Z","iopub.execute_input":"2022-06-27T14:39:14.749143Z","iopub.status.idle":"2022-06-27T15:00:47.453619Z","shell.execute_reply.started":"2022-06-27T14:39:14.749102Z","shell.execute_reply":"2022-06-27T15:00:47.451346Z"},"scrolled":true,"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"#sweeping\n","metadata":{"id":"fiAXTLtggXt1"}},{"cell_type":"code","source":"sweep_config = {\n    \n    'method':'bayes',\n    'metric': {\n        'name':'Val Accuracy',\n        'goal':'maximize'\n    },\n    'parameters':{\n    \n    \"num_of_layer\" : {'values': [1]},\n    \"unit_size\": {\"values\":[256]},\n    \"unit_type\": {\"values\":[\"lstm\"]},\n    \"dropout\": {\"values\": [0.3]},\n    'recurrent_dropout':{'values':[0.3]},\n    \"epochs\":{\"value\":17},\n    \"encoder_embedding_dim\":{\"values\": [1024]},\n    \"decoder_embedding_dim\":{\"values\": [256]},\n    \"optimizer\":{\"values\": [\"rmsprop\"]}             \n                   }\n}\npprint.pprint(sweep_config)","metadata":{"id":"mWIPOOy-gXLd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sweep_id = wandb.sweep(sweep_config, project=\"Sweep_without_Attention2\")","metadata":{"id":"JJwKH2M2hM7o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def train(config = None):\n  \n#     encoder = Encoder(vocab_inp_size, 1024, 256, BATCH_SIZE, 1, \"lstm\", 0.3,0.3)\n#     decoder = Decoder(vocab_tar_size, 256, 256,BATCH_SIZE,1, \"lstm\", 0.3,0.3, 'luong')\n#     EPOCHS = config.epochs\n#     metric = tf.keras.metrics.SparseCategoricalAccuracy()\n#     tf.config.run_functions_eagerly(True)\n\n#     step_per_val_epoch = dataset_creator.num_of_val//BATCH_SIZE\n#     steps_per_epoch = dataset_creator.num_of_train//BATCH_SIZE\n\n#     # step_per_val_epoch = 500//BATCH_SIZE\n#     # steps_per_epoch = 500//BATCH_SIZE\n\n#     for epoch in range(EPOCHS):\n#       start = time.time()\n      \n#       enc_hidden = encoder.initialize_hidden_state()\n#       total_loss = 0\n#       total_accuracy = 0\n#       # print(enc_hidden[0].shape, enc_hidden[1].shape)\n#       metric.reset_state()\n#       print(\"=\"*80)\n#       print(\"TRAINING\")\n#       for (batch, (inp, targ)) in enumerate(train_dataset.take(steps_per_epoch)):\n#         batch_loss, batch_acc= train_step(inp, targ, enc_hidden)\n#         total_loss += batch_loss\n#         total_accuracy+=batch_acc\n\n#         if batch % 100 == 0:\n#           print('\\t Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1,\n#                                                       batch,\n#                                                       batch_loss.numpy(), batch_acc*100 ))\n#       # saving (checkpoint) the model every 2 epochs\n#       metric.reset_state()\n#       total_val_loss = 0\n#       total_val_accuracy = 0\n#       print(\"=\"*80)\n#       print(\"VALIDATING\")\n#       for (batch, (inp, targ)) in enumerate(val_dataset.take(steps_per_epoch)):\n#         val_batch_loss, val_batch_acc= val_step(inp, targ, enc_hidden)\n#         total_val_loss += val_batch_loss\n#         total_val_accuracy += val_batch_acc\n      \n#       print(f\"Validatiion loss:  {total_val_loss.numpy()/  step_per_val_epoch}\")\n#       print((f\"Validatiion Acc:  {(total_val_accuracy.numpy()/  step_per_val_epoch)*100}\"))\n#       if (epoch + 1) % 2 == 0:\n#         checkpoint.save(file_prefix = checkpoint_prefix)\n#       print(\"Accuracy \",(total_accuracy.numpy()/steps_per_epoch) *100)\n#       print('Epoch {} Loss {:.4f} Acc {:.4f}'.format(epoch + 1,\n#                                           total_loss / steps_per_epoch,\n#                                           (total_accuracy/ steps_per_epoch)*100\n#                                           ))\n#       print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))","metadata":{"id":"O368F0QHhWfU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Use tf-addons BasicDecoder for decoding\n","metadata":{"id":"mU3Ce8M6I3rz"}},{"cell_type":"code","source":"next(iter(val_dataset))","metadata":{"id":"j1b5xs5OfjzS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_sentence(sentence, attention_weights = None):\n  #print(\"from evaluate\",sentence)\n  sentence = dataset_creator.preprocess_sentence(sentence)\n\n  inputs = [inp_lang.word_index[i] for i in sentence]\n  inputs = [inputs for _ in range(512)]\n  inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n                                                          maxlen=max_length_input,\n                                                          padding='post')\n  inputs = tf.convert_to_tensor(inputs)\n  #print(inputs)\n  inference_batch_size = 512\n  result = ''\n\n  enc_start_state = encoder.initialize_hidden_state()\n  enc_out, enc_state  = encoder(inputs, enc_start_state)\n\n  # dec_h = enc_h\n  # dec_c = enc_c\n\n  start_tokens = tf.fill([inference_batch_size], targ_lang.word_index['\\t'])\n  end_token = targ_lang.word_index['\\n']\n\n  greedy_sampler = tfa.seq2seq.GreedyEmbeddingSampler(decoder.embedding)\n\n  # Instantiate BasicDecoder object\n  decoder_instance = tfa.seq2seq.BasicDecoder(cell=decoder.rnn_cell, sampler=greedy_sampler, output_layer=decoder.fc, maximum_iterations=25)\n  # Setup Memory in decoder stack\n  decoder.attention_mechanism.setup_memory(enc_out)\n\n  # set decoder_initial_state\n  decoder_initial_state = decoder.build_initial_state(inference_batch_size,tuple(enc_state), tf.float32)\n\n\n  ### Since the BasicDecoder wraps around Decoder's rnn cell only, you have to ensure that the inputs to BasicDecoder \n  ### decoding step is output of embedding layer. tfa.seq2seq.GreedyEmbeddingSampler() takes care of this. \n  ### You only need to get the weights of embedding layer, which can be done by decoder.embedding.variables[0] and pass this callabble to BasicDecoder's call() function\n\n  decoder_embedding_matrix = decoder.embedding.variables\n  if attention_weights:\n    return decoder.attention_mechanism(inputs)\n    #return decoder_instance(None, start_tokens = start_tokens, end_token= end_token, initial_state=decoder_initial_state)\n\n  outputs, _, _ = decoder_instance(None, start_tokens = start_tokens, end_token= end_token, initial_state=decoder_initial_state)\n  return outputs.sample_id.numpy(), outputs\n\ndef translate(sentence):\n  result,_= evaluate_sentence(sentence)\n  print(\"-\"*80)\n  #print(result[1])\n  result = \"\".join(\"\".join(targ_lang.sequences_to_texts(result[:1])).split(\" \"))\n  print('Input: %s' % (sentence))\n  print('Predicted translation: {}'.format(result))\n  return result[:-1]\ntranslate('aaditya')","metadata":{"id":"EbQpyYs13jF_","outputId":"21555b7c-fff7-4590-9c01-095cc81c8093","execution":{"iopub.status.busy":"2022-06-27T15:01:58.495512Z","iopub.execute_input":"2022-06-27T15:01:58.496194Z","iopub.status.idle":"2022-06-27T15:01:58.875070Z","shell.execute_reply.started":"2022-06-27T15:01:58.496147Z","shell.execute_reply":"2022-06-27T15:01:58.873682Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"yRazI3LpZyys"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_list  = [\"bichhua\", \"flynn\", \"dikhai\", \"amit\",\"immune\",\"bhay\",\"samadhan\",\"corolla\",\"brigadier\", \"dhndhe\",\"yatna\",\"chaudhawan\", \"vash\", \"hakikat\", \"kahlaya\", \"sheling\", \"talvon\",\"beesavaan\",\"salary\",\"jaghaega\"]\ntest_df = pd.read_csv(test_file_path, delimiter = \"\\t\", header = None)\ntemp_df = pd.DataFrame(columns=[\"Input\", \"Predicted\",\"True\"])\nfor word in word_list:\n  for index, row in test_df.iterrows():\n    if word == row[1]:\n      #print(word)\n      pred = translate(word)\n      temp_df.loc[len(temp_df.index)] = [word, pred,row[0]]\n      break\ntemp_df.head(30)\n","metadata":{"id":"Cwdfy5DeAguu","outputId":"d8b2ffaa-ef14-4755-a3fb-00f982b61b3c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(test_file_path, delimiter = \"\\t\", header = None)\ntemp_df = pd.DataFrame(columns=[\"Input\", \"Predicted\",\"True\"])\ncount =0\nfor index, row in test_df.iterrows():\n      #print(word)\n      pred = translate(row[1])\n      if pred == row[0]:\n        count+=1\n      temp_df.loc[len(temp_df.index)] = [row[1], pred,row[0]]\ntemp_df.to_csv(\"predictions_attention.csv\")\nprint(\"Test accuracy :\", (count/len(temp_df))*100)","metadata":{"id":"Sr7wEg9WIjac"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df[1]","metadata":{"id":"wD4ZftZVD7ou","outputId":"4f67c332-c3cc-422b-9048-fdce4b856a31"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_attention(attention, sentence, predicted_sentence):\n  #sentence = tf_lower_and_split_punct(sentence).numpy().decode().split()\n  #predicted_sentence = predicted_sentence.numpy().decode().split() + ['[END]']\n  fig = plt.figure(figsize=(10, 10))\n  ax = fig.add_subplot(1, 1, 1)\n\n  attention = attention[:len(predicted_sentence), :len(sentence)]\n\n  ax.matshow(attention, cmap='viridis', vmin=0.0)\n\n  fontdict = {'fontsize': 14}\n\n  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n\n  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n\n  ax.set_xlabel('Input text')\n  ax.set_ylabel('Output text')\n  plt.suptitle('Attention weights')","metadata":{"id":"xvSmMe-ij3Wo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out =  evaluate_sentence(\"aditya\", True)\n","metadata":{"id":"i8p09tR5j49X","outputId":"7fcfd350-60e1-4160-b721-f1eadc3ea497"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"d8vLxz__aQg0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, attention, _ = out","metadata":{"id":"ux7uLBGGolMZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cell_state, attention, alignments, alignment_history, attention_state = attention","metadata":{"id":"HBjlxSHvpW-i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"attention","metadata":{"id":"aZrvAOuXsrIh","outputId":"037e3f98-905e-4654-8058-06ddcac7b4a5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stack_align = alignment_history.stack()","metadata":{"id":"KHAo16cIW4dR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stack_align[:,0,:]","metadata":{"id":"jwsk7lMdXttF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"decoder","metadata":{"id":"wxjz4mlXXAfM","outputId":"132bbf65-3244-45fa-f45b-fb3e9a982a6d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alignment_history.","metadata":{"id":"neFLcH1BVWFC","outputId":"deae87dc-0e10-4970-bae2-9ff25289269f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out[1].attention","metadata":{"id":"LSR7ugOfvlmE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.matshow([out[1].attention_state[0].numpy(),out[1].attention_state[0].numpy()])","metadata":{"id":"tNQsO2f5xjAL","outputId":"5f56a9f8-c995-461c-8861-6243dfcacb2e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_attention(stack_align[:,0,:],[\"a\"]*12,[\"a\"]*12)","metadata":{"id":"yFYj-RVop275","outputId":"b16d13c8-6298-4096-9fdd-4d8059ce54fe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out[1].attention","metadata":{"id":"x_r539V2l3hJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Restore the latest checkpoint and test","metadata":{"id":"n250XbnjOaqP"}},{"cell_type":"code","source":"# restoring the latest checkpoint in checkpoint_dir\ncheckpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))","metadata":{"id":"UJpT9D5_OgP6","outputId":"cab7a8bb-8f9b-42ab-d466-80b99853b2af"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"WYmYhNN_faR5","outputId":"40cbf808-cdb4-4795-eeb2-38b137bdb6c3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"translate(u'esta es mi vida.')","metadata":{"id":"zSx2iM36EZQZ","outputId":"d2b0f03b-454d-452b-eb7e-ead9b77812a5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"translate(u'¿todavia estan en casa?')","metadata":{"id":"A3LLCx3ZE0Ls","outputId":"321c8929-9f30-4b5d-d8da-1592376fe07d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# wrong translation\ntranslate(u'trata de averiguarlo.')","metadata":{"id":"DUQVLVqUE1YW","outputId":"419ed858-c13d-487b-f22e-53d1344e17e9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"aBNwVbNo1wnb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Use tf-addons BeamSearchDecoder \n","metadata":{"id":"IRUuNDeY0HiC"}},{"cell_type":"code","source":"def beam_evaluate_sentence(sentence, beam_width=3):\n  sentence = dataset_creator.preprocess_sentence(sentence)\n\n  inputs = [inp_lang.word_index[i] for i in sentence]\n  inputs = [inputs for _ in range(64)]\n  inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n                                                          maxlen=max_length_input,\n                                                          padding='post')\n  inputs = tf.convert_to_tensor(inputs)\n  print(inputs)\n  inference_batch_size = inputs.shape[0]\n  result = ''\n\n  enc_start_state = [[tf.zeros((inference_batch_size, units)),tf.zeros((inference_batch_size, units))]]*1\n  enc_out, enc_state = encoder(inputs, enc_start_state)\n\n  start_tokens = tf.fill([inference_batch_size], targ_lang.word_index['\\t'])\n  end_token = targ_lang.word_index['\\n']\n\n  # From official documentation\n  # NOTE If you are using the BeamSearchDecoder with a cell wrapped in AttentionWrapper, then you must ensure that:\n  # The encoder output has been tiled to beam_width via tfa.seq2seq.tile_batch (NOT tf.tile).\n  # The batch_size argument passed to the get_initial_state method of this wrapper is equal to true_batch_size * beam_width.\n  # The initial state created with get_initial_state above contains a cell_state value containing properly tiled final state from the encoder.\n\n  enc_out = tfa.seq2seq.tile_batch(enc_out, multiplier=beam_width)\n  decoder.attention_mechanism.setup_memory(enc_out)\n  print(\"beam_with * [batch_size, max_length_input, rnn_units] :  3 * [1, 16, 1024]] :\", enc_out.shape)\n\n  # set decoder_inital_state which is an AttentionWrapperState considering beam_width\n  hidden_state = tfa.seq2seq.tile_batch(tuple(enc_state), multiplier=beam_width)\n  decoder_initial_state = decoder.rnn_cell.get_initial_state(batch_size=beam_width*inference_batch_size, dtype=tf.float32)\n  decoder_initial_state = decoder_initial_state.clone(cell_state=hidden_state)\n\n  # Instantiate BeamSearchDecoder\n  decoder_instance = tfa.seq2seq.BeamSearchDecoder(decoder.rnn_cell,beam_width=beam_width, output_layer=decoder.fc, embedding_fn = decoder.embedding)\n  decoder_embedding_matrix = decoder.embedding.variables[:]\n\n  # The BeamSearchDecoder object's call() function takes care of everything.\n  outputs, final_state, sequence_lengths = decoder_instance(None, start_tokens=start_tokens, end_token=end_token, initial_state=decoder_initial_state)\n  # outputs is tfa.seq2seq.FinalBeamSearchDecoderOutput object. \n  # The final beam predictions are stored in outputs.predicted_id\n  # outputs.beam_search_decoder_output is a tfa.seq2seq.BeamSearchDecoderOutput object which keep tracks of beam_scores and parent_ids while performing a beam decoding step\n  # final_state = tfa.seq2seq.BeamSearchDecoderState object.\n  # Sequence Length = [inference_batch_size, beam_width] details the maximum length of the beams that are generated\n\n  \n  # outputs.predicted_id.shape = (inference_batch_size, time_step_outputs, beam_width)\n  # outputs.beam_search_decoder_output.scores.shape = (inference_batch_size, time_step_outputs, beam_width)\n  # Convert the shape of outputs and beam_scores to (inference_batch_size, beam_width, time_step_outputs)\n  final_outputs = tf.transpose(outputs.predicted_ids, perm=(0,2,1))\n  beam_scores = tf.transpose(outputs.beam_search_decoder_output.scores, perm=(0,2,1))\n  \n  return final_outputs.numpy(), beam_scores.numpy()\ndef beam_translate(sentence):\n  result, beam_scores = beam_evaluate_sentence(sentence)\n  print(result.shape, beam_scores.shape)\n  for beam, score in zip(result, beam_scores):\n    print(beam.shape, score.shape)\n    output = targ_lang.sequences_to_texts(beam)\n    output = [a[:a.index('\\n')] for a in output]\n    beam_score = [a.sum() for a in score]\n    print('Input: %s' % (sentence))\n    for i in range(len(output)):\n      print('{} Predicted translation: {}  {}'.format(i+1, output[i], beam_score[i]))\nbeam_translate(\"aande\")","metadata":{"id":"AJ-RTQ0hsJNL","outputId":"3564ca64-23c0-46c7-a120-acd49d3dd213","execution":{"iopub.status.busy":"2022-06-27T15:01:16.649322Z","iopub.execute_input":"2022-06-27T15:01:16.650085Z","iopub.status.idle":"2022-06-27T15:01:17.322510Z","shell.execute_reply.started":"2022-06-27T15:01:16.650039Z","shell.execute_reply":"2022-06-27T15:01:17.317677Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"decoder.fc.get_config()","metadata":{"id":"FxUg4eSOyvQ6","outputId":"44d00eaf-000b-4fbd-d128-19d4c4adfcf1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for (_, (inp, targ) )  in enumerate(train_dataset.take(64)):\n\n  enc_start_state = [[tf.zeros((64, units)),tf.zeros((64, units))]]*1\n\n  enc_output, enc_state= encoder(inp , enc_start_state)\n\n\n  dec_input = targ[ : , :-1 ] # Ignore <end> token\n  real = targ[ : , 1: ]         # ignore <start> token\n\n      # Set the AttentionMechanism object with encoder_outputs\n  decoder.attention_mechanism.setup_memory(enc_output)\n\n  # Create AttentionWrapperState as initial_state for decoder\n  decoder_initial_state = decoder.build_initial_state(64, tuple(enc_state) ,tf.float32)\n  pred = decoder(dec_input, decoder_initial_state)\n","metadata":{"id":"g_LvXGvX8X-O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get html element\ndef cstr(s, color='black'):\n\tif s == ' ':\n    \n\t\treturn \"<text style=color:#000;padding-left:10px;background-color:{}> </text>\".format(color, s)\n\telse:\n\n\t\treturn \"<text style=color:#000;background-color:{}>{} </text>\".format(color, s)\n\t\n# print html\ndef print_color(t):\n\tdisplay(html_print(''.join([cstr(ti, color=ci) for ti,ci in t])))\n\n# get appropriate color for value\ndef get_clr(value):\n\tcolors = ['#85c2e1', '#89c4e2', '#95cae5', '#99cce6', '#a1d0e8'\n\t\t'#b2d9ec', '#baddee', '#c2e1f0', '#eff7fb', '#f9e8e8',\n\t\t'#f9e8e8', '#f9d4d4', '#f9bdbd', '#f8a8a8', '#f68f8f',\n\t\t'#f47676', '#f45f5f', '#f34343', '#f33b3b', '#f42e2e']\n\tvalue = int((value * 18) )\n\t#print(\"color value\",value)\n\treturn colors[value]\n\n# sigmoid function\ndef sigmoid(x):\n\tz = 1/(1 + np.exp(-x)) \n\treturn z\n","metadata":{"id":"TODnXBleDzzO","execution":{"iopub.status.busy":"2022-06-27T15:02:17.715139Z","iopub.execute_input":"2022-06-27T15:02:17.715509Z","iopub.status.idle":"2022-06-27T15:02:17.727476Z","shell.execute_reply.started":"2022-06-27T15:02:17.715479Z","shell.execute_reply":"2022-06-27T15:02:17.725956Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"uTsudkrv35MS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize(output_values, result_list, cell_no, predicted_char):\n    #print( result_list)\n    print(\"\\nPredicted Char : \", predicted_char)\n    print(f\"Importance of {predicted_char}\")\n    text_colours = []\n    for i in range(len(result_list)):\n      #print(i, cell_no)\n      #print(result_list[i])\n      #print(output_values[i])\n      #print(output_values[i][cell_no])\n      #print(output_values[i][cell_no])\n      #print(output_values[i][cell_no])\n      #print(int(output_values[i][cell_no]*18))\n      text = (result_list[i], get_clr(output_values[i][cell_no]))\n      text_colours.append(text)\n    print_color(text_colours)","metadata":{"id":"W2qZ8Ml_0-ZL","execution":{"iopub.status.busy":"2022-06-27T15:02:19.594585Z","iopub.execute_input":"2022-06-27T15:02:19.595273Z","iopub.status.idle":"2022-06-27T15:02:19.603434Z","shell.execute_reply.started":"2022-06-27T15:02:19.595240Z","shell.execute_reply":"2022-06-27T15:02:19.601685Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"visualize([[0.1,0.9,0.9]],['a'],2,'q')","metadata":{"id":"im_mV_8VR8Mk","outputId":"4b9ad9c9-8e5b-477f-c7c8-c4ccc6bd9b9b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tx = 0\ndef translate(sentence):\n  print(sentence)\n  result, output = evaluate_sentence(sentence)\n  print(\"-\"*80)\n  print(result[0])\n  word_list =\"\".join(targ_lang.sequences_to_texts(result[:1])).split(\" \")\n  print('Input: %s' % (sentence))\n  print('Predicted translation: {}'.format(word_list))\n  #print(output.rnn_output)\n  print(\"word_list\", word_list)\n  print(\"result \", result[0])\n  output_values = []\n  for time_step in output.rnn_output[0]:\n    step = []\n    for char_index in list(result)[0]:\n      #print(char_index)\n      step.append(sigmoid(time_step[char_index]))\n    output_values.append(step)\n  output_values = np.array(output_values)\n  #print(output_values.shape)\n  output_values = output_values.transpose()\n  scaler = MinMaxScaler()\n  scaler.fit(output_values)\n  output_values =scaler.transform(output_values)\n  #print(output_values.shape)\n  #print(word_list)\n  for i,char in enumerate(word_list[:-1]):\n    visualize(output_values[:i+1], word_list[:i+1], i,char )\n  return output.rnn_output\n\ntx =translate('youtube')","metadata":{"id":"OilmC68U6zKL","outputId":"78959355-fa7d-4eec-972e-20d4385d19a6","execution":{"iopub.status.busy":"2022-06-27T15:12:44.829783Z","iopub.execute_input":"2022-06-27T15:12:44.830205Z","iopub.status.idle":"2022-06-27T15:12:45.123207Z","shell.execute_reply.started":"2022-06-27T15:12:44.830176Z","shell.execute_reply":"2022-06-27T15:12:45.121827Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef connectivity_step(inp, targ, enc_hidden):\n  loss = 0\n\n  with tf.GradientTape() as tape:\n    tape.watch(inp)\n    enc_output, enc_state= encoder(inp, enc_hidden)\n\n\n    dec_input = targ[ : , :-1 ] # Ignore <end> token\n    real = targ[ : , 1: ]         # ignore <start> token\n\n    # Set the AttentionMechanism object with encoder_outputs\n    decoder.attention_mechanism.setup_memory(enc_output)\n\n    # Create AttentionWrapperState as initial_state for decoder\n    decoder_initial_state = decoder.build_initial_state(BATCH_SIZE, tuple(enc_state) ,tf.float32)\n    pred = decoder(dec_input, decoder_initial_state)\n    #logits = pred.rnn_output\n    #loss = loss_function(real, logits)\n    #metric.update_state(real, logits)\n\n  #variables = encoder.trainable_variables + decoder.trainable_variables\n  gradients = tape.gradient(pred.rnn_output, inp)\n  print(gradients)\n  #optimizer.apply_gradients(zip(gradients, variables))\n\n  return loss, metric.result().numpy()\n\nfor (i, (inp, targ)) in enumerate(test_dataset.take(1)):\n\n  x, y = connectivity_step(tf.cast(inp, dtype = tf.float32), targ,  encoder.initialize_hidden_state())\n  if i == 1:\n    break","metadata":{"id":"dtlNN-yrfhOE","outputId":"1b1483ba-2ec3-47af-b00b-ba6b20ace084"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with tf.GradientTape(persistent=True, watch_accessed_variables=False) as tape:\n        tape.watch(embedded_in)\n\n        enc_out, enc_state = get_output_from_embedding(model.encoder, embedded_in, enc_state)\n\n        dec_state = enc_state\n        dec_input = tf.expand_dims([model.targ_tokenizer.word_index[\"\\t\"]]*1, 1)\n\n        for t in range(1, model.max_target_len):\n\n            lstm_out, dec_state, _ = get_lstm_output(model.decoder, dec_input, dec_state, enc_out)\n\n            preds = model.decoder.dense(model.decoder.flatten(lstm_out))\n            gradient_list.append(tape.gradient(lstm_out, embedded_in)[0])\n            \n            preds = tf.argmax(preds, 1)\n            next_char = model.targ_tokenizer.index_word[preds.numpy().item()]\n            result += next_char\n\n            dec_input = tf.expand_dims(preds, 1)\n\n            if next_char == \"\\n\":\n                return result[:-1], gradient_list[:-1]\n\n        return result[:-1], gradient_list[:-1]","metadata":{"id":"kjk8922N8tQ9","outputId":"01002dc9-bc4d-4809-998e-e92d8e5140fd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\ndef get_connectivity(word):\n  print(\"Input word : \", word)\n  inputs = [inp_lang.word_index[i] for i in word]\n  inputs = [inputs for _ in range(64)]\n  inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n                                                          maxlen=max_length_input,\n                                                          padding='post')\n  inputs = tf.convert_to_tensor(inputs)\n  print(inputs)\n  #print(index_list)\n\n  enc_start_state = [[tf.zeros((64, units)),tf.zeros((64, units))]]*1\n\n  enc_output, enc_state= encoder(inp , enc_start_state)\n\n\n  dec_input = targ[ : , :-1 ] # Ignore <end> token\n  real = targ[ : , 1: ]         # ignore <start> token\n\n      # Set the AttentionMechanism object with encoder_outputs\n  decoder.attention_mechanism.setup_memory(enc_output)\n\n  # Create AttentionWrapperState as initial_state for decoder\n  decoder_initial_state = decoder.build_initial_state(64, tuple(enc_state) ,tf.float32)\n  pred = decoder(dec_input, decoder_initial_state)\n  \n  output = s2s.call(enc_inp, dec_input)\n  temp_list = []\n  #for i in range(len(index_list)):\n  input_char_list = list(word)\n  first_prediction = output[0].rnn_output[0]\n  pred_char_index = (argmax(output[0].rnn_output[0], axis =1))\n  #print(\"pred_char_index\",pred_char_index)\n  scaler = MinMaxScaler()\n  for i,  pred_char in enumerate(index_list):\n    \n    output_values = []  \n    for time_step in first_prediction:\n        #print(time_step.shape)\n        \n        prob = []\n        for index in pred_char_index:\n          #print(index)\n          prob.append(time_step[index].numpy())\n        #print(prob)\n        output_values.append(prob)\n    scaler.fit(output_values)\n    output_values  = scaler.transform(output_values)\n    #print(np.array(output_values).shape)\n    #print(len(input_char_list))\n    #print(\"pred_char_index\", pred_char_index)\n    out_char_list = list(idx_to_word(pred_char_index))\n\n    temp_list.append(idx_to_word(pred_char_index))\n\n    visualize(output_values, input_char_list[:i],i, out_char_list[i])\n  pred_word = \"\".join(out_char_list)\n  print(f\"\\nTransliterate word of {word[:-1]} is {pred_word[:i]}\")\nget_connectivity(\"ande\")","metadata":{"id":"xY0NMGTv3_i1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"J6xRXikU4Tuw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"beam_translate(u'¿todavia estan en casa?')","metadata":{"id":"_BezQwENFY3L","outputId":"1a5fe75a-7ad0-43b5-fe59-4cce436ebd1a"},"execution_count":null,"outputs":[]}]}